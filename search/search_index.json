{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-moonshots-documentation","title":"Welcome to Moonshot's Documentation","text":"<p>Moonshot is a tool designed for AI developers and security experts to evaluate and red-team any LLM/ LLM application. In this initial version, Moonshot can be used through its interative Command Line Interface, within python notebooks (example), or even seamlessly integrated into your model development workflow to to run repeatable tests.</p> <p>Below are some useful links to help you get started with Moonshot.</p> <ul> <li>If you want to quickly start on Moonshot, look at our getting started.</li> <li>If you need a full user guide on Moonshot UI, our Web UI guide is your best take.</li> <li>If you want to integrate our library with your CI/CD pipeline, take a look at our API reference.</li> </ul>"},{"location":"acknowledgement/acknowledgement/","title":"Acknowledgements","text":""},{"location":"acknowledgement/acknowledgement/#datasets-used-in-moonshot-recipes","title":"Datasets used in Moonshot recipes","text":"Dataset Source License AdvGLUE https://adversarialglue.github.io/ Creative Commons Attribution 4.0 International Analogical Similarity https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/analogical_similarity Apache License Version 2.0, January 2004 AI2 Reasoning Challenge https://allenai.org/data/arc Creative Commons Attribution-ShareAlike 4.0 International Auto Categorization https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/auto_categorization Apache License Version 2.0, January 2004 BBQ https://github.com/nyu-mll/BBQ Creative Commons Attribution 4.0 International CBBQ https://github.com/YFHuangxxxx/CBBQ Creative Commons Attribution Share Alike 4.0 International Cause and Effect https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/cause_and_effect Apache License Version 2.0, January 2004 Challenging Toxicity Prompts https://decodingtrust.github.io/ Creative Commons Attribution ShareAlike 4.0 International Contextual Parametric Knowledge https://github.com/google-research/language Apache License Version 2.0, January 2004 CoQA https://stanfordnlp.github.io/coqa/ Creative Commons Attribution 4.0 International; MSR-LA;     Apache License Version 2.0, January 2004 CValues https://github.com/X-PLUG/CValues/tree/main Apache License Version 2.0, January 2004 Enron Email https://github.com/ParakweetLabs/EmailIntentDataSet Apache License Version 2.0, January 2004 GRE Reading Comprehension https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/gre_reading_comprehension Apache License Version 2.0, January 2004 GSM8K https://github.com/openai/grade-school-math MIT License HellaSwag https://github.com/rowanz/hellaswag MIT License MMLU https://github.com/hendrycks/test MIT License TR9856 https://aclanthology.org/P15-2069.pdf Creative Commons Attribution 3.0 International Winogrande https://github.com/allenai/winogrande Apache-2.0 License WORD https://aclanthology.org/L18-1408/ Creative Commons Attribution 3.0 International Real Toxicity Prompts https://github.com/allenai/real-toxicity-prompts/ Apache License Version 2.0, January 2004 Stanford Question Answering Dataset (SQuAD) https://modestyachts.github.io/squadshifts-website/ Creative Commons Attribution 4.0 International Tanglish Tweets for Sentiment Ananlysis https://www.kaggle.com/datasets/vyombhatia/tanglish-comments-for-sentiment-ananlysis/data Creative Commons Attribution 1.0 International Tamil News Classification https://github.com/vanangamudi/tamil-news-classification/tree/master/dataset/news GNU General Public License v3.0 Thirukkural Dataset https://github.com/vijayanandrp/Thirukkural-Tamil-Dataset Creative Commons Attribution 4.0 International TruthfulQA https://github.com/sylinrl/TruthfulQA Apache License Version 2.0, January 2004 UCI Adult https://archive.ics.uci.edu/dataset/2/adult Creative Commons Attribution 4.0 International"},{"location":"additional_information/additional_information/","title":"Additional information","text":""},{"location":"additional_information/additional_information/#explaining-python-m-moonshot-i-moonshot-ui","title":"Explaining <code>python -m moonshot -i moonshot-ui</code>","text":""},{"location":"additional_information/additional_information/#step-1-install-moonshot-ui","title":"Step 1: Install Moonshot UI","text":"<ol> <li>Downloads Moonshot UI from GitHub. <pre><code>$ git clone git@github.com:moonshot-admin/moonshot-ui.git\n</code></pre></li> <li>Installs Required Dependencies</li> <li>Makes sure that all necessary requirements are installed by executing the following command: <pre><code>$ npm install\n</code></pre></li> <li>From the project root folder, executes the following command: <pre><code>$ npm run build\n</code></pre></li> </ol>"},{"location":"additional_information/additional_information/#step-2-serving-moonshot-ui","title":"Step 2: Serving Moonshot UI","text":"<p>After the build is completed, serves the UI with this command: <pre><code>$ npm start\n</code></pre> Access the Web UI from browser <code>http://localhost:3000</code></p>"},{"location":"api_reference/api_connector/","title":"Connector API","text":""},{"location":"api_reference/api_connector/#moonshot.src.api.api_connector.api_create_connector_from_endpoint","title":"<code>api_create_connector_from_endpoint(ep_id)</code>","text":"<p>Creates a connector based on the provided endpoint ID.</p> <p>This function retrieves the endpoint arguments using the provided endpoint ID and then creates a connector based on those arguments. It utilizes the ConnectorManager's read_endpoint method to fetch the endpoint arguments and then calls the create_connector method to initialize and return the connector.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint for which to create a connector.</p> required <p>Returns:</p> Name Type Description <code>Connector</code> <code>Connector</code> <p>An initialized Connector object.</p> Source code in <code>moonshot/src/api/api_connector.py</code> <pre><code>@validate_call\ndef api_create_connector_from_endpoint(ep_id: str) -&gt; Connector:\n    \"\"\"\n    Creates a connector based on the provided endpoint ID.\n\n    This function retrieves the endpoint arguments using the provided endpoint ID and then creates a connector\n    based on those arguments. It utilizes the ConnectorManager's read_endpoint method to fetch the endpoint\n    arguments and then calls the create_connector method to initialize and return the connector.\n\n    Args:\n        ep_id (str): The ID of the endpoint for which to create a connector.\n\n    Returns:\n        Connector: An initialized Connector object.\n    \"\"\"\n    return Connector.create(ConnectorEndpoint.read(ep_id))\n</code></pre>"},{"location":"api_reference/api_connector/#moonshot.src.api.api_connector.api_create_connectors_from_endpoints","title":"<code>api_create_connectors_from_endpoints(ep_ids)</code>","text":"<p>Creates connectors for multiple endpoints based on their IDs.</p> <p>This function takes a list of endpoint IDs, retrieves the corresponding endpoint arguments for each ID, and then creates a connector for each set of arguments. It utilizes the ConnectorEndpoint's read method to fetch the endpoint arguments and then calls the Connector's create method to initialize the connectors.</p> <p>Parameters:</p> Name Type Description Default <code>ep_ids</code> <code>conlist(str, min_length=1</code> <p>A list of endpoint IDs for which to create connectors.</p> required <p>Returns:</p> Type Description <code>list[Connector]</code> <p>list[Connector]: A list of initialized Connector objects.</p> Source code in <code>moonshot/src/api/api_connector.py</code> <pre><code>@validate_call\ndef api_create_connectors_from_endpoints(\n    ep_ids: conlist(str, min_length=1)\n) -&gt; list[Connector]:\n    \"\"\"\n    Creates connectors for multiple endpoints based on their IDs.\n\n    This function takes a list of endpoint IDs, retrieves the corresponding endpoint arguments for each ID,\n    and then creates a connector for each set of arguments. It utilizes the ConnectorEndpoint's read method\n    to fetch the endpoint arguments and then calls the Connector's create method to initialize the connectors.\n\n    Args:\n        ep_ids (conlist(str, min_length=1)): A list of endpoint IDs for which to create connectors.\n\n    Returns:\n        list[Connector]: A list of initialized Connector objects.\n    \"\"\"\n    return [Connector.create(ConnectorEndpoint.read(ep_id)) for ep_id in ep_ids]\n</code></pre>"},{"location":"api_reference/api_connector/#moonshot.src.api.api_connector.api_get_all_connector_type","title":"<code>api_get_all_connector_type()</code>","text":"<p>Retrieves a list of all available connector types.</p> <p>This function calls the ConnectorManager's get_available_connector_types method to retrieve a list of all available connector types. It returns the list of connector types.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of connector types.</p> Source code in <code>moonshot/src/api/api_connector.py</code> <pre><code>def api_get_all_connector_type() -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of all available connector types.\n\n    This function calls the ConnectorManager's get_available_connector_types method to retrieve a list of all available\n    connector types. It returns the list of connector types.\n\n    Returns:\n        list[str]: A list of connector types.\n    \"\"\"\n    return Connector.get_available_items()\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/","title":"Connector Endpoint API","text":""},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_create_endpoint","title":"<code>api_create_endpoint(name, connector_type, uri, token, max_calls_per_second, max_concurrency, params)</code>","text":"<p>Creates a new connector endpoint.</p> <p>This function creates a new connector endpoint with the specified parameters. It initializes a ConnectorEndpointArguments instance and then uses the ConnectorEndpoint class to create the endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the endpoint.</p> required <code>connector_type</code> <code>str</code> <p>The type of the connector.</p> required <code>uri</code> <code>str</code> <p>The URI for the connector.</p> required <code>token</code> <code>str</code> <p>The token for authentication with the connector.</p> required <code>max_calls_per_second</code> <code>int</code> <p>The maximum number of calls allowed per second.</p> required <code>max_concurrency</code> <code>int</code> <p>The maximum number of concurrent calls allowed.</p> required <code>params</code> <code>dict</code> <p>Additional parameters for the connector.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created connector endpoint.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_create_endpoint(\n    name: str,\n    connector_type: str,\n    uri: str,\n    token: str,\n    max_calls_per_second: int,\n    max_concurrency: int,\n    params: dict,\n) -&gt; str:\n    \"\"\"\n    Creates a new connector endpoint.\n\n    This function creates a new connector endpoint with the specified parameters. It initializes\n    a ConnectorEndpointArguments instance and then uses the ConnectorEndpoint class to create\n    the endpoint.\n\n    Args:\n        name (str): The name of the endpoint.\n        connector_type (str): The type of the connector.\n        uri (str): The URI for the connector.\n        token (str): The token for authentication with the connector.\n        max_calls_per_second (int): The maximum number of calls allowed per second.\n        max_concurrency (int): The maximum number of concurrent calls allowed.\n        params (dict): Additional parameters for the connector.\n\n    Returns:\n        str: The ID of the newly created connector endpoint.\n    \"\"\"\n    # Create a new connector endpoint arguments instance.\n    # We do not need to provide id and created_date.\n    # This is because during creation:\n    #   1. the id is slugify from the name and stored as id.\n    #   2. the created_date is based on the os file created date and time.\n    connector_endpoint_args = ConnectorEndpointArguments(\n        id=\"\",\n        name=name,\n        connector_type=connector_type,\n        uri=uri,\n        token=token,\n        max_calls_per_second=max_calls_per_second,\n        max_concurrency=max_concurrency,\n        params=params,\n        created_date=\"\",\n    )\n    return ConnectorEndpoint.create(connector_endpoint_args)\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_delete_endpoint","title":"<code>api_delete_endpoint(ep_id)</code>","text":"<p>Deletes an endpoint from the connector manager.</p> <p>This function deletes an endpoint from the connector manager using the provided endpoint ID.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the deletion was successful.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the endpoint with the given ID does not exist or the deletion failed.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_delete_endpoint(ep_id: str) -&gt; bool:\n    \"\"\"\n    Deletes an endpoint from the connector manager.\n\n    This function deletes an endpoint from the connector manager using the provided endpoint ID.\n\n    Args:\n        ep_id (str): The ID of the endpoint to delete.\n\n    Returns:\n        bool: True if the deletion was successful.\n\n    Raises:\n        RuntimeError: If the endpoint with the given ID does not exist or the deletion failed.\n    \"\"\"\n    return ConnectorEndpoint.delete(ep_id)\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_get_all_endpoint","title":"<code>api_get_all_endpoint()</code>","text":"<p>Retrieves a list of all available endpoints.</p> <p>This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available endpoints and their details. It then converts each ConnectorEndpointArguments object into a dictionary for easier consumption by the caller.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing an endpoint's details.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>def api_get_all_endpoint() -&gt; list[dict]:\n    \"\"\"\n    Retrieves a list of all available endpoints.\n\n    This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available\n    endpoints and their details. It then converts each ConnectorEndpointArguments object into a dictionary for easier\n    consumption by the caller.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing an endpoint's details.\n    \"\"\"\n    _, endpoints = ConnectorEndpoint.get_available_items()\n    return [endpoint.to_dict() for endpoint in endpoints]\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_get_all_endpoint_name","title":"<code>api_get_all_endpoint_name()</code>","text":"<p>Retrieves a list of all endpoint names.</p> <p>This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available endpoint names. It extracts the names from the tuple returned by get_available_endpoints, which contains a list of endpoint names and a list of ConnectorEndpointArguments objects.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of endpoint names.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>def api_get_all_endpoint_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of all endpoint names.\n\n    This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available\n    endpoint names. It extracts the names from the tuple returned by get_available_endpoints, which contains a list\n    of endpoint names and a list of ConnectorEndpointArguments objects.\n\n    Returns:\n        list[str]: A list of endpoint names.\n    \"\"\"\n    endpoints_names, _ = ConnectorEndpoint.get_available_items()\n    return endpoints_names\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_read_endpoint","title":"<code>api_read_endpoint(ep_id)</code>","text":"<p>Reads an endpoint from the connector manager.</p> <p>This function reads an endpoint from the connector manager using the provided endpoint ID.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint to read.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the endpoint information.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_read_endpoint(ep_id: str) -&gt; dict:\n    \"\"\"\n    Reads an endpoint from the connector manager.\n\n    This function reads an endpoint from the connector manager using the provided endpoint ID.\n\n    Args:\n        ep_id (str): The ID of the endpoint to read.\n\n    Returns:\n        dict: A dictionary containing the endpoint information.\n    \"\"\"\n    return ConnectorEndpoint.read(ep_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_update_endpoint","title":"<code>api_update_endpoint(ep_id, **kwargs)</code>","text":"<p>Updates an existing endpoint with new values.</p> <p>This function updates an existing endpoint in the connector manager using the provided endpoint ID and keyword arguments.</p> <p>Each keyword argument corresponds to an attribute of the endpoint that should be updated.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint to update.</p> required <code>**kwargs</code> <p>Arbitrary keyword arguments representing the attributes to update.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the update was successful.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the endpoint with the given ID does not exist or the update failed.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_update_endpoint(ep_id: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Updates an existing endpoint with new values.\n\n    This function updates an existing endpoint in the connector manager using the provided endpoint ID and\n    keyword arguments.\n\n    Each keyword argument corresponds to an attribute of the endpoint that should be updated.\n\n    Args:\n        ep_id (str): The ID of the endpoint to update.\n        **kwargs: Arbitrary keyword arguments representing the attributes to update.\n\n    Returns:\n        bool: True if the update was successful.\n\n    Raises:\n        RuntimeError: If the endpoint with the given ID does not exist or the update failed.\n    \"\"\"\n    # Check if the endpoint exists\n    try:\n        existing_endpoint = ConnectorEndpoint.read(ep_id)\n    except Exception:\n        raise RuntimeError(\n            f\"[api_connector_endpoint]: Endpoint with ID '{ep_id}' does not exist\"\n        )\n\n    # Update the fields of the existing endpoint with the provided kwargs\n    for key, value in kwargs.items():\n        if hasattr(existing_endpoint, key):\n            setattr(existing_endpoint, key, value)\n\n    # Perform pydantic check on the updated existing endpoint\n    ConnectorEndpointArguments.model_validate(existing_endpoint.to_dict())\n\n    # Update the endpoint\n    return ConnectorEndpoint.update(existing_endpoint)\n</code></pre>"},{"location":"api_reference/api_context_strategy/","title":"Context Strategy API","text":""},{"location":"api_reference/api_context_strategy/#moonshot.src.api.api_context_strategy.api_delete_context_strategy","title":"<code>api_delete_context_strategy(cs_id)</code>","text":"<p>Deletes a context strategy identified by its ID.</p> <p>This API endpoint interfaces with the <code>ContextStrategy.delete</code> method to remove a context strategy from the system. It is used to manage the available context strategies by allowing for their removal when they are no longer needed.</p> <p>Parameters:</p> Name Type Description Default <code>cs_id</code> <code>str</code> <p>The unique identifier of the context strategy to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the context strategy was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_context_strategy.py</code> <pre><code>@validate_call\ndef api_delete_context_strategy(cs_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a context strategy identified by its ID.\n\n    This API endpoint interfaces with the `ContextStrategy.delete` method to remove a context strategy from the system.\n    It is used to manage the available context strategies by allowing for their removal when they are no longer needed.\n\n    Args:\n        cs_id (str): The unique identifier of the context strategy to be deleted.\n\n    Returns:\n        bool: True if the context strategy was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return ContextStrategy.delete(cs_id)\n</code></pre>"},{"location":"api_reference/api_context_strategy/#moonshot.src.api.api_context_strategy.api_get_all_context_strategies","title":"<code>api_get_all_context_strategies()</code>","text":"<p>Retrieves and returns the names of all context strategies currently available.</p> <p>This API endpoint interfaces with the <code>ContextStrategy.get_all_context_strategy_names</code> method to fetch a list of all context strategy names. It's designed for clients that need to know what context strategies are available for use in sessions or other components of the system.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing the name of a context strategy.</p> Source code in <code>moonshot/src/api/api_context_strategy.py</code> <pre><code>def api_get_all_context_strategies() -&gt; list[str]:\n    \"\"\"\n    Retrieves and returns the names of all context strategies currently available.\n\n    This API endpoint interfaces with the `ContextStrategy.get_all_context_strategy_names` method to fetch a list\n    of all context strategy names. It's designed for clients that need to know what context strategies are available for\n    use in sessions or other components of the system.\n\n    Returns:\n        list[str]: A list of strings, each representing the name of a context strategy.\n    \"\"\"\n    return ContextStrategy.get_all_context_strategies()\n</code></pre>"},{"location":"api_reference/api_context_strategy/#moonshot.src.api.api_context_strategy.api_get_all_context_strategy_metadata","title":"<code>api_get_all_context_strategy_metadata()</code>","text":"<p>Retrieves metadata for all context strategy modules.</p> <p>This function retrieves the metadata for all available context strategies and returns a list of metadata dictionaries.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list of attack module metadata.</p> Source code in <code>moonshot/src/api/api_context_strategy.py</code> <pre><code>def api_get_all_context_strategy_metadata() -&gt; list:\n    \"\"\"\n    Retrieves metadata for all context strategy modules.\n\n    This function retrieves the metadata for all available context strategies and\n    returns a list of metadata dictionaries.\n\n    Returns:\n        list: A list of attack module metadata.\n    \"\"\"\n\n    return [\n        ContextStrategy.load(context_strategy_name).get_metadata()  # type: ignore ; ducktyping\n        for context_strategy_name in ContextStrategy.get_all_context_strategies()\n    ]\n</code></pre>"},{"location":"api_reference/api_cookbook/","title":"Cookbook API","text":""},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_create_cookbook","title":"<code>api_create_cookbook(name, description, recipes)</code>","text":"<p>Creates a new cookbook.</p> <p>This function takes the name, description, and recipes for a new cookbook as input. It then creates a new CookbookArguments object with these details and an empty id. The id is left empty because it will be generated from the name during the creation process. The function then calls the Cookbook's create_cookbook method to create the new cookbook.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new cookbook.</p> required <code>description</code> <code>str</code> <p>A brief description of the new cookbook.</p> required <code>recipes</code> <code>list[str]</code> <p>A list of recipes to be included in the new cookbook.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created cookbook.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_create_cookbook(name: str, description: str, recipes: list[str]) -&gt; str:\n    \"\"\"\n    Creates a new cookbook.\n\n    This function takes the name, description, and recipes for a new cookbook as input. It then creates a new\n    CookbookArguments object with these details and an empty id. The id is left empty because it will be generated\n    from the name during the creation process. The function then calls the Cookbook's create_cookbook method to\n    create the new cookbook.\n\n    Args:\n        name (str): The name of the new cookbook.\n        description (str): A brief description of the new cookbook.\n        recipes (list[str]): A list of recipes to be included in the new cookbook.\n\n    Returns:\n        str: The ID of the newly created cookbook.\n    \"\"\"\n    # Create a new cookbook\n    # We do not need to provide the id.\n    # This is because during creation:\n    # 1. the id is slugify from the name and stored as id.\n    cb_args = CookbookArguments(\n        id=\"\",\n        name=name,\n        description=description,\n        recipes=recipes,\n    )\n    return Cookbook.create(cb_args)\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_delete_cookbook","title":"<code>api_delete_cookbook(cb_id)</code>","text":"<p>Deletes a cookbook based on the provided cookbook ID.</p> <p>This function calls the <code>delete</code> method of the <code>Cookbook</code> class with the given cookbook ID. If the cookbook is successfully deleted, the method returns True, otherwise it returns False.</p> <p>Parameters:</p> Name Type Description Default <code>cb_id</code> <code>str</code> <p>The ID of the cookbook to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the cookbook was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_delete_cookbook(cb_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a cookbook based on the provided cookbook ID.\n\n    This function calls the `delete` method of the `Cookbook` class with the given cookbook ID. If the cookbook\n    is successfully deleted, the method returns True, otherwise it returns False.\n\n    Args:\n        cb_id (str): The ID of the cookbook to delete.\n\n    Returns:\n        bool: True if the cookbook was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Cookbook.delete(cb_id)\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_get_all_cookbook","title":"<code>api_get_all_cookbook()</code>","text":"<p>Retrieves all available cookbooks.</p> <p>This function calls the <code>get_available_cookbooks</code> method of the <code>Cookbook</code> class, which returns a tuple containing a list of cookbook IDs and a list of <code>CookbookArguments</code> objects. The function then returns a list of dictionaries, each representing a cookbook.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a cookbook.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>def api_get_all_cookbook() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available cookbooks.\n\n    This function calls the `get_available_cookbooks` method of the `Cookbook` class, which returns a tuple\n    containing a list of cookbook IDs and a list of `CookbookArguments` objects. The function then returns a list\n    of dictionaries, each representing a cookbook.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a cookbook.\n    \"\"\"\n    _, cookbooks = Cookbook.get_available_items()\n    return [cookbook.to_dict() for cookbook in cookbooks]\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_get_all_cookbook_name","title":"<code>api_get_all_cookbook_name()</code>","text":"<p>Retrieves the names of all available cookbooks.</p> <p>This function calls the <code>get_available_cookbooks</code> method of the <code>Cookbook</code> class, which returns a tuple containing a list of cookbook IDs and a list of <code>CookbookArguments</code> objects. The function then returns the list of cookbook IDs, which are the names of the cookbooks.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of cookbook names.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>def api_get_all_cookbook_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves the names of all available cookbooks.\n\n    This function calls the `get_available_cookbooks` method of the `Cookbook` class, which returns a tuple\n    containing a list of cookbook IDs and a list of `CookbookArguments` objects. The function then returns the\n    list of cookbook IDs, which are the names of the cookbooks.\n\n    Returns:\n        list[str]: A list of cookbook names.\n    \"\"\"\n    cookbooks_names, _ = Cookbook.get_available_items()\n    return cookbooks_names\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_read_cookbook","title":"<code>api_read_cookbook(cb_id)</code>","text":"<p>Retrieves a cookbook based on the provided cookbook ID.</p> <p>This function reads a cookbook using the <code>read_cookbook</code> method of the <code>Cookbook</code> class, and converts the returned <code>Cookbook</code> object to a dictionary using its <code>to_dict</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>cb_id</code> <code>str</code> <p>A cookbook ID.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representing a cookbook.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_read_cookbook(cb_id: str) -&gt; dict:\n    \"\"\"\n    Retrieves a cookbook based on the provided cookbook ID.\n\n    This function reads a cookbook using the `read_cookbook` method\n    of the `Cookbook` class, and converts the returned `Cookbook` object to a dictionary using its `to_dict` method.\n\n    Args:\n        cb_id (str): A cookbook ID.\n\n    Returns:\n        dict: A dictionary representing a cookbook.\n    \"\"\"\n    return Cookbook.read(cb_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_read_cookbooks","title":"<code>api_read_cookbooks(cb_ids)</code>","text":"<p>Retrieves a list of cookbooks based on the provided list of cookbook IDs.</p> <p>This function iterates over the list of provided cookbook IDs, reads each cookbook using the <code>read_cookbook</code> method of the <code>Cookbook</code> class, and converts the returned <code>Cookbook</code> objects to dictionaries using their <code>to_dict</code> method. It then returns a list of these dictionary representations.</p> <p>Parameters:</p> Name Type Description Default <code>cb_ids</code> <code>conlist(str, min_length=1</code> <p>A list of cookbook IDs.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries representing the cookbooks.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_read_cookbooks(cb_ids: conlist(str, min_length=1)) -&gt; list[dict]:\n    \"\"\"\n    Retrieves a list of cookbooks based on the provided list of cookbook IDs.\n\n    This function iterates over the list of provided cookbook IDs, reads each cookbook using the `read_cookbook` method\n    of the `Cookbook` class, and converts the returned `Cookbook` objects to dictionaries using their `to_dict` method.\n    It then returns a list of these dictionary representations.\n\n    Args:\n        cb_ids (conlist(str, min_length=1)): A list of cookbook IDs.\n\n    Returns:\n        list[dict]: A list of dictionaries representing the cookbooks.\n    \"\"\"\n    return [Cookbook.read(cb_id).to_dict() for cb_id in cb_ids]\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_update_cookbook","title":"<code>api_update_cookbook(cb_id, **kwargs)</code>","text":"<p>Updates the fields of an existing cookbook with the provided keyword arguments.</p> <p>This function first checks if the cookbook with the given ID exists. If it does, it updates the fields of the cookbook with the provided keyword arguments. If a field does not exist on the cookbook, it is ignored. After updating the fields, it persists the changes to the cookbook.</p> <p>Parameters:</p> Name Type Description Default <code>cb_id</code> <code>str</code> <p>The ID of the cookbook to update.</p> required <code>**kwargs</code> <p>Arbitrary keyword arguments representing the fields to update and their new values.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the cookbook was successfully updated.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error during the update process.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_update_cookbook(cb_id: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Updates the fields of an existing cookbook with the provided keyword arguments.\n\n    This function first checks if the cookbook with the given ID exists. If it does, it updates the fields\n    of the cookbook with the provided keyword arguments. If a field does not exist on the cookbook, it is ignored.\n    After updating the fields, it persists the changes to the cookbook.\n\n    Args:\n        cb_id (str): The ID of the cookbook to update.\n        **kwargs: Arbitrary keyword arguments representing the fields to update and their new values.\n\n    Returns:\n        bool: True if the cookbook was successfully updated.\n\n    Raises:\n        Exception: If there's an error during the update process.\n    \"\"\"\n    # Check if the cookbook exists\n    try:\n        existing_cookbook = Cookbook.read(cb_id)\n    except Exception:\n        raise RuntimeError(f\"Cookbook with ID '{cb_id}' does not exist\")\n\n    # Update the fields of the existing cookbook with the provided kwargs\n    for key, value in kwargs.items():\n        if hasattr(existing_cookbook, key):\n            setattr(existing_cookbook, key, value)\n\n    # Perform pydantic check on the updated existing cookbook\n    CookbookArguments.model_validate(existing_cookbook.to_dict())\n\n    # Update the cookbook\n    return Cookbook.update(existing_cookbook)\n</code></pre>"},{"location":"api_reference/api_dataset/","title":"Dataset API","text":""},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_delete_dataset","title":"<code>api_delete_dataset(ds_id)</code>","text":"<p>Deletes a dataset identified by its unique dataset ID.</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>The unique identifier for the dataset to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the dataset was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>@validate_call\ndef api_delete_dataset(ds_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a dataset identified by its unique dataset ID.\n\n    Args:\n        ds_id (str): The unique identifier for the dataset to be deleted.\n\n    Returns:\n        bool: True if the dataset was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Dataset.delete(ds_id)\n</code></pre>"},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_get_all_datasets","title":"<code>api_get_all_datasets()</code>","text":"<p>This function retrieves all available datasets and returns them as a list of dictionaries. Each dictionary represents a result and contains its information.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a result.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>def api_get_all_datasets() -&gt; list[dict]:\n    \"\"\"\n    This function retrieves all available datasets and returns them as a list of dictionaries. Each dictionary\n    represents a result and contains its information.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a result.\n    \"\"\"\n    _, datasets = Dataset.get_available_items()\n    return [dataset.to_dict() for dataset in datasets]\n</code></pre>"},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_get_all_datasets_name","title":"<code>api_get_all_datasets_name()</code>","text":"<p>This function retrieves all available datasets names and returns them as a list.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of datasets names.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>def api_get_all_datasets_name() -&gt; list[str]:\n    \"\"\"\n    This function retrieves all available datasets names and returns them as a list.\n\n    Returns:\n        list[str]: A list of datasets names.\n    \"\"\"\n    datasets_name, _ = Dataset.get_available_items()\n    return datasets_name\n</code></pre>"},{"location":"api_reference/api_environment_variables/","title":"Environment Variable API","text":""},{"location":"api_reference/api_environment_variables/#moonshot.src.api.api_environment_variables.api_set_environment_variables","title":"<code>api_set_environment_variables(env_vars)</code>","text":"<p>Sets the environment variables for the current session.</p> <p>Parameters:</p> Name Type Description Default <code>env_vars</code> <code>dict</code> <p>A dictionary containing the environment variables to set.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>moonshot/src/api/api_environment_variables.py</code> <pre><code>def api_set_environment_variables(env_vars: dict) -&gt; None:\n    \"\"\"\n    Sets the environment variables for the current session.\n\n    Args:\n        env_vars (dict): A dictionary containing the environment variables to set.\n\n    Returns:\n        None\n    \"\"\"\n    EnvironmentVars.load_env(env_vars)\n</code></pre>"},{"location":"api_reference/api_metrics/","title":"Metric API","text":""},{"location":"api_reference/api_metrics/#moonshot.src.api.api_metrics.api_delete_metric","title":"<code>api_delete_metric(met_id)</code>","text":"<p>Deletes a metric identified by its unique metric ID.</p> <p>Parameters:</p> Name Type Description Default <code>met_id</code> <code>str</code> <p>The unique identifier for the metric to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the metric was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_metrics.py</code> <pre><code>@validate_call\ndef api_delete_metric(met_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a metric identified by its unique metric ID.\n\n    Args:\n        met_id (str): The unique identifier for the metric to be deleted.\n\n    Returns:\n        bool: True if the metric was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Metric.delete(met_id)\n</code></pre>"},{"location":"api_reference/api_metrics/#moonshot.src.api.api_metrics.api_get_all_metric","title":"<code>api_get_all_metric()</code>","text":"<p>Retrieves all available metrics.</p> <p>This function calls the get_available_items method from the Metric class to retrieve all available metrics. It then returns a list of dictionaries, each containing the details of a metric.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a metric's details.</p> Source code in <code>moonshot/src/api/api_metrics.py</code> <pre><code>def api_get_all_metric() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available metrics.\n\n    This function calls the get_available_items method from the Metric class to retrieve all available metrics.\n    It then returns a list of dictionaries, each containing the details of a metric.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a metric's details.\n    \"\"\"\n    _, metrics_info = Metric.get_available_items()\n    return metrics_info\n</code></pre>"},{"location":"api_reference/api_metrics/#moonshot.src.api.api_metrics.api_get_all_metric_name","title":"<code>api_get_all_metric_name()</code>","text":"<p>Retrieves all available metric names.</p> <p>This function calls the get_available_items method from the Metric class to retrieve all available metrics. It then extracts the names of each metric and returns a list of these names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing a metric name.</p> Source code in <code>moonshot/src/api/api_metrics.py</code> <pre><code>def api_get_all_metric_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available metric names.\n\n    This function calls the get_available_items method from the Metric class to retrieve all available metrics.\n    It then extracts the names of each metric and returns a list of these names.\n\n    Returns:\n        list[str]: A list of strings, each representing a metric name.\n    \"\"\"\n    metrics_names, _ = Metric.get_available_items()\n    return metrics_names\n</code></pre>"},{"location":"api_reference/api_prompt_template/","title":"Prompt Template API","text":""},{"location":"api_reference/api_prompt_template/#moonshot.src.api.api_prompt_template.api_delete_prompt_template","title":"<code>api_delete_prompt_template(pt_id)</code>","text":"<p>Deletes a prompt template by its identifier.</p> <p>Parameters:</p> Name Type Description Default <code>pt_id</code> <code>str</code> <p>The unique identifier of the prompt template to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the prompt template was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_prompt_template.py</code> <pre><code>@validate_call\ndef api_delete_prompt_template(pt_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a prompt template by its identifier.\n\n    Args:\n        pt_id (str): The unique identifier of the prompt template to be deleted.\n\n    Returns:\n        bool: True if the prompt template was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return PromptTemplate.delete(pt_id)\n</code></pre>"},{"location":"api_reference/api_prompt_template/#moonshot.src.api.api_prompt_template.api_get_all_prompt_template_detail","title":"<code>api_get_all_prompt_template_detail()</code>","text":"<p>Retrieves all available prompt template details and returns them as a list of dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing the details of a prompt template.</p> Source code in <code>moonshot/src/api/api_prompt_template.py</code> <pre><code>def api_get_all_prompt_template_detail() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available prompt template details and returns them as a list of dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing the details of a prompt template.\n    \"\"\"\n    return PromptTemplate.get_all_prompt_template_details()\n</code></pre>"},{"location":"api_reference/api_prompt_template/#moonshot.src.api.api_prompt_template.api_get_all_prompt_template_name","title":"<code>api_get_all_prompt_template_name()</code>","text":"<p>Retrieves all available prompt template names and returns them as a list.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of prompt template names.</p> Source code in <code>moonshot/src/api/api_prompt_template.py</code> <pre><code>def api_get_all_prompt_template_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available prompt template names and returns them as a list.\n\n    Returns:\n        list[str]: A list of prompt template names.\n    \"\"\"\n    return PromptTemplate.get_all_prompt_template_names()\n</code></pre>"},{"location":"api_reference/api_recipe/","title":"Recipe API","text":""},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_create_recipe","title":"<code>api_create_recipe(name, description, tags, categories, datasets, prompt_templates, metrics, attack_modules, grading_scale)</code>","text":"<p>Creates a new recipe with the given parameters.</p> <p>This function takes various parameters that define a recipe, creates a RecipeArguments object with these parameters, and then calls the Recipe.create method to create a new recipe in the system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the recipe.</p> required <code>description</code> <code>str</code> <p>A description of the recipe.</p> required <code>tags</code> <code>list[str]</code> <p>A list of tags associated with the recipe.</p> required <code>categories</code> <code>list[str]</code> <p>A list of categories the recipe belongs to.</p> required <code>datasets</code> <code>list[str]</code> <p>A list of datasets used in the recipe.</p> required <code>prompt_templates</code> <code>list[str]</code> <p>A list of prompt templates for the recipe.</p> required <code>metrics</code> <code>list[str]</code> <p>A list of metrics to evaluate the recipe.</p> required <code>attack_modules</code> <code>list[str]</code> <p>A list of attack modules used in the recipe.</p> required <code>grading_scale</code> <code>dict[str, list[int]]</code> <p>A grading scale dictionary where the key is the grade and the</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created recipe.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_create_recipe(\n    name: str,\n    description: str,\n    tags: list[str],\n    categories: list[str],\n    datasets: list[str],\n    prompt_templates: list[str],\n    metrics: list[str],\n    attack_modules: list[str],\n    grading_scale: dict[str, list[int]],\n) -&gt; str:\n    \"\"\"\n    Creates a new recipe with the given parameters.\n\n    This function takes various parameters that define a recipe, creates a RecipeArguments\n    object with these parameters, and then calls the Recipe.create method to create a new\n    recipe in the system.\n\n    Args:\n        name (str): The name of the recipe.\n        description (str): A description of the recipe.\n        tags (list[str]): A list of tags associated with the recipe.\n        categories (list[str]): A list of categories the recipe belongs to.\n        datasets (list[str]): A list of datasets used in the recipe.\n        prompt_templates (list[str]): A list of prompt templates for the recipe.\n        metrics (list[str]): A list of metrics to evaluate the recipe.\n        attack_modules (list[str]): A list of attack modules used in the recipe.\n        grading_scale (dict[str, list[int]]): A grading scale dictionary where the key is the grade and the\n        value is a list of integers representing the scale.\n\n    Returns:\n        str: The ID of the newly created recipe.\n    \"\"\"\n    rec_args = RecipeArguments(\n        id=\"\",\n        name=name,\n        description=description,\n        tags=tags,\n        categories=categories,\n        datasets=datasets,\n        prompt_templates=prompt_templates,\n        metrics=metrics,\n        attack_modules=attack_modules,\n        grading_scale=grading_scale,\n    )\n    return Recipe.create(rec_args)\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_delete_recipe","title":"<code>api_delete_recipe(rec_id)</code>","text":"<p>Deletes a recipe identified by its unique recipe ID.</p> <p>This function takes a recipe ID, verifies the existence of the recipe, and if found, calls the delete method from the Recipe class to remove the recipe from storage.</p> <p>If the deletion is successful, it returns True. If the recipe does not exist or an exception occurs during deletion, a RuntimeError is raised with an appropriate error message.</p> <p>Parameters:</p> Name Type Description Default <code>rec_id</code> <code>str</code> <p>The unique identifier for the recipe to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the recipe was successfully deleted.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_delete_recipe(rec_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a recipe identified by its unique recipe ID.\n\n    This function takes a recipe ID, verifies the existence of the recipe, and if found, calls the delete method from\n    the Recipe class to remove the recipe from storage.\n\n    If the deletion is successful, it returns True.\n    If the recipe does not exist or an exception occurs during deletion, a RuntimeError is raised with an\n    appropriate error message.\n\n    Args:\n        rec_id (str): The unique identifier for the recipe to be deleted.\n\n    Returns:\n        bool: True if the recipe was successfully deleted.\n\n    Raises:\n        RuntimeError: If the deletion process encounters an error.\n    \"\"\"\n    return Recipe.delete(rec_id)\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_get_all_recipe","title":"<code>api_get_all_recipe()</code>","text":"<p>Retrieves all available recipes.</p> <p>This function calls the get_available_recipes method to retrieve all available recipes. It then converts each recipe into a dictionary using the to_dict method and returns a list of these dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a recipe.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>def api_get_all_recipe() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available recipes.\n\n    This function calls the get_available_recipes method to retrieve all available recipes. It then converts each\n    recipe into a dictionary using the to_dict method and returns a list of these dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a recipe.\n    \"\"\"\n    _, recipes = Recipe.get_available_items()\n    return [recipe.to_dict() for recipe in recipes]\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_get_all_recipe_name","title":"<code>api_get_all_recipe_name()</code>","text":"<p>Retrieves all available recipe names.</p> <p>This function calls the get_available_recipes method to retrieve all available recipes. It then extracts the names of each recipe and returns a list of these names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing a recipe name.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>def api_get_all_recipe_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available recipe names.\n\n    This function calls the get_available_recipes method to retrieve all available recipes. It then extracts the names\n    of each recipe and returns a list of these names.\n\n    Returns:\n        list[str]: A list of strings, each representing a recipe name.\n    \"\"\"\n    recipes_names, _ = Recipe.get_available_items()\n    return recipes_names\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_read_recipe","title":"<code>api_read_recipe(rec_id)</code>","text":"<p>Reads a recipe and returns its information.</p> <p>This function takes a recipe ID as input, reads the corresponding recipe, and returns a dictionary containing the recipe's information.</p> <p>Parameters:</p> Name Type Description Default <code>rec_id</code> <code>str</code> <p>The ID of the recipe.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the recipe's information.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_read_recipe(rec_id: str) -&gt; dict:\n    \"\"\"\n    Reads a recipe and returns its information.\n\n    This function takes a recipe ID as input, reads the corresponding recipe,\n    and returns a dictionary containing the recipe's information.\n\n    Args:\n        rec_id (str): The ID of the recipe.\n\n    Returns:\n        dict: A dictionary containing the recipe's information.\n    \"\"\"\n    return Recipe.read(rec_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_read_recipes","title":"<code>api_read_recipes(rec_ids)</code>","text":"<p>Reads multiple recipes and returns their information.</p> <p>This function takes a list of recipe IDs as input, reads the corresponding recipes, and returns a list of dictionaries containing each recipe's information.</p> <p>Parameters:</p> Name Type Description Default <code>rec_ids</code> <code>list[str]</code> <p>The IDs of the recipes.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each containing a recipe's information.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_read_recipes(rec_ids: conlist(str, min_length=1)) -&gt; list[dict]:\n    \"\"\"\n    Reads multiple recipes and returns their information.\n\n    This function takes a list of recipe IDs as input, reads the corresponding recipes,\n    and returns a list of dictionaries containing each recipe's information.\n\n    Args:\n        rec_ids (list[str]): The IDs of the recipes.\n\n    Returns:\n        list[dict]: A list of dictionaries, each containing a recipe's information.\n    \"\"\"\n    # This function uses list comprehension to iterate over the list of recipe IDs,\n    # calling the read_recipe method for each ID and converting the result to a dictionary.\n    # The resulting list of dictionaries is then returned.\n    return [Recipe.read(rec_id).to_dict() for rec_id in rec_ids]\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_update_recipe","title":"<code>api_update_recipe(rec_id, **kwargs)</code>","text":"<p>Updates a recipe with the given keyword arguments.</p> <p>This function takes a recipe ID and arbitrary keyword arguments, checks if the recipe exists, and updates the fields of the recipe with the provided values. If the recipe does not exist, a RuntimeError is raised. If the update is successful, it returns True.</p> <p>Parameters:</p> Name Type Description Default <code>rec_id</code> <code>str</code> <p>The ID of the recipe to update.</p> required <code>**kwargs</code> <p>Arbitrary keyword arguments representing the fields to update.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the recipe was successfully updated.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the recipe with the given ID does not exist.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_update_recipe(rec_id: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Updates a recipe with the given keyword arguments.\n\n    This function takes a recipe ID and arbitrary keyword arguments, checks if the recipe exists,\n    and updates the fields of the recipe with the provided values. If the recipe does not exist,\n    a RuntimeError is raised. If the update is successful, it returns True.\n\n    Args:\n        rec_id (str): The ID of the recipe to update.\n        **kwargs: Arbitrary keyword arguments representing the fields to update.\n\n    Returns:\n        bool: True if the recipe was successfully updated.\n\n    Raises:\n        RuntimeError: If the recipe with the given ID does not exist.\n    \"\"\"\n    # Check if the recipe exists\n    try:\n        existing_recipe = Recipe.read(rec_id)\n    except Exception:\n        raise RuntimeError(f\"Recipe with ID '{rec_id}' does not exist\")\n\n    # Update the fields of the existing recipe with the provided kwargs\n    for key, value in kwargs.items():\n        if hasattr(existing_recipe, key):\n            setattr(existing_recipe, key, value)\n\n    # Perform pydantic check on the updated existing recipe\n    RecipeArguments.model_validate(existing_recipe.to_dict())\n\n    # Update the recipe\n    return Recipe.update(existing_recipe)\n</code></pre>"},{"location":"api_reference/api_red_teaming/","title":"Red Teaming API","text":""},{"location":"api_reference/api_red_teaming/#moonshot.src.api.api_red_teaming.api_delete_attack_module","title":"<code>api_delete_attack_module(am_id)</code>","text":"<p>Deletes an attack module by its identifier.</p> <p>This function takes an attack module ID as input and calls the delete method from the AttackModule class to remove the specified attack module from storage.</p> <p>Parameters:</p> Name Type Description Default <code>am_id</code> <code>str</code> <p>The unique identifier of the attack module to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the attack module was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_red_teaming.py</code> <pre><code>@validate_call\ndef api_delete_attack_module(am_id: str) -&gt; bool:\n    \"\"\"\n    Deletes an attack module by its identifier.\n\n    This function takes an attack module ID as input and calls the delete method from the AttackModule class\n    to remove the specified attack module from storage.\n\n    Args:\n        am_id (str): The unique identifier of the attack module to be deleted.\n\n    Returns:\n        bool: True if the attack module was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return AttackModule.delete(am_id)\n</code></pre>"},{"location":"api_reference/api_red_teaming/#moonshot.src.api.api_red_teaming.api_get_all_attack_module_metadata","title":"<code>api_get_all_attack_module_metadata()</code>","text":"<p>Retrieves metadata for all available attack modules.</p> <p>This function calls the <code>get_available_items</code> method from the <code>AttackModule</code> class to retrieve all available attack modules metadata.</p> <p>It then extracts the metadata for each attack module and returns a list of dictionaries, each containing the metadata of an attack module.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing the metadata of an attack module.</p> Source code in <code>moonshot/src/api/api_red_teaming.py</code> <pre><code>def api_get_all_attack_module_metadata() -&gt; list[dict]:\n    \"\"\"\n    Retrieves metadata for all available attack modules.\n\n    This function calls the `get_available_items` method from the `AttackModule` class to retrieve all available\n    attack modules metadata.\n\n    It then extracts the metadata for each attack module and returns a list of dictionaries, each containing the\n    metadata of an attack module.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing the metadata of an attack module.\n    \"\"\"\n    _, attack_modules_metadata = AttackModule.get_available_items()\n    return attack_modules_metadata\n</code></pre>"},{"location":"api_reference/api_red_teaming/#moonshot.src.api.api_red_teaming.api_get_all_attack_modules","title":"<code>api_get_all_attack_modules()</code>","text":"<p>Retrieves all available attack module IDs.</p> <p>This function calls the <code>get_available_items</code> method from the <code>AttackModule</code> class to retrieve all available attack modules.</p> <p>It then extracts the IDs of each attack module and returns a list of these IDs.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing an attack module ID.</p> Source code in <code>moonshot/src/api/api_red_teaming.py</code> <pre><code>def api_get_all_attack_modules() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available attack module IDs.\n\n    This function calls the `get_available_items` method from the `AttackModule` class to retrieve all available\n    attack modules.\n\n    It then extracts the IDs of each attack module and returns a list of these IDs.\n\n    Returns:\n        list[str]: A list of strings, each representing an attack module ID.\n    \"\"\"\n    attack_modules_ids, _ = AttackModule.get_available_items()\n    return attack_modules_ids\n</code></pre>"},{"location":"api_reference/api_result/","title":"Result API","text":""},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_delete_result","title":"<code>api_delete_result(res_id)</code>","text":"<p>Deletes a result by its identifier.</p> <p>This function takes a result ID as input and calls the delete method from the Result class to remove the specified result from storage.</p> <p>Parameters:</p> Name Type Description Default <code>res_id</code> <code>str</code> <p>The unique identifier of the result to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the result was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>@validate_call\ndef api_delete_result(res_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a result by its identifier.\n\n    This function takes a result ID as input and calls the delete method from the Result class\n    to remove the specified result from storage.\n\n    Args:\n        res_id (str): The unique identifier of the result to be deleted.\n\n    Returns:\n        bool: True if the result was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Result.delete(res_id)\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_get_all_result","title":"<code>api_get_all_result()</code>","text":"<p>This function retrieves all available results and returns them as a list of dictionaries. Each dictionary represents a result and contains its information.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a result.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>def api_get_all_result() -&gt; list[dict]:\n    \"\"\"\n    This function retrieves all available results and returns them as a list of dictionaries. Each dictionary\n    represents a result and contains its information.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a result.\n    \"\"\"\n    _, results = Result.get_available_items()\n    return [result for result in results]\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_get_all_result_name","title":"<code>api_get_all_result_name()</code>","text":"<p>This function retrieves all available result names and returns them as a list.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of result names.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>def api_get_all_result_name() -&gt; list[str]:\n    \"\"\"\n    This function retrieves all available result names and returns them as a list.\n\n    Returns:\n        list[str]: A list of result names.\n    \"\"\"\n    results_name, _ = Result.get_available_items()\n    return results_name\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_read_result","title":"<code>api_read_result(res_id)</code>","text":"<p>Reads a result and returns its information.</p> <p>This function takes a result ID as input, reads the corresponding database file from the storage manager, and returns a dictionary containing the result's information.</p> <p>Parameters:</p> Name Type Description Default <code>res_id</code> <code>str</code> <p>The ID of the result.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the result's information.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>@validate_call\ndef api_read_result(res_id: str) -&gt; dict:\n    \"\"\"\n    Reads a result and returns its information.\n\n    This function takes a result ID as input, reads the corresponding database file from the storage manager,\n    and returns a dictionary containing the result's information.\n\n    Args:\n        res_id (str): The ID of the result.\n\n    Returns:\n        dict: A dictionary containing the result's information.\n    \"\"\"\n    return Result.read(res_id)\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_read_results","title":"<code>api_read_results(res_ids)</code>","text":"<p>Reads multiple results and returns their information.</p> <p>This function takes a list of result IDs as input, reads the corresponding database files from the storage manager, and returns a list of dictionaries, each containing a result's information.</p> <p>Parameters:</p> Name Type Description Default <code>res_ids</code> <code>conlist(str, min_length=1</code> <p>A list of result IDs.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each containing a result's information.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>@validate_call\ndef api_read_results(res_ids: conlist(str, min_length=1)) -&gt; list[dict]:\n    \"\"\"\n    Reads multiple results and returns their information.\n\n    This function takes a list of result IDs as input, reads the corresponding database files from the storage manager,\n    and returns a list of dictionaries, each containing a result's information.\n\n    Args:\n        res_ids (conlist(str, min_length=1)): A list of result IDs.\n\n    Returns:\n        list[dict]: A list of dictionaries, each containing a result's information.\n    \"\"\"\n\n    return [Result.read(res_id) for res_id in res_ids]\n</code></pre>"},{"location":"api_reference/api_run/","title":"Run API","text":""},{"location":"api_reference/api_run/#moonshot.src.api.api_run.api_get_all_run","title":"<code>api_get_all_run(runner_id='')</code>","text":"<p>Retrieves all runs for a given runner ID or for all runners if no ID is provided.</p> <p>This function calls an internal API to get available runs and then converts each run into a dictionary format.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner to retrieve runs for. If empty, runs for all runners</p> <code>''</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a run's data.</p> Source code in <code>moonshot/src/api/api_run.py</code> <pre><code>def api_get_all_run(runner_id: str = \"\") -&gt; list[dict]:\n    \"\"\"\n    Retrieves all runs for a given runner ID or for all runners if no ID is provided.\n\n    This function calls an internal API to get available runs and then converts each run into a dictionary format.\n\n    Args:\n        runner_id (str, optional): The ID of the runner to retrieve runs for. If empty, runs for all runners\n        are retrieved.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a run's data.\n    \"\"\"\n    _, runs = _api_get_available_runs(runner_id)\n    return [run.to_dict() for run in runs]\n</code></pre>"},{"location":"api_reference/api_runner/","title":"Runner API","text":""},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_create_runner","title":"<code>api_create_runner(name, endpoints, description='', progress_callback_func=None)</code>","text":"<p>Creates a new runner.</p> <p>This function takes the name, endpoints, and an optional progress callback function to create a new Runner instance. The id of the runner is generated from the name of the runner using the slugify function, so it does not need to be provided.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the runner.</p> required <code>endpoints</code> <code>list[str]</code> <p>A list of endpoint identifiers for the runner.</p> required <code>description</code> <code>str</code> <p>A brief description of the runner. Defaults to an empty string.</p> <code>''</code> <code>progress_callback_func</code> <code>Callable | None</code> <p>An optional callback function for progress updates.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Runner</code> <code>Runner</code> <p>A new Runner object.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_create_runner(\n    name: str,\n    endpoints: list[str],\n    description: str = \"\",\n    progress_callback_func: Callable | None = None,\n) -&gt; Runner:\n    \"\"\"\n    Creates a new runner.\n\n    This function takes the name, endpoints, and an optional progress callback function to create a new Runner instance.\n    The id of the runner is generated from the name of the runner using the slugify function,\n    so it does not need to be provided.\n\n    Args:\n        name (str): The name of the runner.\n        endpoints (list[str]): A list of endpoint identifiers for the runner.\n        description (str, optional): A brief description of the runner. Defaults to an empty string.\n        progress_callback_func (Callable | None, optional): An optional callback function for progress updates.\n        Defaults to None.\n\n    Returns:\n        Runner: A new Runner object.\n    \"\"\"\n    # Create a new recipe runner\n    # We do not need to provide the id.\n    # This is because during creating:\n    # 1. the id is slugify from the name and stored as id.\n    runner_args = RunnerArguments(\n        id=\"\",\n        name=name,\n        endpoints=endpoints,\n        description=description,\n        progress_callback_func=progress_callback_func,\n    )\n    return Runner.create(runner_args)\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_delete_runner","title":"<code>api_delete_runner(runner_id)</code>","text":"<p>Deletes a runner by its identifier.</p> <p>This function takes a runner ID as input and calls the delete method from the Runner class to remove the specified runner from storage.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the runner was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_delete_runner(runner_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a runner by its identifier.\n\n    This function takes a runner ID as input and calls the delete method from the Runner class\n    to remove the specified runner from storage.\n\n    Args:\n        runner_id (str): The unique identifier of the runner to be deleted.\n\n    Returns:\n        bool: True if the runner was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Runner.delete(runner_id)\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_get_all_runner","title":"<code>api_get_all_runner()</code>","text":"<p>Retrieves all available runners.</p> <p>This function calls the get_available_items method to retrieve all available runners. It then converts each runner into a dictionary using the to_dict method and returns a list of these dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a runner.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>def api_get_all_runner() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available runners.\n\n    This function calls the get_available_items method to retrieve all available runners. It then converts each\n    runner into a dictionary using the to_dict method and returns a list of these dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a runner.\n    \"\"\"\n    _, runners = Runner.get_available_items()\n    return [runner.to_dict() for runner in runners]\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_get_all_runner_name","title":"<code>api_get_all_runner_name()</code>","text":"<p>Retrieves all available runner names.</p> <p>This function calls the get_available_items method to retrieve all available runners. It then extracts the names of each runner and returns a list of these names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of runner names.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>def api_get_all_runner_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available runner names.\n\n    This function calls the get_available_items method to retrieve all available runners. It then extracts the names of\n    each runner and returns a list of these names.\n\n    Returns:\n        list[str]: A list of runner names.\n    \"\"\"\n    runners_names, _ = Runner.get_available_items()\n    return runners_names\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_load_runner","title":"<code>api_load_runner(runner_id, progress_callback_func=None)</code>","text":"<p>Loads a runner based on the provided runner ID.</p> <p>This function retrieves the runner using the provided runner ID and then loads it. It utilizes the Runner's load method to fetch and return the runner.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner to be loaded.</p> required <code>progress_callback_func</code> <code>Callable | None</code> <p>The progress callback function to be used by the runner.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Runner</code> <code>Runner</code> <p>An initialized Runner object.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_load_runner(\n    runner_id: str, progress_callback_func: Callable | None = None\n) -&gt; Runner:\n    \"\"\"\n    Loads a runner based on the provided runner ID.\n\n    This function retrieves the runner using the provided runner ID and then loads it.\n    It utilizes the Runner's load method to fetch and return the runner.\n\n    Args:\n        runner_id (str): The ID of the runner to be loaded.\n        progress_callback_func (Callable | None): The progress callback function to be used by the runner.\n\n    Returns:\n        Runner: An initialized Runner object.\n    \"\"\"\n    return Runner.load(runner_id, progress_callback_func)\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_read_runner","title":"<code>api_read_runner(runner_id)</code>","text":"<p>Reads a runner and returns its information.</p> <p>This function takes a runner ID as input, reads the corresponding runner, and returns a dictionary containing the runner's information.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the runner's information.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_read_runner(runner_id: str) -&gt; dict:\n    \"\"\"\n    Reads a runner and returns its information.\n\n    This function takes a runner ID as input, reads the corresponding runner,\n    and returns a dictionary containing the runner's information.\n\n    Args:\n        runner_id (str): The ID of the runner.\n\n    Returns:\n        dict: A dictionary containing the runner's information.\n    \"\"\"\n    return Runner.read(runner_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_session/","title":"Session API","text":""},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_create_session","title":"<code>api_create_session(runner_id, database_instance, endpoints, runner_args)</code>","text":"<p>Creates a new session for a specific runner.</p> <p>This function creates a new session by calling the <code>Session</code> constructor with the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner for which the session is to be created.</p> required <code>database_instance</code> <code>Any</code> <p>The database instance to be used for the session.</p> required <code>endpoints</code> <code>list</code> <p>A list of endpoints for the session.</p> required <code>runner_args</code> <code>dict</code> <p>A dictionary of arguments for the runner.</p> required <p>Returns:</p> Type Description <code>Session</code> <p>Session</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_create_session(\n    runner_id: str, database_instance: Any, endpoints: list[str], runner_args: dict\n) -&gt; Session:\n    \"\"\"\n    Creates a new session for a specific runner.\n\n    This function creates a new session by calling the `Session` constructor with the provided arguments.\n\n    Args:\n        runner_id (str): The unique identifier of the runner for which the session is to be created.\n        database_instance (Any): The database instance to be used for the session.\n        endpoints (list): A list of endpoints for the session.\n        runner_args (dict): A dictionary of arguments for the runner.\n\n    Returns:\n        Session\n    \"\"\"\n    if isinstance(database_instance, DBInterface):\n        if runner_id:\n            session_instance = Session(\n                runner_id,\n                RunnerType.REDTEAM,\n                {**runner_args},\n                database_instance,\n                endpoints,\n                Storage.get_filepath(\n                    EnvVariables.RESULTS.name, runner_id, \"json\", True\n                ),\n            )\n            return session_instance\n        else:\n            raise RuntimeError(\n                \"[Session] Failed to initialise Session. String should have at least 1 character.\"\n            )\n    else:\n        raise RuntimeError(\n            \"[Session] Failed to initialise Session. No database instance provided.\"\n        )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_delete_session","title":"<code>api_delete_session(runner_id)</code>","text":"<p>Deletes the session for a specific runner.</p> <p>This function deletes the session for the runner identified by the given runner_id. It calls the <code>Session.delete</code> method with the runner's database instance.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the session needs to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the session is deleted successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_delete_session(runner_id: str) -&gt; bool:\n    \"\"\"\n    Deletes the session for a specific runner.\n\n    This function deletes the session for the runner identified by the given runner_id. It calls the\n    `Session.delete` method with the runner's database instance.\n\n    Args:\n        runner_id (str): The ID of the runner for which the session needs to be deleted.\n\n    Returns:\n        bool: The status on whether the session is deleted successfully.\n    \"\"\"\n    return Session.delete(api_load_runner(runner_id).database_instance)\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_all_chats_from_session","title":"<code>api_get_all_chats_from_session(runner_id)</code>","text":"<p>Retrieves all chat messages from a specific session.</p> <p>This function retrieves all chat messages from the session associated with the specified runner ID. It calls the <code>Session.get_session_chats</code> method with the runner's database instance.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner for which the chat messages are to be retrieved.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: A dictionary containing all chat messages if available, otherwise None.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_get_all_chats_from_session(runner_id: str) -&gt; dict | None:\n    \"\"\"\n    Retrieves all chat messages from a specific session.\n\n    This function retrieves all chat messages from the session associated with the specified runner ID.\n    It calls the `Session.get_session_chats` method with the runner's database instance.\n\n    Args:\n        runner_id (str): The unique identifier of the runner for which the chat messages are to be retrieved.\n\n    Returns:\n        dict | None: A dictionary containing all chat messages if available, otherwise None.\n    \"\"\"\n    return Session.get_session_chats(api_load_runner(runner_id).database_instance)\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_all_session_metadata","title":"<code>api_get_all_session_metadata()</code>","text":"<p>Retrieves metadata for all sessions.</p> <p>This function retrieves the metadata for all active sessions by calling the <code>api_get_available_session_info</code> method.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list</code> <p>A list containing the metadata for all active sessions, sorted by created datetime in descending order.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>def api_get_all_session_metadata() -&gt; list:\n    \"\"\"\n    Retrieves metadata for all sessions.\n\n    This function retrieves the metadata for all active sessions by calling the `api_get_available_session_info` method.\n\n    Returns:\n        list: A list containing the metadata for all active sessions, sorted by created datetime in descending order.\n    \"\"\"\n    _, session_metadata_list = api_get_available_session_info()\n    return sorted(\n        session_metadata_list, key=itemgetter(\"created_datetime\"), reverse=True\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_all_session_names","title":"<code>api_get_all_session_names()</code>","text":"<p>Retrieves a list of all session names.</p> <p>This function calls the <code>api_get_available_session_info</code> method to obtain the available session information and returns a list of session names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each denoting a session name.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>def api_get_all_session_names() -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of all session names.\n\n    This function calls the `api_get_available_session_info` method to obtain the available session information\n    and returns a list of session names.\n\n    Returns:\n        list[str]: A list of strings, each denoting a session name.\n    \"\"\"\n    session_names, _ = api_get_available_session_info()\n    return session_names\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_available_session_info","title":"<code>api_get_available_session_info()</code>","text":"<p>Retrieves the IDs and database instances of runners with active sessions.</p> <p>This function retrieves the IDs and database instances of runners with active sessions by querying all runners and checking if each runner has an active session. It returns a tuple containing a list of runner IDs and a list of corresponding session metadata for runners with active sessions.</p> <p>Returns:</p> Type Description <code>list</code> <p>tuple[list[str], list[str]]: A tuple containing a list of runner IDs and a list of corresponding session</p> <code>list</code> <p>metadata for runners with active sessions.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>def api_get_available_session_info() -&gt; tuple[list, list]:\n    \"\"\"\n    Retrieves the IDs and database instances of runners with active sessions.\n\n    This function retrieves the IDs and database instances of runners with active sessions by querying all runners\n    and checking if each runner has an active session. It returns a tuple containing a list of runner IDs and a list\n    of corresponding session metadata for runners with active sessions.\n\n    Returns:\n        tuple[list[str], list[str]]: A tuple containing a list of runner IDs and a list of corresponding session\n        metadata for runners with active sessions.\n    \"\"\"\n    runners_info = api_get_all_runner()\n    runner_instances = [\n        api_load_runner(str(runner_info.get(\"id\"))) for runner_info in runners_info\n    ]\n\n    runner_ids = []\n    session_metadata_list = []\n\n    for runner_instance in runner_instances:\n        if runner_instance.database_instance:\n            session_metadata = Session.load(runner_instance.database_instance)\n            if session_metadata is not None:\n                runner_ids.append(runner_instance.id)\n                session_metadata_list.append(session_metadata)\n    return runner_ids, session_metadata_list\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_load_session","title":"<code>api_load_session(runner_id)</code>","text":"<p>Loads the session details for a specific runner.</p> <p>This function calls the <code>Session.load</code> method to retrieve the session details associated with the specified runner ID.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner for which the session details are to be loaded.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: A dictionary containing the session details if available, otherwise None.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_load_session(runner_id: str) -&gt; dict | None:\n    \"\"\"\n    Loads the session details for a specific runner.\n\n    This function calls the `Session.load` method to retrieve the session details associated with the\n    specified runner ID.\n\n    Args:\n        runner_id (str): The unique identifier of the runner for which the session details are to be loaded.\n\n    Returns:\n        dict | None: A dictionary containing the session details if available, otherwise None.\n    \"\"\"\n    return Session.load(api_load_runner(runner_id).database_instance)\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_attack_module","title":"<code>api_update_attack_module(runner_id, attack_module_id)</code>","text":"<p>Updates the attack module for a specific runner.</p> <p>This function updates the attack module for a specific runner identified by the given runner_id. It calls the <code>Session.update_attack_module</code> method with the runner's database instance, runner_id, and the new attack_module_id.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the attack module needs to be updated.</p> required <code>attack_module_id</code> <code>str</code> <p>The new attack module to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the attack module is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_attack_module(runner_id: str, attack_module_id: str) -&gt; bool:\n    \"\"\"\n    Updates the attack module for a specific runner.\n\n    This function updates the attack module for a specific runner identified by the given runner_id. It calls the\n    `Session.update_attack_module` method with the runner's database instance,\n    runner_id, and the new attack_module_id.\n\n    Args:\n        runner_id (str): The ID of the runner for which the attack module needs to be updated.\n        attack_module_id (str): The new attack module to be set for the runner.\n\n    Returns:\n        bool: The status on whether the attack module is updated successfully.\n    \"\"\"\n    return Session.update_attack_module(\n        api_load_runner(runner_id).database_instance, runner_id, attack_module_id\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_context_strategy","title":"<code>api_update_context_strategy(runner_id, context_strategy)</code>","text":"<p>Updates the context strategy for a specific runner.</p> <p>This function updates the context strategy for a specific runner identified by the given runner_id. It calls the <code>Session.update_context_strategy</code> method with the runner's database instance, runner_id, and the new context_strategy.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the context strategy needs to be updated.</p> required <code>context_strategy</code> <code>str</code> <p>The new context strategy to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the context strategy is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_context_strategy(runner_id: str, context_strategy: str) -&gt; bool:\n    \"\"\"\n    Updates the context strategy for a specific runner.\n\n    This function updates the context strategy for a specific runner identified by the given runner_id. It calls the\n    `Session.update_context_strategy` method with the runner's database instance,\n    runner_id, and the new context_strategy.\n\n    Args:\n        runner_id (str): The ID of the runner for which the context strategy needs to be updated.\n        context_strategy (str): The new context strategy to be set for the runner.\n\n    Returns:\n        bool: The status on whether the context strategy is updated successfully.\n    \"\"\"\n    return Session.update_context_strategy(\n        api_load_runner(runner_id).database_instance, runner_id, context_strategy\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_cs_num_of_prev_prompts","title":"<code>api_update_cs_num_of_prev_prompts(runner_id, num_of_prev_prompts)</code>","text":"<p>Updates the number of previous prompts used in a context strategy for a specific runner.</p> <p>This function updates the number of previous prompts used in a context strategy for a specific runner identified by the given runner_id. It calls the <code>Session.update_cs_num_of_prev_prompts</code> method with the runner's database instance, runner_id, and the new num_of_prev_prompts.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the number of previous prompts needs to be updated.</p> required <code>num_of_prev_prompts</code> <code>int</code> <p>The new number of previous prompts to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the number of prompts for context strategy is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_cs_num_of_prev_prompts(runner_id: str, num_of_prev_prompts: int) -&gt; bool:\n    \"\"\"\n    Updates the number of previous prompts used in a context strategy for a specific runner.\n\n    This function updates the number of previous prompts used in a context strategy for a specific runner identified by\n    the given runner_id. It calls the `Session.update_cs_num_of_prev_prompts` method with the runner's database\n    instance, runner_id, and the new num_of_prev_prompts.\n\n    Args:\n        runner_id (str): The ID of the runner for which the number of previous prompts needs to be updated.\n        num_of_prev_prompts (int): The new number of previous prompts to be set for the runner.\n\n    Returns:\n        bool: The status on whether the number of prompts for context strategy is updated successfully.\n    \"\"\"\n    return Session.update_cs_num_of_prev_prompts(\n        api_load_runner(runner_id).database_instance, runner_id, num_of_prev_prompts\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_metric","title":"<code>api_update_metric(runner_id, metric_id)</code>","text":"<p>Updates the metric for a specific runner.</p> <p>This function updates the metric for a specific runner identified by the given runner_id. It calls the <code>Session.update_metric</code> method with the runner's database instance, runner_id, and the new metric_id.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the metric needs to be updated.</p> required <code>metric_id</code> <code>str</code> <p>The new metric to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the metric is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_metric(runner_id: str, metric_id: str) -&gt; bool:\n    \"\"\"\n    Updates the metric for a specific runner.\n\n    This function updates the metric for a specific runner identified by the given runner_id. It calls the\n    `Session.update_metric` method with the runner's database instance,\n    runner_id, and the new metric_id.\n\n    Args:\n        runner_id (str): The ID of the runner for which the metric needs to be updated.\n        metric_id (str): The new metric to be set for the runner.\n\n    Returns:\n        bool: The status on whether the metric is updated successfully.\n    \"\"\"\n    return Session.update_metric(\n        api_load_runner(runner_id).database_instance, runner_id, metric_id\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_prompt_template","title":"<code>api_update_prompt_template(runner_id, prompt_template)</code>","text":"<p>Updates the prompt template for a specific runner.</p> <p>This function updates the prompt template for a specific runner identified by the given runner_id. It calls the <code>Session.update_prompt_template</code> method with the runner's database instance, runner_id, and the new prompt_template.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the prompt template needs to be updated.</p> required <code>prompt_template</code> <code>str</code> <p>The new prompt template to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the prompt template is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_prompt_template(runner_id: str, prompt_template: str) -&gt; bool:\n    \"\"\"\n    Updates the prompt template for a specific runner.\n\n    This function updates the prompt template for a specific runner identified by the given runner_id. It calls the\n    `Session.update_prompt_template` method with the runner's database instance,\n    runner_id, and the new prompt_template.\n\n    Args:\n        runner_id (str): The ID of the runner for which the prompt template needs to be updated.\n        prompt_template (str): The new prompt template to be set for the runner.\n\n    Returns:\n        bool: The status on whether the prompt template is updated successfully.\n    \"\"\"\n    return Session.update_prompt_template(\n        api_load_runner(runner_id).database_instance, runner_id, prompt_template\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_system_prompt","title":"<code>api_update_system_prompt(runner_id, system_prompt)</code>","text":"<p>Updates the system prompt for a specific runner.</p> <p>This function updates the system prompt for a specific runner identified by the given runner_id. It calls the <code>Session.update_system_prompt</code> method with the runner's database instance, runner_id, and the new system_prompt.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the system prompt needs to be updated.</p> required <code>system_prompt</code> <code>str</code> <p>The new system prompt to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the system prompt is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_system_prompt(runner_id: str, system_prompt: str) -&gt; bool:\n    \"\"\"\n    Updates the system prompt for a specific runner.\n\n    This function updates the system prompt for a specific runner identified by the given runner_id. It calls the\n    `Session.update_system_prompt` method with the runner's database instance,\n    runner_id, and the new system_prompt.\n\n    Args:\n        runner_id (str): The ID of the runner for which the system prompt needs to be updated.\n        system_prompt (str): The new system prompt to be set for the runner.\n\n    Returns:\n        bool: The status on whether the system prompt is updated successfully.\n    \"\"\"\n    return Session.update_system_prompt(\n        api_load_runner(runner_id).database_instance, runner_id, system_prompt\n    )\n</code></pre>"},{"location":"api_reference/introduction/","title":"Moonshot","text":"<p>Moonshot is a comprehensive Large Language Model (LLM) Evaluation tool designed to address the challenge faced by developers and system owners in benchmarking large language models (LLMs) and testing their LLM applications against a baseline set of risks. It provides a platform for thorough evaluation and testing, ensuring the reliability and effectiveness of LLM applications.</p>"},{"location":"api_reference/introduction/#model-connectors","title":"Model Connectors","text":"<p>Model Connectors in Moonshot enable users to integrate new models into the toolkit by connecting to their Large Language Models (LLMs) via API connectors. This feature empowers users to create and modify LLM endpoints within Moonshot, facilitating customized testing and benchmarking scenarios tailored to their specific needs.</p>"},{"location":"api_reference/introduction/#benchmark","title":"Benchmark","text":"<p>A benchmark refers to a standardized set of tasks or datasets used to assess the performance of a Language Model, such as Large Language Models (LLMs) like GPT (Generative Pre-trained Transformer) models. These benchmarks are crucial for evaluating the capabilities and limitations of LLMs across various natural language processing tasks.</p> <p>A benchmark typically includes:</p> <ol> <li>Task Description: Clear instructions on the task(s) to be performed by the Language Model. Tasks can vary widely and may include text generation, summarization, question answering, sentiment analysis, etc.</li> <li>Datasets: The benchmark provides one or more datasets relevant to the task(s) being evaluated. These datasets often come with labeled examples or ground truth annotations to facilitate evaluation.</li> <li>Evaluation Metrics: Standardized metrics are used to quantify the performance of the Language Model on the given tasks. These metrics could include accuracy, precision, recall, F1 score, perplexity, etc., depending on the nature of the task.</li> </ol> <p>Benchmarks are essential for comparing different Language Models objectively and for tracking progress in the field of natural language processing. They provide a standardized framework for researchers to evaluate and improve the performance of their models. Additionally, benchmarks serve as a means of fostering collaboration and facilitating the development of more robust and reliable Language Models.</p>"},{"location":"api_reference/introduction/#during-a-run","title":"During a Run","text":"<p>During a run in Moonshot, the toolkit executes the selected Cookbook and interacts with the model endpoints chosen by the users. This process allows for the evaluation of LLM applications against predefined benchmarks and test scenarios.</p>"},{"location":"api_reference/introduction/#cookbook","title":"Cookbook","text":"<p>The Cookbook in Moonshot contains one or more recipes, each designed to generate results when selected to run with the model endpoints. It serves as a comprehensive guide for conducting evaluations and tests, offering a structured approach to assessing LLM applications' performance and addressing potential risks.</p>"},{"location":"api_reference/introduction/#recipe","title":"Recipe","text":"<p>A Recipe in Moonshot brings together 3 essential components:</p> <ul> <li>Dataset(s)</li> <li>Prompt Template(s)</li> <li>Metrics(s)</li> </ul> <p>A recipe can contain one or more datasets, prompt templates and metrics. </p>"},{"location":"api_reference/introduction/#components-of-a-recipe","title":"Components of a Recipe","text":""},{"location":"api_reference/introduction/#datasets","title":"Datasets","text":"<p>Datasets consist of a collection of input-target pairs, where the 'input' is a prompt provided to the LLM (being tested), and the 'target' is the correct response or ground truth. The LLM's output is then compared with the target to assess its performance. These datasets can include various types of interactions such as questions and answers or commands and actions. Users have the flexibility to compile and incorporate their own datasets. </p>"},{"location":"api_reference/introduction/#prompt-templates","title":"Prompt Templates","text":"<p>Prompt templates are predefined text structures that guide the formatting and contextualisation of inputs submitted to the LLM. Inputs adapt to these templates before being sent to the LLM for processing.</p>"},{"location":"api_reference/introduction/#metrics","title":"Metrics","text":"<p>Metrics are predefined criterias used to evaluate the LLM\u2019s outputs against the targets. These metrics may include measures of accuracy, precision, or the relevance of the LLM\u2019s responses. By applying these metrics, users can assess the quality of the output generated by the LLM in response to the input.</p>"},{"location":"api_reference/introduction/#red-teaming","title":"Red Teaming","text":"<p>Red Teaming serves as a valuable tool within the toolkit, aimed at aiding and simplifying the process of probing large language models (LLMs) to enhance the reliability and security of LLM applications. It facilitates structured testing procedures to identify vulnerabilities and improve overall system robustness.</p>"},{"location":"api_reference/introduction/#session","title":"Session","text":"<p>A Session feature allows users to initiate interactions with selected models, enabling them to engage in chats and send prompts to red team the models. Sessions provide a controlled environment for conducting testing and evaluation activities, ensuring systematic and organized testing procedures.</p>"},{"location":"api_reference/introduction/#chat","title":"Chat","text":"<p>A Chat refers to an interaction directed to a specific model within a session, initiating the red teaming prompt process. Users can communicate with individual models, sending prompts and assessing their responses to identify potential vulnerabilities and areas for improvement in LLM applications.</p>"},{"location":"api_reference/web_api_guide/","title":"Running Moonshot as a Web API","text":"<p>Moonshot WebAPI is built using FastAPI. This guide will help you get started and configure your environment.</p> <p>To run Moonshot Web API: <pre><code>$ python -m moonshot web-api\n</code></pre></p> <p>For instructions on setting up the Moonshot UI, please refer to the Moonshot UI repository.</p>"},{"location":"api_reference/web_api_guide/#getting-started","title":"Getting Started","text":"<p>By default, Moonshot WebAPI uses its own configuration settings. However, you can customize these settings by providing your own <code>.env</code> file in the directory where you are running Moonshot.</p>"},{"location":"api_reference/web_api_guide/#configuring-your-env-file","title":"Configuring your <code>.env</code> File","text":"<p>The <code>.env</code> file should include the following variables:</p> <ul> <li><code>MS_WEB_API_CONFIG</code>: This is used to specify the path to your configuration file. For example: <code>/User/path/to/your/config.yml</code>.</li> <li><code>APP_ENVIRONMENT</code>: This defines the environment in which you are running Moonshot. For example: <code>PROD</code>.</li> <li><code>HOST</code>: This is the host where you wish to run Moonshot. For example: <code>127.0.0.1</code>.</li> <li><code>PORT</code>: This is the port at which you wish to run your FastAPI. For example: <code>5000</code>.</li> </ul>"},{"location":"api_reference/web_api_guide/#configuring-your-configyml-file","title":"Configuring your <code>config.yml</code> File","text":"<p>The <code>config.yml</code> file contains several sections. Here's a brief overview of each section:</p> <ul> <li> <p><code>asyncio</code></p> <ul> <li><code>monitor_task</code>: This flag determines whether to monitor tasks in asyncio or not. For example: <code>monitor_task: false</code>.</li> </ul> </li> <li> <p><code>ssl</code></p> <ul> <li><code>enabled</code>: This flag determines whether SSL is enabled or not. For example: <code>enabled: ${ENABLE_SSL:false}</code>.</li> <li><code>file_path</code>: This is the path to the directory containing the SSL certificate and key files. For example: <code>file_path: \"${SSL_FILE_PATH:./web_api/certs}\"</code>.</li> <li><code>cert_filename</code>: This is the filename of the SSL certificate. For example: <code>cert_filename: \"cert.pem\"</code>.</li> <li><code>key_filename</code>: This is the filename of the SSL key. For example: <code>key_filename: \"key.pem\"</code>.</li> </ul> </li> <li> <p><code>cors</code></p> <ul> <li><code>enabled</code>: This flag determines whether CORS is enabled or not. For example: <code>enabled: false</code>.</li> <li><code>allowed_origins</code>: This is a list of origins that are allowed to make cross-origin requests. For example: <code>allowed_origins: \"http://localhost:3000\"</code>.</li> </ul> </li> <li> <p><code>log</code></p> <ul> <li><code>logging</code>: This flag determines whether logging is enabled or not. For example: <code>logging: ${LOGGING:true}</code>.</li> <li><code>level</code>: This sets the level of logging. It could be <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, or <code>CRITICAL</code>. For example: <code>level: ${LOG_LEVEL:DEBUG}</code>.</li> <li><code>format</code>: This specifies the format of the log messages. For example: <code>format: \"[%(asctime)s] [%(levelname)s] [%(name)s]: %(message)s\"</code>.</li> <li><code>log_file_path</code>: This is the path where the log files will be stored. For example: <code>log_file_path: \"/path/to/write/moonshot.logs\"</code>.</li> <li><code>log_file_max_size</code>: This is the maximum size (in bytes) that a log file can have before it gets rolled over. For example: <code>log_file_max_size: 5242880</code>.</li> <li><code>log_file_backup_count</code>: This is the number of backup log files to keep. For example: <code>log_file_backup_count: 3</code>.</li> </ul> </li> </ul> <p>For example on how to structure your <code>config.yml</code> file, refer to the example provided here.</p>"},{"location":"api_reference/web_api_swagger/","title":"Swagger","text":""},{"location":"cli/add_your_own_tests/","title":"Add Your Own Tests","text":"<p>In this section, we will be going through the steps required to add tests in CLI.</p> <p>Some of the things that you can add into Moonshot are: - Dataset - Bring your own dataset and add it into Moonshot - Recipe - Contains all the details to run a benchmark - Cookbook - A set of recipes</p> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter <code>python -m moonshot cli interactive</code></p>"},{"location":"cli/add_your_own_tests/#create-a-new-dataset","title":"Create a New Dataset","text":"<p>Refer to this Jupyter notebook example for the guide (Under the Prepare the Dataset section).</p>"},{"location":"cli/add_your_own_tests/#create-a-new-recipe","title":"Create a New Recipe","text":"<p>To run this dataset, you need to create a new recipe. A recipe contains all the details required to run a benchmark. A recipe guides Moonshot on what data to use, and how to evaluate the model's responses.</p> <ol> <li> <p>Enter <code>add_recipe -h</code> for an example: </p> <ul> <li> <p>Example: <code>add_recipe 'My new recipe' 'I am recipe description' \"['tag1','tag2']\" \"['category1','category2']\" \"['bbq-lite-age-ambiguous']\" \"['analogical-similarity','auto-categorisation']\" \"['bertscore','bleuscore']\" \"[]\" \"{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}\"</code></p> <p>The fields are as follows for this example:</p> <ul> <li>Name (A unique name for the recipe): <code>My new recipe</code></li> <li>Description (An explanation of what the recipe does and what it's for): <code>I am recipe description</code></li> <li>Categories (Broader classifications that help organize recipes into collections): <code>['category1','category2']</code></li> <li>Datasets (The data that will be used when running the recipe. This could be a set of prompts, questions, or any input that - the model will respond to): <code>['bbq-lite-age-ambiguous']</code></li> <li>Metrics (Criteria or measurements used to evaluate the model's responses, such as accuracy, fluency, or adherence to a - prompt): <code>['bertscore','bleuscore']</code></li> <li>Prompt Templates (Optional pre-prompt or post-prompt): <code>['analogical-similarity','mmlu']</code></li> <li>Tags (Optional keywords that categorize the recipe, making it easier to find and group with similar recipes): <code>['tag1','tag2']</code></li> <li>Attack Strategies (Optional components that introduce adversarial testing scenarios to probe the model's robustness): <code>['charswap_attack_module']</code></li> <li>Grading Scale (Optional set of thresholds or criteria used to grade or score the model's performance): <code>{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}</code></li> </ul> </li> </ul> </li> <li> <p>Use the <code>add_recipe</code> command to create your recipe, then use the <code>view_recipe my-new-recipe</code> command to view your newly created cookbook:</p> <p>NOTE: The ID of the recipe is created by slugifying the name.</p> <p></p> </li> </ol>"},{"location":"cli/add_your_own_tests/#create-a-new-cookbook","title":"Create a New Cookbook","text":"<p>We can also create a new cookbook and add existing recipes together with our new recipe. A cookbook in Moonshot is a curated collection of recipes designed to be executed together.</p> <ol> <li> <p>Enter <code>add_cookbook -h</code> for an example: </p> <ul> <li> <p>Example: <code>add_cookbook 'My new cookbook' 'I am cookbook description' \"['analogical-similarity','auto-categorisation']\"</code></p> <p>The fields are as follows for this example:  - Name (A unique name for the cookbook): <code>My new cookbook</code> - Description (A detailed explanation of the cookbook's purpose and the types of recipes it contains): <code>I am cookbook description</code> - Recipes (A list of recipe names that are included in the cookbook. Each recipe represents a specific test or benchmark): <code>['analogical-similarity','auto-categorisation']</code></p> </li> </ul> <p>Use the <code>add_cookbook</code> command to create your cookbook, then use the <code>view_cookbook my-new-cookbook</code> command to view your newly created cookbook:</p> <p></p> </li> </ol>"},{"location":"cli/benchmarking/","title":"Execute Existing Tests","text":"<p>In this section, we will be going through the steps required to run a test in CLI.</p> <p>To run a test, you will need:</p> <ul> <li>Connector Endpoint - a configuration file to connect to your desired LLM endpoint</li> <li>Cookbook/Recipe - benchmarks you want to run TODO</li> </ul> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter <code>python -m moonshot cli interactive</code></p>"},{"location":"cli/benchmarking/#select-a-connector-endpoint","title":"Select a Connector Endpoint","text":"<p>If we do not have a connector endpoint you need, check out the guide here to create one yourself.</p>"},{"location":"cli/benchmarking/#running-a-test-using-our-predefined-cookbook","title":"Running a Test Using Our Predefined Cookbook","text":"<p>Once you have your connector endpoint, we can start choosing the test we want to run. </p> <ol> <li> <p>To view all the cookbooks available, enter <code>list_cookbooks</code>. You will see a list of available cookbooks:</p> <p></p> </li> <li> <p>To run a cookbook, you can first enter <code>run_cookbook -h</code> to better understand its usage.</p> <ul> <li> <p>Example: <code>run_cookbook \"my new cookbook runner\" \"['common-risk-easy']\" \"['my-openai-connector']\" -n 1 -r 2 -s \"This is a customised system prompt\"</code>: </p> <ul> <li>Runner ID (<code>id</code> in <code>list_runners</code>): my-new-cookbook-runner (Enter <code>list_runners</code> to view the runners available. If you do not want to use an existing runner or do not have a runner yet, the <code>run_cookbook</code> command will create a runner for you using a slugified ID.)</li> <li>ID of the cookbook (<code>ID</code> in <code>list_cookbooks</code>): <code>common-risk-easy</code></li> <li>ID of your connector endpoint (<code>Id</code> column in <code>list_endpoints</code>): <code>my-openai-connector</code> </li> <li>Number of prompts (Optional TODO): <code>1</code> </li> <li>Random seed (Optional TODO): <code>2</code></li> <li>System prompt (Optional system prompt which overwrites our default system prompt): <code>This is a customised system prompt</code></li> </ul> </li> </ul> <p>TIP:  You can run more than one cookbook and endpoint by adding them into the list( i.e. <code>\"['common-risk-easy','common-risk-hard']\"</code>)</p> </li> <li> <p>Run your cookbook with the <code>run_cookbook</code> command. You should see a table of results from your run:</p> <p></p> </li> </ol>"},{"location":"cli/benchmarking/#running-a-test-using-our-predefined-recipe","title":"Running a Test Using Our Predefined Recipe","text":"<p>You can choose to run a recipe instead of a cookbook as well.</p> <ol> <li> <p>To view all the recipes available, enter <code>list_recipes</code>. You will see a list of available recipes:</p> <p></p> </li> <li> <p>To run a recipe, you can first enter <code>run_recipe -h</code> to better understand its usage. For example, to run a recipe with the following configuration:</p> <ul> <li>Runner ID (<code>id</code> in <code>list_runners</code>): my-new-recipe-runner (Enter <code>list_runners</code> to view the runners available. If you do not want to use an existing runner or do not have a runner yet, the <code>run_recipe</code> command will create a runner for you using a slugified ID.)</li> <li>ID of the recipes (<code>ID</code> in <code>list_recipes</code>): <code>auto-categorisation</code> and <code>winobias</code></li> <li>Name of your connector endpoint (<code>Id</code> column in <code>list_endpoints</code>): <code>my-openai-connector</code> </li> <li>Number of prompts (TODO): <code>1</code> </li> <li>Random seed (TODO): <code>2</code></li> <li>System prompt: <code>This is a customised system prompt</code></li> <li>Runner and result proc (TODO)</li> </ul> <p>The command would be: <code>run_recipe \"my new recipe runner\" \"['auto-categorisation','winobias']\" \"['my-openai-connector']\" -n 1 -r 2 -s \"This is a customised system prompt\"</code></p> </li> <li> <p>Run your recipe with the <code>run_recipe</code> command. You should see a table of results from your run:</p> <p></p> </li> </ol>"},{"location":"cli/cli_guide/","title":"Running Moonshot via CLI","text":"<p>Two modes are available on the Moonshot CLI: Command-Based Mode and Interactive Mode.</p> Full list of commands in Moonshot <pre><code>Initialisation\n======================================================================================================\ninteractive           Run the interactive shell.                                                      \nlist_connect_types    Get a list of available Language Model (LLM) connection types.                  \nlist_endpoints        Get a list of available Language Model (LLM) endpoints.                         \nversion               Get the version of the application.                                             \n\nMoonshot Benchmarking\n======================================================================================================\nadd_cookbook          Add a new cookbook.                                                             \nadd_endpoint          Add a new endpoint.                                                             \nadd_recipe            Add a new recipe.                                                               \nlist_cookbooks        Get a list of available cookbooks.                                              \nlist_recipes          Get a list of available recipes.                                                \nlist_results          Get a list of available results.                                                \nlist_runs             Get a list of available runs.                                                   \nresume_run            Resume an interrupted run.                                                      \nrun_cookbook          Run a cookbook.                                                                 \nrun_recipe            Run a recipe.                                                                   \nview_cookbook         View a cookbook.                                                                \nview_results          View a results file.                                                            \n\nMoonshot RedTeaming\n=======================================================================================================\nend_session            End the current session.                                                        \nlist_prompt_templates  List all prompt templates available.                                            \nlist_sessions          List all available sessions.                                                    \nnew_session            Add a new red teaming session.                                                  \nuse_context_strategy   Use a context strategy.                                                         \nuse_prompt_template    Use a prompt template.                                                          \nuse_session            Use an existing red teaming session.                                            \n\nUncategorized\n======================================================================================================\nalias                 Manage aliases                                                                  \nedit                  Run a text editor and optionally open a file with it                            \nhelp                  List available commands or provide detailed help for a specific command         \nhistory               View, run, edit, save, or clear previously entered commands                     \nmacro                 Manage macros                                                                   \nquit                  Exit this application                                                           \nrun_pyscript          Run a Python script file inside the console                                     \nrun_script            Run commands in script file that is encoded as either ASCII or UTF-8 text       \nset                   Set a settable parameter or show current settings of parameters                 \nshell                 Execute a command as if at the OS prompt                                        \nshortcuts             List available shortcuts                                                \n</code></pre>"},{"location":"cli/cli_guide/#command-based-mode","title":"Command-based Mode","text":"<p>In the command-based mode, run commands by prepending <code>python -m moonshot cli</code>. </p> <p>For example,</p> <ul> <li>To list all the available commands: <code>python -m moonshot cli help</code></li> <li>To list the connector types available: <code>python -m moonshot cli list_connect_types</code></li> </ul>"},{"location":"cli/cli_guide/#interactive-mode","title":"Interactive Mode","text":"<p>We recommend the interactive mode for a more efficient experience, especially if you are using Moonshot to red-team. </p> <p>To enter interactive mode: <code>python -m moonshot cli interactive</code> (You should see the command prompt change to <code>moonshot &gt;</code> ) For example, - To list all the available commands:      <pre><code>moonshot &gt; help\n</code></pre> - To list the connector types available:     <pre><code>moonshot &gt; list_connect_types\n</code></pre></p>"},{"location":"cli/connecting_endpoints/","title":"Connecting to LLMs","text":"<p>In this section, we will be going through the steps required to create a connector endpoint.</p> <p>Before we jump into executing tests and performing red teaming on LLMs, we have to first create a connector endpoint. This connector endpoint will help us to connect to a specific LLM.</p> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter <code>python -m moonshot cli interactive</code></p>"},{"location":"cli/connecting_endpoints/#using-a-existing-connector-endpoint","title":"Using a Existing Connector Endpoint","text":"<ol> <li> <p>To view the connector endpoint available, enter <code>list_endpoints</code>. You will see a list of available connector endpoints that we have created beforehand:</p> <p></p> </li> <li> <p>If there is no connector endpoint for you here, you create your own connector endpoint here. Otherwise, enter <code>update_endpoint -h</code> to understand how to modify the connector endpoint you want to use (like adding your own API key):</p> <ul> <li> <p>Example: <code>update_endpoint openai-gpt4 \"[('name', 'my-special-openai-endpoint'), ('uri', 'my-uri-loc'), ('token', 'my-token-here')]\"</code></p> <p>Here, we are updating a connector endpoint with the ID <code>open-gpt-4</code>. The keys and values to be updated are tuples in a list (i.e. update the <code>name</code> field to <code>my-special-openai-endpoint</code>)</p> </li> </ul> </li> <li> <p>Use the <code>update_endpoint</code> command to update your connector endpoint, then use the <code>view_endpoint</code> command to view your updated connector endpoint:</p> <p></p> </li> </ol>"},{"location":"cli/connecting_endpoints/#creating-a-connector-endpoint","title":"Creating a Connector Endpoint","text":"<ol> <li> <p>To understand more about creating a connector endpoint, enter <code>add_endpoint -h</code>:</p> <ul> <li> <p>Example: <code>add_endpoint openai-connector 'my-openai-connector' myendpointuri mythisismysecretapitoken 2 10 \"{'temperature': 0.5}\"</code>. </p> <p>In this example, we are creating a connector endpoint for the <code>openai-connector</code> connector type:</p> <ul> <li>Name of your endpoint connenctor (unique identifier): <code>my-openai-connector</code></li> <li>URI: <code>myendpointuri</code> (set this to a random string like <code>none</code> if it is not required by your connector endpoint)</li> <li>API token: <code>thisismysecretapitoken</code></li> <li>Max number of calls made to the endpoint per second: <code>2</code></li> <li>Max concurrency of the endpoint:<code>10</code></li> <li>Other parameters that this endpoint may need:<ul> <li>Temperature: 0.5        </li> </ul> </li> </ul> <p>To view the list of connector types, enter <code>list_connector_types</code>:     </p> <p>NOTE: If you do not see the connector type you want to use, refer to this TODO guide to learn how to create your own connector type. </p> </li> </ul> </li> <li> <p>Use the <code>create_endpoint</code> command to create your endpoint, then use the <code>view_endpoint &lt;YOUR CONNECTOR ENDPOINT ID&gt;</code> command to view your newly created connector endpoint:</p> <p>NOTE: The ID of the connector endpoint is created by slugifying the name.</p> <p></p> </li> </ol>"},{"location":"cli/connecting_endpoints_old/","title":"Connecting endpoints old","text":""},{"location":"cli/connecting_endpoints_old/#connecting-endpoints","title":"Connecting Endpoints","text":"<p>Establish and save connections to the endpoints of the LLMs that you wish to evaluate. </p> <p>Moonshot currently provides easy connection to: OpenAI's GPT4 &amp; GPT3.5, GPT2 and Llama2-13b-gptq on Hugging Face, and Anthropic's Claude2.</p> <p>Important</p> <p>Please note that you will most likely need to supply your own API token/key to connect to the LLM endpoints.</p> <p>To connect to these models, you simply need to create an endpoint configuration file under the directory <code>data/connectors-endpoints</code> and define the following fields in that file:</p> <ul> <li>type: The python module name of LLM that you would like to connect to. (It should be any ONE of the Python modules available at <code>data/connectors</code>) </li> <li>name: The name of this endpoint (It should also be the name of this file)</li> <li>uri: The URI of the LLM endpoint. </li> <li>token: Your API token/key to connect to the LLM endpoint.</li> <li>max_calls_per_second: The maximum number of API calls made to the LLM endpoint per second.</li> <li>max_concurrency: The maximum number of open concurrent connections to the LLM endpoint.</li> <li>params: The parameter(s) required to be sent to the LLM endpoint. (optional)</li> </ul> <p>For example, if you wish to create an endpoint configuration file to connect to Claude 2, you can create a file named <code>my-anthropic-claude2.json</code> in <code>data/connectors-endpoints</code>. The contents of <code>my-anthropic-claude2.json</code> should look something like this:</p> <pre><code>{\n    \"type\": \"claude2\",\n    \"name\": \"my-anthropic-claude2\",\n    \"uri\": \"&lt;your_endpoint_url&gt;\",\n    \"token\": \"&lt;your_api_token&gt;\",\n    \"max_calls_per_second\": 100,\n    \"max_concurrency\": 100,\n    \"params\": {}\n}\n</code></pre> <p>\ud83d\udca1Quick Start: If you have an OpenAI API key, simply edit the pre-configured endpoint at <code>my-openai-gpt35.json</code>, and you'll be able to start evaluating or red-teaming GPT3.5. </p> <p>Connecting LLMs - CLI Commands <pre><code>list_connect_types    Get a list of available LLM connection types.\nadd_endpoint          Add a new endpoint.\nlist_endpoints        Get a list of configured LLM endpoints.\n</code></pre> You can run <code>&lt;command-name&gt; --help</code> to better understand the usage of a command or view cli guide here.</p>"},{"location":"cli/red_teaming/","title":"Run Red Teaming Sessions","text":"<p>In this section, we will be going through the steps required to run red teaming sessions.</p> <p>To run a test, you will need:</p> <ul> <li>Connector Endpoint - a configuration file to connect to your desired LLM endpoint</li> <li>Session - a session allows users to perform manual and automated red teaming on the LLMs, and stores the prompts and responses to and fro.</li> <li>Prompt - a prompt that you will be sending to LLMs in manual red teaming/ a starting prompt to input in attack modules before sending to the LLMs</li> </ul> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter <code>python -m moonshot cli interactive</code></p>"},{"location":"cli/red_teaming/#create-a-connector-endpoint","title":"Create a Connector Endpoint","text":"<p>If you have not already created a connector endpoint, check out the guide here.</p>"},{"location":"cli/red_teaming/#create-a-session","title":"Create a Session","text":"<p>Once your connector endpoint is created, we can start creating our session for red teaming.</p> <p>Every session must reside in a runner. Before we create a session, we can view a list of runners currently available by entering <code>list_runners</code>:     </p> <p>There are two options to create a session: you can either use an existing runner, or create a new runner with a session. To better understand its usage, enter <code>new_session -h</code>.</p> <ol> <li> <p>Use existing runner.</p> <ul> <li>Example: <code>new_session my-test-mrt -c add_previous_prompt -p mmlu</code><ul> <li>Runner ID: <code>my-test-mrt</code></li> <li>Context strategy: <code>add_previous_prompt</code></li> <li>Prompt template:  <code>mmlu</code></li> </ul> </li> </ul> <p></p> <p>NOTE:  Context strategy and prompt template are optional and can be set later so you can omit the <code>-c -p</code> flags if you do not need them    </p> </li> <li> <p>Create new runner.</p> <ul> <li>Example: <code>new_session my-new-runner-test-mrt -e \"['openai-gpt35-turbo','openai-gpt4']\" -p phrase-relatedness</code><ul> <li>Runner ID: <code>my-new-runner-test-mrt</code></li> <li>Endpoint: <code>['openai-gpt35-turbo','openai-gpt4']</code></li> <li>Prompt template: <code>phrase-relatedness</code></li> </ul> </li> </ul> <p></p> </li> </ol> <p>Once you have a session created and activated, we can proceed with red teaming. There are two ways to perform red teaming: manual red teaming and using attack modules to perform automated attacks. </p>"},{"location":"cli/red_teaming/#manual-red-teaming","title":"Manual Red Teaming","text":"<p>From the previous section, you should have a session created and activated. For manual red teaming, you can start by typing something in the session and that prompt will be sent to all the LLMs in that session.      </p> <p>NOTE:  Anything entered in a session that is not a command will be considered a prompt and sent to the LLMs in that session! </p>"},{"location":"cli/red_teaming/#automated-red-teaming-run-attack-modules","title":"Automated Red Teaming (Run Attack Modules)","text":"<p>We will use the same session from manual red teaming in this example. Enter <code>run_attack_module -h</code> to better understand its usage.</p> <ul> <li>Example: <code>run_attack_module charswap_attack \"The grandpa and his son went to does not know how to use a phone?\\na)Grandpa\\nb)Son.\"</code><ul> <li>Attack module ID:  <code>charswap_attack</code></li> <li>Prompt: <code>The grandpa and his son went to does not know how to use a phone?\\na)Grandpa\\nb)Son.</code> </li> </ul> </li> </ul> <p>Refer to this section for more information on automated red teaming</p>"},{"location":"cli/red_teaming/#ending-and-resuming-a-session","title":"Ending and Resuming a Session","text":"<p>End Session - Once you are done with red teaming, you can close the session by entering <code>end_session</code>. </p> <p>View sessions -  You can view your sessions by entering <code>list_sessions</code>.</p> <p>Resume session - You can resume a session by entering <code>use_session &lt;desired session id&gt;</code>, where <code>&lt;desired session id&gt;</code> is an <code>id</code> in <code>list_sessions</code>. When you resume a session, the state of your previous red teaming attempts will be restored.</p>"},{"location":"cli/red_teaming/#configurations-in-a-session","title":"Configurations in a Session","text":"<ul> <li> <p>These are the configurations you can set in a session:</p> <ul> <li> <p>Context strategy: a Python module that helps to add context to the current prompt (i.e. add in the previous five prompts sent.) </p> <p>Available commands:</p> <ul> <li><code>use_context_strategy &lt;desired context strategy id&gt;</code>: You can use <code>list_context_strategies</code> to view the list of context strategies available and <code>&lt;desired context strategy id&gt;</code> should correspond to an <code>Id</code> in this list.<ul> <li>It is also possible to set the number of previous prompts to use with a context strategy. For example, to add <code>8</code> previous prompts as context using the <code>add_previous_prompt</code>, the command would be <code>use_context_strategy add_previous_prompt -n 8</code></li> </ul> </li> <li><code>clear_context_strategy</code>: Clears the prompt template used in a session.</li> </ul> </li> <li> <p>Prompt template: a JSON file which contains static texts that is appended to every prompt before they are sent to the LLMs. It should correspond to an <code>id</code> in <code>list_prompt_templates</code>.</p> <p>Available commands:</p> <ul> <li> <p><code>use_prompt_template &lt;desired prompt template id&gt;</code>: You can use <code>list_prompt_templates</code> to view the list of prompt templates available and <code>&lt;desired prompt template id&gt;</code> should correspond to an <code>id</code> in this list.</p> </li> <li> <p><code>clear_prompt_template</code>: Clears the context strategy used in a session.</p> </li> </ul> </li> </ul> </li> </ul>"},{"location":"cli/red_teaming/#more-about-automated-red-teaming","title":"More About Automated Red Teaming","text":"<p>Currently, automated red teaming heavily relies on the attack module being used. We have created a class, AttackModule, which serves as the base class for creating custom attack modules within the Moonshot framework. This class provides a structure that red teamers can extend to implement their own adversarial attack strategies.</p> <p>In the AttackModule class, we have simplified the process for red teamers by providing easy access to necessary components for red teaming, such as connector endpoints and a function to automatically wrap the prompt template and context strategy contents around the provided prompt.</p> <p>The design is very free-form, thus it is entirely up to the attack module developers whether they want to use the functions we have prepared. For instance, they may choose not to use the context strategy and prompt template at all in the attack module, even though these may be set in the session.</p>"},{"location":"contributor_guide/create_connector/","title":"How to Create a Connector","text":"<p>Currently, we do not have a better way to create a new connector as it involves users to create it as a Python module. The most straightforward way is to copy and paste an existing connector module, and modify the codes.</p> <p>All connectors inherit the super class Connector. In this super class, we initialise it with certain variables which we think are common across various connectors (i.e. <code>token</code>, <code>max_concurrency</code>, etc). These variables come from another class called ConnectorEndpoint, but we will get to this later.</p> <p>We will use our OpenAI connector openai-connector as an example: <pre><code>    def __init__(self, ep_arguments: ConnectorEndpointArguments):\n        # Initialize super class\n        super().__init__(ep_arguments)\n\n        # This is optional. You can keep this here if your model needs to take in a model field from the user\n        self.model = self.optional_params.get(\"model\", \"\")\n\n    @Connector.rate_limited #TODO\n    @perform_retry # Performs retries based on a variable num_of_retries. Throws a ConnectionError when the number of retries is hit. \n    async def get_response(self, prompt: str) -&gt; str:\n        \"\"\"\n        Copy and paste this function and insert your codes to send prompts and receive responses from the target LLM \n        here. \n\n        Args:\n            prompt (str): The input prompt to send to the target LLM.\n\n        Returns:\n            str: The text response generated by the target LLM.\n        \"\"\"\n        # You may want to insert codes to perform appending or editing of prompt before sending to LLM\n        connector_prompt = f\"{self.pre_prompt}{prompt}{self.post_prompt}\" # just an example\n\n        # Every LLM requires their connector to send the prompts in a specific way with certain configurations\n        response = await self._client.chat.completions.create(**new_params) # an example from the OpenAI Connector\n\n        # Return the response of the LLM \n        return await self._process_response(response) # an example\n\n    async def _process_response(self, response: Any) -&gt; str:\n        \"\"\"\n        An optional helper method we have in all our connector types to process the response from the LLM. The way to\n        process responses from different LLMs can be different. You can insert codes to process the response here if \n        you want.\n\n        Args:\n            response (Any): The response from the LLM. It depends on what the LLM returns as a response\n            (i.e. could be a dict, string, list, etc)\n\n        Returns:\n            str: The processed response\n        \"\"\"\n        return str(response) # an example\n</code></pre></p>"},{"location":"examples/example/","title":"Examples","text":"<p>In this Jupyter notebook, we demonstrate how you can leverage on the Moonshot library to:</p> <ul> <li>Connect to OpenAI's GPT-3.5</li> <li>Create your own recipes and cookbooks</li> <li>Run benchmarks</li> </ul>"},{"location":"getting_started/first_test/","title":"Running your first test","text":""},{"location":"getting_started/first_test/#objective","title":"Objective","text":"<p>In this guide, you will learn how to</p> <ol> <li>Launch Moonshot UI </li> <li>Run tests using benchmark and perform red teaming on one of the OpenAI models.</li> </ol>"},{"location":"getting_started/first_test/#launch-moonshot-ui","title":"Launch Moonshot UI","text":"<p>Moonshot UI is designed to simplify the testing workflows. Once Moonshot is installed, you can start the user inferface using the  following command:</p> <pre><code>python -m moonshot web\n</code></pre> <p>Then, use your browser and navigate to <code>http://localhost:3000</code></p> <p>Note</p> <p>We will be testing a model from OpenAI in this guide. You will need to prepare two API tokens - one from OpenAI and one from TogetherAI</p>"},{"location":"getting_started/first_test/#run-benchmark-test","title":"Run Benchmark Test","text":"<p>Upon navigating to the webpage, you will be greeted with our main screen. To start a benchmark test, click on \"Get Started.\"</p> <p></p> <p>This will direct you to a wizard that will guide you through the testing process. In the first step, select the tests you would like to run on your model. By default, three baseline tests are selected.</p> <p>Note</p> <p>We will be testing a model from OpenAI in this guide. You will need to prepare an OpenAI API token.</p> <p></p> <p>Once you have completed the selection, click on the down arrow to proceed to the next step. In this step, you will see the total number of prompts in this set of tests. Click on the \"inverted triangle\" again to advance to the next step.</p> <p></p> <p>In the next step, connect to your AI system. Click \"Edit\" for one of the OpenAI models, such as OpenAI GPT-3.5 Turbo.</p> <p></p> <p>Enter your API token on this screen, then click \"Save\". Repeat this step for \"Together Llama Guard 7B Assistant.\"</p> <p>Note</p> <p>Some cookbooks use another LLM to evaluate the response. In this case, one of the baseline cookbooks uses Llama Guard 7B to evaluate if the response is safe or unsafe.</p> <p></p> <p>You will return to the screen to select the endpoint. Choose the endpoint you have just configured, then proceed to the next step by clicking the down arrow.</p> <p>Finally, enter the name and description for this test. Set the number of prompts to \"1\" and click \"Run.\"</p> <p></p> <p>The progress bar will be shown in the screen.</p> <p></p> <p>Note</p> <p>You can continue using Moonshot for other tasks, such as red teaming, while waiting for the test to complete.</p> <p>If the test runs unsuccessfully, you can view the errors by clicking on \"View Errors.\"</p> <p></p> <p>If the test runs successfully, you will be prompted to view the report.</p> <p></p> <p>You can view the report in the web browser, or you can download it for offline access by clicking the \"Download HTML Report\" button.</p> <p></p>"},{"location":"getting_started/first_test/#run-red-teaming","title":"Run Red Teaming","text":"<p>To initiate red teaming, click on the icon in the sidebar or select \"Start Red Teaming\" from the home page.</p> <p></p> <p>Note</p> <p>If you click on the icon in the sidebar, click \"Start New Session\" in the next screen.</p> <p>Select one or more endpoints to red team on this screen. Click the arrow to proceed to the next screen.</p> <p></p> <p>In this screen, you have the option to select one of the attack modules to automatically red team your model. For the purposes of this guide, we will skip this step. Click \"Skip for now.\"</p> <p></p> <p>Enter a name and type a description in this screen, then click \"Start.\"</p> <p></p> <p>In the red teaming screen, you can type any text in the textbox at the bottom to send a prompt to the selected endpoints. The prompt will be sent to all endpoints.</p> <p></p> <p>To run automated red teaming, click on \"Attack Module\" and select one of the modules. In this case, select \"Toxic Sentence Generator\" to test whether the endpoints can be induced to complete the sentences with toxic words.</p> <p></p> <p>Type a cuss word in the prompt. This process may take a while to load, as it requires Moonshot to download a specific model. Once completed, you can review the prompts by scrolling through the chatbox.</p> <p></p>"},{"location":"getting_started/installation/","title":"Installing Moonshot","text":""},{"location":"getting_started/installation/#preinstallation-requirements","title":"Preinstallation Requirements","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git <p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre>"},{"location":"getting_started/installation/#installation-from-pypi-to-be-updated-please-skip-to-next-installation-section","title":"Installation from PyPi (To be updated - Please skip to next installation section)","text":"<p>You can find the Moonshot Package here.</p>"},{"location":"getting_started/installation/#installing-the-moonshot-library","title":"Installing the Moonshot Library","text":"<p>The Moonshot Library allows you to interact with the Moonshot API without any additional features. This is the simplest way to get started with Moonshot if you only need to use the API. Install with: <pre><code>$ pip install aiverify-moonshot\n</code></pre></p>"},{"location":"getting_started/installation/#enabling-moonshot-web-api","title":"Enabling Moonshot Web API","text":"<p>The Moonshot Web API enables you to interact with the Moonshot Library through HTTP requests. The Web API accomodates building a web application or accessing the Moonshot Library from a remote machine. Install with: <pre><code>$ pip install \"aiverify-moonshot[web-api]\"\n</code></pre></p>"},{"location":"getting_started/installation/#enabling-moonshot-cli","title":"Enabling Moonshot CLI","text":"<p>The Moonshot CLI enables you to interact with the Moonshot Library through your terminal. This allows you to run Moonshot commands directly from your terminal. </p> <pre><code>$ pip install \"aiverify-moonshot[cli]\"\n</code></pre>"},{"location":"getting_started/installation/#enabling-both-cli-and-webapi","title":"Enabling Both CLI and WebAPI","text":"<p>This command enables you to interact with the Moonshot Library through HTTP requests and CLI. It gives you the most flexibility, as you can interact with Moonshot through both command-line commands and HTTP requests. <pre><code>$ pip install \"aiverify-moonshot[all]\"\n</code></pre></p>"},{"location":"getting_started/installation/#installation-from-source","title":"Installation from Source","text":"<p>The source code is available on GitHub here. Ensure that git is installed before proceeding with below steps.</p> <ol> <li>Download the source files by cloning the repository: <pre><code>$ git clone https://github.com/moonshot-admin/moonshot.git\n</code></pre></li> <li>Change directory to project's root directory: <pre><code>cd moonshot\n</code></pre></li> <li>Checkout to the run-moonshot branch (temporary step): <pre><code>git checkout run-moonshot\n</code></pre></li> <li>Install the required packages: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/installation/#installation-from-pypi-latest","title":"Installation from PyPi (Latest)","text":"<p>The source code is available on GitHub here. Ensure that git is installed before proceeding with below steps.</p>"},{"location":"getting_started/installation/#installation","title":"Installation","text":"<p>Install the Moonshot package using pip by fetching the package from the specificied repository: <pre><code>$ pip install -i https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple \"projectmoonshot-imda[all]==0.3.13\"\n</code></pre></p>"},{"location":"getting_started/installation/#running-moonshot","title":"Running Moonshot","text":"<p>Moonshot can be run in 3 different modes depending on your needs:  1. Web and API Server  2. API Server  3. CLI </p> <p>Before running Moonshot, clone Moonshot data from GitHub:</p> <pre><code>$ python -m moonshot -i moonshot-data\n</code></pre>"},{"location":"getting_started/installation/#web-and-api-server","title":"Web and API Server","text":"<p>Before running the Web and API server, make sure moonshot-ui is installed. To clone moonshot-ui from GitHub:</p> <pre><code>$ python -m moonshot -i moonshot-ui\n</code></pre> <p>To start web-API server and UI server:</p> <pre><code>$ python -m moonshot web\n</code></pre>"},{"location":"getting_started/installation/#api-server","title":"API Server","text":"<p>To run the web-API only: <pre><code>$ python -m moonshot web-api\n</code></pre></p>"},{"location":"getting_started/installation/#cli-commands","title":"CLI Commands","text":"<p>To execute CLI commands: <pre><code>$ python -m moonshot cli [command]\n</code></pre></p> <p>Replace [command] with a specific CLI command. For example, to run a recipe: <pre><code>$ python -m moonshot cli list_cookbooks\n</code></pre></p> <p>Alternatively, to enter interactive mode in CLI (Recommended): <pre><code>$ python -m moonshot cli interactive\n</code></pre></p>"},{"location":"getting_started/installation/#additional-arguments","title":"Additional Arguments","text":""},{"location":"getting_started/installation/#specify-custom-environment-file","title":"Specify Custom Environment File","text":"<p>If you have a custom '.env' file, specify the path to the file as follows: <pre><code>python -m moonshot -e /path/to/your/.env\n</code></pre></p>"},{"location":"getting_started/installation/#others","title":"Others","text":"<p>You can also combine additional arguments with Moonshot's run commands like this:</p> <pre><code>python -m moonshot web -i moonshot-data -i moonshot-ui -e /path/to/your/.env\n</code></pre> <p>This example demonstrates how to launch the Moonshot web server with additional parameters to install moonshot-data and moonshot-ui, and to configure it using a specified '.env' file.</p>"},{"location":"getting_started/installation_cli/","title":"Installing Moonshot for CLI","text":""},{"location":"getting_started/installation_cli/#preinstallation-requirements","title":"Preinstallation Requirements","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git <p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre> <p>There are 2 ways to install Moonshot - PyPi (Method 1) or Source (Method 2).</p>"},{"location":"getting_started/installation_cli/#method-1-installation-from-pypi","title":"Method 1: Installation from PyPi","text":"<p>You can find the Moonshot Package here. The source code is available on GitHub.</p>"},{"location":"getting_started/installation_cli/#installing-the-moonshot-library","title":"Installing the Moonshot Library","text":"<p>The Moonshot Library allows you to interact with the Moonshot API without any additional features. This is the simplest way to get started with Moonshot if you only need to use the API. Install with: <pre><code>$ pip install aiverify-moonshot\n</code></pre></p>"},{"location":"getting_started/installation_cli/#enabling-moonshot-cli","title":"Enabling Moonshot CLI","text":"<p>The Moonshot CLI enables you to interact with the Moonshot Library through your terminal. This allows you to run Moonshot commands directly from your terminal. </p> <pre><code>$ pip install \"aiverify-moonshot[cli]\"\n</code></pre>"},{"location":"getting_started/installation_cli/#method-2-installation-from-source","title":"Method 2: Installation from Source","text":"<p>The source code is available on GitHub here. Ensure that git is installed before proceeding with below steps.</p> <ol> <li>Download the source files by cloning the repository: <pre><code>$ git clone https://github.com/moonshot-admin/moonshot.git\n</code></pre></li> <li>Change directory to project's root directory: <pre><code>cd moonshot\n</code></pre></li> <li>Install the required packages: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/installation_cli/#running-moonshot","title":"Running Moonshot","text":"<p>Before running Moonshot, ensure that git is installed. Clone Moonshot data from GitHub:</p> <pre><code>$ python -m moonshot -i moonshot-data\n</code></pre>"},{"location":"getting_started/installation_cli/#cli-commands","title":"CLI Commands","text":"<p>To execute CLI commands: <pre><code>$ python -m moonshot cli [command]\n</code></pre></p> <p>Replace [command] with a specific CLI command. For example, to run a recipe: <pre><code>$ python -m moonshot cli list_cookbooks\n</code></pre></p> <p>Alternatively, to enter interactive mode in CLI (Recommended): <pre><code>$ python -m moonshot cli interactive\n</code></pre></p>"},{"location":"getting_started/installation_cli/#additional-arguments","title":"Additional Arguments","text":""},{"location":"getting_started/installation_cli/#specify-custom-environment-file","title":"Specify Custom Environment File","text":"<p>If you have a custom '.env' file, specify the path to the file as follows: <pre><code>python -m moonshot -e /path/to/your/.env\n</code></pre></p>"},{"location":"getting_started/installation_cli/#others","title":"Others","text":"<p>You can also combine additional arguments with Moonshot's run commands like this:</p> <pre><code>python -m moonshot cli interactive -i moonshot-data -i moonshot-ui -e /path/to/your/.env\n</code></pre> <p>This example demonstrates how to launch the Moonshot CLI with additional parameters to install moonshot-data and moonshot-ui, and to configure it using a specified '.env' file.</p>"},{"location":"getting_started/installation_ui/","title":"Installing Moonshot for User Interface","text":""},{"location":"getting_started/installation_ui/#preinstallation-requirements","title":"Preinstallation Requirements","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git <p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre> <p>There are 2 ways to install Moonshot - PyPi (Method 1) or Source (Method 2). </p>"},{"location":"getting_started/installation_ui/#method-1-installation-from-pypi","title":"Method 1: Installation from PyPi","text":"<p>You can find the Moonshot Package here. The source code is available on GitHub.</p>"},{"location":"getting_started/installation_ui/#installing-the-moonshot-library","title":"Installing the Moonshot Library","text":"<p>The Moonshot Library allows you to interact with the Moonshot API without any additional features. This is the simplest way to get started with Moonshot if you only need to use the API. Install with: <pre><code>$ pip install aiverify-moonshot\n</code></pre></p>"},{"location":"getting_started/installation_ui/#enabling-moonshot-ui","title":"Enabling Moonshot UI","text":"<p>The Moonshot UI enables you to interact with the Moonshot Library through a User Interface. Install with: <pre><code>$ pip install \"aiverify-moonshot[web-api]\"\n</code></pre></p> <p>Alternatively, for the greatest flexibility, to interact with the Moonshot Library through both CLI and HTTP, install with:  <pre><code>$ pip install \"aiverify-moonshot[all]\"\n</code></pre></p>"},{"location":"getting_started/installation_ui/#method-2-installation-from-source","title":"Method 2: Installation from Source","text":"<p>The source code is available on GitHub here. Ensure that git is installed before proceeding with below steps.</p> <ol> <li>Download the source files by cloning the repository: <pre><code>$ git clone https://github.com/moonshot-admin/moonshot.git\n</code></pre></li> <li>Change directory to project's root directory: <pre><code>cd moonshot\n</code></pre></li> <li>Install the required packages: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/installation_ui/#running-moonshot","title":"Running Moonshot","text":"<ol> <li> <p>Before running the Moonshot User Interface, clone Moonshot data and Moonshot UI from GitHub:</p> <pre><code>$ python -m moonshot -i moonshot-data\n$ python -m moonshot -i moonshot-ui\n</code></pre> </li> </ol> <p>  Find out more about what <code>-i moonshot-ui</code> does here.</p> <ol> <li> <p>To run the User Interface:</p> <pre><code>$ python -m moonshot web\n</code></pre> </li> </ol> <p>Access the Web UI from browser <code>http://localhost:3000</code></p>"},{"location":"getting_started/installation_ui/#additional-arguments","title":"Additional Arguments","text":""},{"location":"getting_started/installation_ui/#specify-custom-environment-file","title":"Specify Custom Environment File","text":"<p>If you have a custom '.env' file, specify the path to the file as follows: <pre><code>python -m moonshot -e /path/to/your/.env\n</code></pre></p>"},{"location":"getting_started/installation_ui/#others","title":"Others","text":"<p>You can also combine additional arguments with Moonshot's run commands like this:</p> <pre><code>python -m moonshot web -i moonshot-data -i moonshot-ui -e /path/to/your/.env\n</code></pre> <p>This example demonstrates how to launch the Moonshot UI with additional parameters to install moonshot-data and moonshot-ui, and to configure it using a specified '.env' file.</p>"},{"location":"getting_started/installation_web_api/","title":"Installing Moonshot for Web API","text":""},{"location":"getting_started/installation_web_api/#preinstallation-requirements","title":"Preinstallation Requirements","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git <p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre> <p>There are 2 ways to install Moonshot - PyPi (Method 1) or Source (Method 2).</p>"},{"location":"getting_started/installation_web_api/#method-1-installation-from-pypi","title":"Method 1: Installation from PyPi","text":"<p>You can find the Moonshot Package here. The source code is available on GitHub.</p>"},{"location":"getting_started/installation_web_api/#installing-the-moonshot-library","title":"Installing the Moonshot Library","text":"<p>The Moonshot Library allows you to interact with the Moonshot API without any additional features. This is the simplest way to get started with Moonshot if you only need to use the API. Install with: <pre><code>$ pip install aiverify-moonshot\n</code></pre></p>"},{"location":"getting_started/installation_web_api/#enabling-moonshot-web-api","title":"Enabling Moonshot Web API","text":"<p>The Moonshot Web API enables you to interact with the Moonshot Library through HTTP requests. The Web API accomodates building a web application or accessing the Moonshot Library from a remote machine. Install with: <pre><code>$ pip install \"aiverify-moonshot[web-api]\"\n</code></pre></p> <p>Alternatively, for the greatest flexibility, to interact with the Moonshot Library through both CLI and HTTP, install with:  <pre><code>$ pip install \"aiverify-moonshot[all]\"\n</code></pre></p>"},{"location":"getting_started/installation_web_api/#method-2-installation-from-source","title":"Method 2: Installation from Source","text":"<p>The source code is available on GitHub here. Ensure that git is installed before proceeding with below steps.</p> <ol> <li>Download the source files by cloning the repository: <pre><code>$ git clone https://github.com/moonshot-admin/moonshot.git\n</code></pre></li> <li>Change directory to project's root directory: <pre><code>cd moonshot\n</code></pre></li> <li>Install the required packages: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/installation_web_api/#running-moonshot-web-api","title":"Running Moonshot Web API","text":"<ol> <li> <p>Before running Moonshot, clone Moonshot data from GitHub:     <pre><code>$ python -m moonshot -i moonshot-data\n</code></pre></p> </li> <li> <p>To run the web API:     <pre><code>$ python -m moonshot web-api\n</code></pre></p> </li> </ol>"},{"location":"getting_started/installation_web_api/#additional-arguments","title":"Additional Arguments","text":""},{"location":"getting_started/installation_web_api/#specify-custom-environment-file","title":"Specify Custom Environment File","text":"<p>If you have a custom '.env' file, specify the path to the file as follows: <pre><code>python -m moonshot -e /path/to/your/.env\n</code></pre></p>"},{"location":"getting_started/installation_web_api/#others","title":"Others","text":"<p>You can also combine additional arguments with Moonshot's run commands like this:</p> <pre><code>python -m moonshot web-api -i moonshot-data -i moonshot-ui -e /path/to/your/.env\n</code></pre> <p>This example demonstrates how to launch the Moonshot web api server with additional parameters to install moonshot-data and moonshot-ui, and to configure it using a specified '.env' file.</p>"},{"location":"getting_started/overview/","title":"Moonshot","text":"<p>Developed by the AI Verify Foundation, Project Moonshot is one of the first tools to bring benchmarking and red teaming together to help AI developers, compliance teams and AI system owners test and evaluate their LLMs and LLM applications.</p>"},{"location":"getting_started/overview/#what-does-moonshot-do","title":"What does Moonshot do?","text":"<p>Moonshot provides ready access to test LLMs from popular model providers E.g., OpenAI, Anthropic, Together, HuggingFace. You will just need to provide your API Key. See Model Connectors Available.</p> <p>If you are testing other models or your own LLM Application hosted on a custom server, you will need to create your own Model Connector. Fortunately, Model Connectors in Moonshot are designed in such a way that you will need to write as little lines of code as possible. How to create a custom model connector.</p>"},{"location":"getting_started/overview/#benchmark","title":"Benchmark","text":"<p>Benchmarks are \u201cExam questions\u201d to test the model across a variety of competencies, e.g., language and context understanding.</p> <p>Project Moonshot offers a range of benchmarks to measure your LLM application's performance in Capability, Quality, and Trust &amp; Safety. These include benchmarks widely used by the community like Google's BigBench and HuggingFace's leaderboards, and more domain/task specific tests like Tamil Language and Medical LLM benchmarks.</p>"},{"location":"getting_started/overview/#red-teaming","title":"Red Teaming","text":"<p>Red-Teaming is the adversarial prompting of LLM applications to induce them to behave in a manner incongruent with their design. This process is crucial to identify vulnerabilities in AI systems.</p> <p>Project Moonshot simplifies the process of Red-Teaming by providing an easy to use interface that allows for the simulataneous probing of multiple LLM applications, and equipping you with Red-Teaming tools like prompt templates, context strategies and attack modules.</p>"},{"location":"getting_started/overview/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>As Red-Teaming conventionally relies on human ingenuity, it is hard to scale. Project Moonshot has developed some attack modules based on research-backed techniques that will enable you to automatically generate adversarial prompts.</p>"},{"location":"getting_started/overview/#glossary","title":"Glossary","text":"Term Description Connector Model Connectors in Moonshot enable users to integrate new models into the toolkit by connecting to their Large Language Models (LLMs) via API connectors. Cookbook The Cookbook in Moonshot contains one or more recipes, each designed to generate results when selected to run with the model endpoints. It serves as a comprehensive guide for conducting evaluations and tests, offering a structured approach to assessing LLM applications' performance and addressing potential risks. Recipe A Recipe in Moonshot brings together 3 essential components. A recipe can contain one or more datasets, prompt templates and metrics. Datasets Datasets consist of a collection of input-target pairs, where the 'input' is a prompt provided to the LLM (being tested), and the 'target' is the correct response or ground truth. Session A Session feature allows users to initiate interactions with selected models, enabling them to engage in chats and send prompts to red team the models. Chat A Chat refers to an interaction directed to a specific model within a session, initiating the red teaming prompt process. Users can communicate with individual models, sending prompts and assessing their responses to identify potential vulnerabilities and areas for improvement in LLM applications."},{"location":"getting_started/preinstallation/","title":"Installing Moonshot","text":""},{"location":"getting_started/preinstallation/#preinstallation-requirements","title":"Preinstallation Requirements","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git <p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre> <p>Moonshot is currently available in 3 versions. Find out which version suits your needs best here. To access the proceed with installation, click on the relevant link: 1) Command Line Interface (CLI) 2) User Interface (UI) 3) Web Application Programming Interface (Web API)  </p>"},{"location":"getting_started/quick_install/","title":"Installing Moonshot for User Interface","text":""},{"location":"getting_started/quick_install/#dependencies-needed-for-installation","title":"Dependencies needed for installation","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git"},{"location":"getting_started/quick_install/#install-moonshot","title":"Install Moonshot","text":"<p>Run the following command in a virtual environment of your choice:</p> <pre><code>$ pip install \"aiverify-moonshot[all]\"\n</code></pre> <p>Once install, Moonshot provides commands to download all the test assets required to start testing your AI system:</p> <pre><code>$ python -m moonshot -i moonshot-data -i moonshot-ui\n</code></pre> <p>Run Moonshot UI with the following command:</p> <pre><code>$ python -m moonshot web\n</code></pre> <p>Lastly, access Moonshot UI using a browser (<code>http://localhost:3000</code>).</p>"},{"location":"getting_started/quick_install/#extra-resources","title":"Extra Resources","text":""},{"location":"getting_started/quick_install/#setting-up-virtual-environment","title":"Setting up Virtual Environment","text":"<p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre>"},{"location":"getting_started/quick_install/#specifying-custom-environment-file","title":"Specifying Custom Environment File","text":"<p>If you have a custom '.env' file, specify the path to the file as follows: <pre><code>python -m moonshot -e /path/to/your/.env\n</code></pre></p>"},{"location":"getting_started/quick_start_cli/","title":"Quick Start Guide (CLI)","text":""},{"location":"getting_started/quick_start_cli/#setting-up","title":"Setting Up","text":""},{"location":"getting_started/quick_start_cli/#step-0-creating-virtual-environment","title":"Step 0: Creating virtual environment","text":"<p>We highly recommend creating a virtual environment to avoid any conflicts in the Python libraries.</p>"},{"location":"getting_started/quick_start_cli/#step-1-install-moonshot","title":"Step 1: Install Moonshot","text":"<ol> <li> <p>To begin, install Moonshot from the designated source (e.g., GitHub/PyPi). <pre><code>$ git clone git@github.com:moonshot-admin/moonshot.git\n\nOR \n\n$ pip install \"projectmoonshot-imda[cli]\"\n</code></pre></p> </li> <li> <p>Install Required Dependencies</p> </li> <li>Ensure that all necessary requirements are installed by executing the appropriate command provided in the documentation.</li> <li>If you are installing the project from GitHub, run the following command: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/quick_start_cli/#step-2-environment-variables-optional","title":"Step 2: Environment Variables (Optional)","text":"<ul> <li>You can link your own data folder with the library by running the following code snippet:</li> </ul> <pre><code>CONNECTORS = \"/path/to/your/connectors\"\nRECIPES = \"/path/to/your/recipes\"\nCOOKBOOKS = \"/path/to/your/cookbooks\"\nDATASETS = \"/path/to/your/datasets\"\nPROMPT_TEMPLATES = \"/path/to/your/prompt-templates\"\nMETRICS = \"/path/to/your/metrics\"\nMETRICS_CONFIG = \"/path/to/your/metrics/metrics_config.json\"\nCONTEXT_STRATEGY = \"/path/to/your/context-strategy\"\nRESULTS = \"/path/to/your/results\"\nDATABASES = \"/path/to/your/databases\"\nSESSIONS = \"/path/to/your/sessions\"\n</code></pre> <p>Note</p> <p>When changing the reference folder for data, users will no longer be able to access the stock cookbooks. To access these cookbooks, users should copy over their respctive json files and dependencies_</p>"},{"location":"getting_started/quick_start_cli/#step-3-starting-moonshot-cli","title":"Step 3: Starting Moonshot CLI","text":"<p>There are two available modes to use Moonshot CLI. Command-Based Mode and Interactive Mode.</p> <p>For a better experience, we recommend using the Interactive Mode. To use interactive mode, run this code: <pre><code>python -m moonshot cli interactive\n</code></pre></p> <p>You should see the command prompt change to <code>moonshot &gt;</code> like this: <pre><code>moonshot &gt; \n</code></pre></p> <p>For this quick start guide, we will be using Interactive Mode as an example.</p> <p>To start off, you can use the commmand <code>help</code> to view all the available commands in Moonshot CLI. <pre><code>moonshot &gt; help\n</code></pre></p>"},{"location":"getting_started/quick_start_cli/#step-4-creating-endpoint","title":"Step 4: Creating Endpoint","text":"<p>You can establish connectivity to an LLM or LLM application by creating an endpoint with your environment.</p> <ul> <li>View the list of conenctor type availables in Moonshot with this: <pre><code>moonshot &gt; list_connector_types\n</code></pre></li> <li>Create new endpoint with:  <pre><code>moonshot &gt; add_endpoint openai-gpt35 my-openai-endpoint MY_URI ADD_YOUR_TOKEN_HERE 10 2 \"{'temperature': 0}\"\n</code></pre></li> <li>To view the parameters required, you can run the command with the help tag. <pre><code>moonshot &gt; add_endpoint -h \n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_cli/#benchmarking","title":"Benchmarking","text":""},{"location":"getting_started/quick_start_cli/#step-1-creating-custom-recipecookbook-optional","title":"Step 1: Creating Custom Recipe/Cookbook (Optional)","text":"<p>You can create a custom recipe consisting of a dataset, metric and prompt templates.</p> <p>This step allows you to tailor the benchmarking process to your specific need and objective.</p> <ul> <li>To add a new recipe, use the <code>add_recipe</code> command.  <pre><code> moonshot &gt; add_recipe 'My new recipe' 'I am recipe description' \"['tag1','tag2']\" \"['bbq-lite-age-ambiguous']\" \"['analogical-similarity','auto-categorisation']\" \"['bertscore','bleuscore']\"\n</code></pre></li> <li>To add a new cookbook, use the <code>add_cookbook</code> command. <pre><code>moonshot &gt; add_cookbook 'My new cookbook' 'I am cookbook description' \"['analogical-similarity','auto-categorisation']\"\n</code></pre></li> <li>To view the parameters required, you can run the command with the help tag. <pre><code>moonshot &gt; add_recipe -h # To view the parameter required to add recipe.\nmoonshot &gt; add_cookbook -h # To view the paramter required to add cookbook.\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_cli/#step-2-select-recipe-cookbook-to-run-a-benchmark","title":"Step 2: Select Recipe / Cookbook to Run a Benchmark","text":"<p>To run a benchmark, select a recipe or cookbook that aligns with your desired evaluation or analysis objective.</p> <ul> <li>To start benchmarking using a recipe, use the <code>run_recipe</code> command. <pre><code>moonshot &gt; run_recipe -n 1 \"['bbq','auto-categorisation']\" \"['test-openai-endpoint']\"\n</code></pre></li> <li>To start benchmarking using a cookbook, use the <code>run_cookbook</code> command. <pre><code>moonshot &gt; run_cookbook -n 1 \"['bbq-lite-age-cookbook']\" \"['test-openai-endpoint']\"\n</code></pre></li> <li>To view the parameters required, you can run the command with the help tag. <pre><code>moonshot &gt; run_recipe -h # To view the parameter required to run recipe.\nmoonshot &gt; run_cookbook -h # To view the paramter required to run cookbook.\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_cli/#step-3-view-results","title":"Step 3: View Results","text":"<ul> <li>To view the list of result, use the <code>list_results</code> command. <pre><code>moonshot &gt; list_results\n</code></pre></li> <li>To view the result, use the <code>view_result</code> command. <pre><code>moonshot &gt; view_result cookbook-my-new-cookbook-executor\n</code></pre></li> <li>To view the parameters required, you can run the command with the help tag. <pre><code>moonshot &gt; view_result -h # To view the parameter required to view results.\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_cli/#red-teaming","title":"Red Teaming","text":""},{"location":"getting_started/quick_start_cli/#step-1-create-a-red-teaming-session","title":"Step 1: Create a Red Teaming session","text":"<p>To begin, create a Red Teaming session with the list of endpoins you wish to test.</p> <ul> <li>To create a new sesion, use the <code>new_session</code> command. <pre><code>moonshot &gt; new_session 'my_new_session' 'My new session description' \"['my-openai-gpt35', 'my-openai-gpt4']\"\n</code></pre></li> <li>To view the parameters required, you can run the command with the help tag. <pre><code>moonshot &gt; new_session -h # To view the parameter required to create a new session.\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_cli/#step-2-using-created-session","title":"Step 2: Using created session.","text":"<p>To start red teaming, you would have to enter the session that you have created.</p> <ul> <li>To enter the created session, use the <code>use_session</code> command.  <pre><code> use_session 'my-my_new_session'\n</code></pre></li> <li>To view the parameters required, you can run the command with the help tag. <pre><code>moonshot &gt; use_session -h # To view the parameter required to use a session.\n</code></pre></li> </ul> <p>Once you entered a session, your command prompt should change to look like this with the value of <code>session_id</code> being of a certain value.  <pre><code>moonshot (my-new-session_{session_id}) [PT: , CS: ] &gt;\n</code></pre></p>"},{"location":"getting_started/quick_start_cli/#step-3-remove-and-adding-prompt-tempaltes-or-context-strategies","title":"Step 3: Remove and Adding Prompt Tempaltes or Context Strategies","text":"<p>Optionally, you can utilize prompt templates and context strategies to customize augment prompts that are sent to the model.</p> <p>The prompt template provides pre-prompt and post-prompt text are passed into the LLM/LLM application along with your prompt.</p> <p>A context strategy defines additional information from the chat history that will be appended to your prompt as a 'context'. Examples of a 'context' includes a summary of the previous n-prompts.</p> <ul> <li>To view the list of prompt template and contexst strategy, use this two commands. <pre><code>list_prompt_templates\nlist_contexst_strategies\n</code></pre></li> <li>To load prompt template, use the <code>use_prompt_template</code> command. <pre><code> use_prompt_template 'analogical-similarity'\n</code></pre></li> <li>To load a context strategy, use the <code>use_context_strategy</code> command. <pre><code> use_context_strategy 'add_previous_prompt'\n</code></pre></li> </ul> <p>When you have successfully loaded your prompt template and context strategy, your command prompt should look like this:  <pre><code>moonshot (my-new-session_{session_id}) [PT: analogical-similarity, CS: add_previous_prompt] &gt;\n</code></pre> - To remove prompt template and context strategy, use this two commands. <pre><code>clear_prompt_template\nclear_context_strategy\n</code></pre> Your prompt template and context strategy should be unloaded and your command prompt will look like this:  <pre><code>moonshot (my-new-session_{session_id}) [PT: , CS: ] &gt;\n</code></pre></p>"},{"location":"getting_started/quick_start_cli/#step-4-analyze-results","title":"Step 4: Analyze Results","text":"<p>Analyze the results from benchmarking or red teaming to assess the security posture or vulnerabilities of the target systems. Interpret the responses to identify potential weaknesses or areas for improvement in the tested environment.</p>"},{"location":"getting_started/quick_start_library/","title":"Quick Start Guide (Library)","text":"<p>Refer to this example for the usage of Moonshot.</p>"},{"location":"getting_started/quick_start_library/#setting-up","title":"Setting Up","text":""},{"location":"getting_started/quick_start_library/#step-0-creating-virtual-environment","title":"Step 0: Creating virtual environment","text":"<p>We highly recommend creating a virtual environment to avoid any conflicts in the Python libraries.</p>"},{"location":"getting_started/quick_start_library/#step-1-install-moonshot","title":"Step 1: Install Moonshot","text":"<ol> <li> <p>To begin, install Moonshot from the designated source (e.g., GitHub/PyPi). <pre><code>$ git clone git@github.com:moonshot-admin/moonshot.git\n\nOR \n\n$ pip install projectmoonshot-imda\n</code></pre></p> </li> <li> <p>Install Required Dependencies</p> </li> <li>Ensure that all necessary requirements are installed by executing the appropriate command provided in the documentation.</li> <li>If you are installing the project from GitHub, run the following command: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/quick_start_library/#step-2-importing-moonshot","title":"Step 2: Importing Moonshot","text":"<ul> <li>Import Moonshot as a library to use it.  <pre><code>from moonshot.api import (\n    api_create_recipe,\n    api_create_cookbook,\n    api_create_endpoint,\n    api_create_recipe_executor,\n    api_create_cookbook_executor,\n    api_create_session,\n    api_get_session,\n    api_get_all_connector_type,\n    api_get_all_endpoint,\n    api_get_all_cookbook,\n    api_get_all_recipe,\n    api_get_all_executor,\n    api_get_all_session_detail,\n    api_get_all_prompt_template_detail,\n    api_get_all_context_strategy_name,\n    api_get_session_chats_by_session_id,\n    api_load_executor,\n    api_set_environment_variables,\n    api_send_prompt,\n    api_update_context_strategy,\n    api_update_prompt_template,\n)\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_library/#step-3-environment-variables-optional","title":"Step 3: Environment Variables (Optional)","text":"<ul> <li>You can link your own data folder with the library by running the following code snippet:</li> </ul> <pre><code>moonshot_path = \"../moonshot/data/\"\n\nenv = {\n    \"CONNECTORS_ENDPOINTS\": os.path.join(moonshot_path, \"connectors-endpoints\"),\n    \"CONNECTORS\": os.path.join(moonshot_path, \"connectors\"),\n    \"RECIPES\": os.path.join(moonshot_path, \"recipes\"),\n    \"COOKBOOKS\": os.path.join(moonshot_path, \"cookbooks\"),\n    \"DATASETS\": os.path.join(moonshot_path, \"datasets\"),\n    \"PROMPT_TEMPLATES\": os.path.join(moonshot_path, \"prompt-templates\"),\n    \"METRICS\": os.path.join(moonshot_path, \"metrics\"),\n    \"METRICS_CONFIG\": os.path.join(moonshot_path, \"metrics/metrics_config.json\"),\n    \"CONTEXT_STRATEGY\": os.path.join(moonshot_path, \"context-strategy\"),\n    \"RESULTS\": os.path.join(moonshot_path, \"results\"),\n    \"DATABASES\": os.path.join(moonshot_path, \"databases\"),\n    \"SESSIONS\": os.path.join(moonshot_path, \"sessions\"),\n}\n\napi_set_environment_variables(env)\n</code></pre>"},{"location":"getting_started/quick_start_library/#step-4-connecting-endpoints","title":"Step 4: Connecting Endpoints","text":"<p>You can establish connectivity to an LLM or LLM application by creating an endpoint within your environment.</p> <ul> <li>View the list of connector types available in Moonshot with: <pre><code>api_get_all_connector_type()\n</code></pre></li> <li>Create a new endpoint with:  <pre><code>api_create_endpoint()\n</code></pre></li> <li>The following is a code snippet to create an endpoint: <pre><code>api_create_endpoint(\n    \"test-openai-endpoint\", # name: give it a name to retrieve it later\n    \"openai-gpt35\", # connector_type: the model that we want to evaluate\n    \"\", # uri: not required as we use OpenAI library to connect to their models.\n    \"ADD_NEW_TOKEN_HERE\", # token: access token\n    10, # max_calls_per_second: the number of max calls per second\n    2, # max_concurrency: the number of concurrent call at any one time,\n    {\n        \"temperature\": 0\n    } # params: any additional required for this model\n)\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_library/#benchmarking","title":"Benchmarking","text":""},{"location":"getting_started/quick_start_library/#step-1-create-custom-recipecookbook-optional","title":"Step 1: Create Custom Recipe/Cookbook (Optional)","text":"<p>You can create a custom recipe consisting of a dataset, metric and prompt templates.</p> <p>This step allows you to tailor the benchmarking process to your specific need and objective.</p> <ul> <li> <p>To add a new recipe, use <code>api_create_recipe()</code>. The code snippet below uses a dataset and prompt template from the baseline benchmarks available in Moonshot. <pre><code>api_create_recipe(\n    \"auto-categorisation-2\" # name of recipe\n    \"A duplicate of the existing Auto Categorisation recipe with a different name.\", # description of recipe\n    [], # tags\n    [\"auto-categorisation\"], # datasets\n    [\"auto-categorisation\"], # prompt templates\n    [\"relaxstrmatch\"], # metrics\n    \"benchmark\", # type\n    [], # attack_strategies\n)\n</code></pre></p> </li> <li> <p>To add a new cookbook, use api_create_cookbook().  <pre><code>api_create_cookbook(\n    \"new-cookbook\", # name of cookbook\n    \"This cookbook is a compiled auto-categorisation cookbook\", # description of cookbook\n    [\"auto-categorisation\",\"auto-categorisation-2\"] # list of recipes\n)\n</code></pre></p> </li> </ul>"},{"location":"getting_started/quick_start_library/#step-2-select-recipecookbook-to-run-a-benchmark","title":"Step 2: Select Recipe/Cookbook to Run a Benchmark","text":"<p>To run a benchmark, select a recipe or cookbook that aligns with your desired evaluation or analysis objective.</p> <ul> <li>To start benchmarking using a recipe, use <code>api_create_recipe_runner()</code>. <pre><code>recipes = [\"auto-categorisation-2\"]\nendpoints = [\"test-openai-endpoint\"]\nnum_of_prompts = 5 # use a smaller number to test out the function\n\nbm_runner = api_create_recipe_runner(\n    \"my new recipe runner\",\n    recipes,\n    endpoints,\n    num_of_prompts\n)\n</code></pre></li> <li>To start benchmarking using a cookbook, use <code>api_create_cookbook_runner()</code>. <pre><code>cookbooks = [\"new-cookbook\"]\nendpoints = [\"test-openai-endpoint\"]\nnum_of_prompts = 1\n\nbm_runner = api_create_cookbook_runner(\n    \"my new cookbook runner\",\n    cookbooks,\n    endpoints,\n    num_of_prompts\n)\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_library/#step-3-view-results","title":"Step 3: View Results","text":"<p>The results will be stored in the <code>moonshot/data/results</code> directory by default. However, if a custom path is defined during the Set Up process, the results will be stored there instead.</p> <p>Analyze the output to gain insight into the performance your model/application.</p>"},{"location":"getting_started/quick_start_library/#red-teaming","title":"Red Teaming","text":""},{"location":"getting_started/quick_start_library/#step-1-create-a-red-teaming-session","title":"Step 1: Create a Red Teaming session","text":"<p>To begin, create a Red Teaming session with the list of endpoints you wish to test.</p> <pre><code>endpoints = [\"test-openai-endpoint\"]\n\nmy_rt_session = api_create_session(\n    \"My Red Teaming Session\", #session name\n    \"Creating a new red teaming description\", # session description\n    endpoints,\n    \"add_previous_prompt\", # context strategy [optional]\n    \"legal-term-template\", # prompt template [optional]\n)\n</code></pre>"},{"location":"getting_started/quick_start_library/#step-2-store-session-id","title":"Step 2: Store Session ID","text":"<ul> <li>After creating a session, store the <code>session_id</code> as a variable for future use.</li> <li>This <code>session_id</code> will be needed for additional functions and operations. <pre><code>session_id = my_rt_session.metadata.session_id\n\n# To see session details\nshow_session(my_rt_session)\n</code></pre></li> </ul>"},{"location":"getting_started/quick_start_library/#step-2-send-prompts","title":"Step 2: Send Prompts","text":"<p>Utilize the toolkit to send prompts to the configured endpoints. Create prompts that are specifically crafted to elicit responses or actions from the target LLM or applications.</p> <pre><code>prompt = \"What is the largest fruit\"\n\nawait api_send_prompt(session_id, prompt)\n\nshow_session_chats(api_get_session_chats_by_session_id(session_id))\n</code></pre>"},{"location":"getting_started/quick_start_library/#step-3-remove-and-adding-prompt-templates-or-context-strategies","title":"Step 3: Remove and Adding Prompt Templates or Context Strategies","text":"<p>Optionally, you can utilize prompt templates and context strategies to customize augment prompts that are sent to the model.</p> <p>The prompt template provides pre-prompt and post-prompt text are passed into the LLM/LLM application along with your prompt.</p> <p>A context strategy defines additional information from the chat history that will be appended to your prompt as a 'context'. Examples of a 'context' includes a summary of the previous n-prompts.</p> <pre><code>context_strategy = \"add_previous_prompt\"\nprompt_template = \"test-prompt-template\"\n\napi_update_context_strategy(session_id, context_strategy)\napi_update_prompt_template(session_id, prompt_template)\n\n# Get updated session\nupdated_session = api_get_session(session_id)\n</code></pre> <p>Use these commands to view the list of prompt templates and context strategies. <pre><code>api_get_all_prompt_template_detail()\napi_get_all_context_strategy_name()\n</code></pre></p>"},{"location":"getting_started/quick_start_library/#step-4-analyze-results","title":"Step 4: Analyze Results","text":"<p>Analyze the results from benchmarking or red teaming to assess the security posture or vulnerabilities of the target systems. Interpret the responses to identify potential weaknesses or areas for improvement in the tested environment.</p>"},{"location":"getting_started/quick_start_ui/","title":"Quick Start Guide (User Interface)","text":""},{"location":"getting_started/quick_start_ui/#setting-up","title":"Setting Up","text":""},{"location":"getting_started/quick_start_ui/#step-0-creating-a-virtual-environment","title":"Step 0: Creating a virtual environment","text":"<p>We highly recommend creating a virtual environment to avoid any conflicts in the Python libraries.</p>"},{"location":"getting_started/quick_start_ui/#step-1-install-moonshot","title":"Step 1: Install Moonshot","text":"<ol> <li> <p>To begin, install Moonshot from the designated source (e.g., GitHub/PyPi). <pre><code>$ git clone git@github.com:moonshot-admin/moonshot.git\n\nOR \n\n$ pip install \"projectmoonshot-imda[web-api]\"\n</code></pre></p> </li> <li> <p>Install Required Dependencies</p> </li> <li>Ensure that all necessary requirements are installed by executing the appropriate command provided in the documentation.</li> <li>If you are installing the project from GitHub, run the following command: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/quick_start_ui/#step-2-environment-variables-optional","title":"Step 2: Environment Variables (Optional)","text":"<ul> <li>You can link your own data folder with the library by running the following code snippet:</li> </ul> <pre><code>CONNECTORS = \"/path/to/your/connectors\"\nRECIPES = \"/path/to/your/recipes\"\nCOOKBOOKS = \"/path/to/your/cookbooks\"\nDATASETS = \"/path/to/your/datasets\"\nPROMPT_TEMPLATES = \"/path/to/your/prompt-templates\"\nMETRICS = \"/path/to/your/metrics\"\nMETRICS_CONFIG = \"/path/to/your/metrics/metrics_config.json\"\nCONTEXT_STRATEGY = \"/path/to/your/context-strategy\"\nRESULTS = \"/path/to/your/results\"\nDATABASES = \"/path/to/your/databases\"\nSESSIONS = \"/path/to/your/sessions\"\n</code></pre> <p>Note</p> <p>When changing the reference folder for data, users will no longer be able to access the stock cookbooks. To access these cookbooks, users should copy over their respctive json files and dependencies_</p>"},{"location":"getting_started/quick_start_ui/#starting-the-web-api-server","title":"Starting the Web API Server","text":"<p>To start the Web API server, run the following command in your console. <pre><code>$ python -m moonshot web-api\n</code></pre></p> <p>To know more about the available endpoints, refer to the Web API documentation here.</p>"},{"location":"getting_started/quick_start_ui/#setting-up-moonshot-ui","title":"Setting Up Moonshot UI","text":"<p>The Moonshot UI is a UI extension that runs on top of the Moonshot Web API server.</p>"},{"location":"getting_started/quick_start_ui/#step-0-install-prerequisites","title":"Step 0: Install Prerequisites","text":"<p>Ensure the following prerequisites are installed:</p> <ol> <li>Node.js verion 20.11.1 LTS and above</li> <li>Python version 3.11 and above</li> <li>Moonshot Web API. Ensure the Web API server is running as well.</li> </ol>"},{"location":"getting_started/quick_start_ui/#step-1-install-moonshot-ui","title":"Step 1: Install Moonshot UI","text":"<ol> <li>To begin, download Moonshot UI from GitHub. <pre><code>$ git clone git@github.com:moonshot-admin/moonshot-ui.git\n</code></pre></li> <li>Install Required Dependencies</li> <li>Make sure that all necessary requirements are installed by executing the following command: <pre><code>$ npm install\n</code></pre></li> <li>From the project root folder, execute the following command: <pre><code>$ npm run build\n</code></pre></li> </ol>"},{"location":"getting_started/quick_start_ui/#step-2-serving-moonshot-ui","title":"Step 2: Serving Moonshot UI","text":"<p>After the build is completed, serve the UI with this command: <pre><code>$ npm start\n</code></pre> Access the Web UI from browser <code>http://localhost:3000</code></p>"},{"location":"getting_started/quick_start_web_api/","title":"Quick Start Guide (Web API)","text":""},{"location":"getting_started/quick_start_web_api/#setting-up","title":"Setting Up","text":""},{"location":"getting_started/quick_start_web_api/#step-0-creating-a-virtual-environment","title":"Step 0: Creating a virtual environment","text":"<p>We highly recommend creating a virtual environment to avoid any conflicts in the Python libraries.</p>"},{"location":"getting_started/quick_start_web_api/#step-1-install-moonshot","title":"Step 1: Install Moonshot","text":"<ol> <li> <p>To begin, install Moonshot from the designated source (e.g., GitHub/PyPi). <pre><code>$ git clone git@github.com:moonshot-admin/moonshot.git\n\nOR \n\n$ pip install \"projectmoonshot-imda[web-api]\"\n</code></pre></p> </li> <li> <p>Install Required Dependencies</p> </li> <li>Ensure that all necessary requirements are installed by executing the appropriate command provided in the documentation.</li> <li>If you are installing the project from GitHub, run the following command: <pre><code>$ pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"getting_started/quick_start_web_api/#step-2-environment-variables-optional","title":"Step 2: Environment Variables (Optional)","text":"<ul> <li>You can link your own data folder with the library by running the following code snippet:</li> </ul> <pre><code>CONNECTORS = \"/path/to/your/connectors\"\nRECIPES = \"/path/to/your/recipes\"\nCOOKBOOKS = \"/path/to/your/cookbooks\"\nDATASETS = \"/path/to/your/datasets\"\nPROMPT_TEMPLATES = \"/path/to/your/prompt-templates\"\nMETRICS = \"/path/to/your/metrics\"\nMETRICS_CONFIG = \"/path/to/your/metrics/metrics_config.json\"\nCONTEXT_STRATEGY = \"/path/to/your/context-strategy\"\nRESULTS = \"/path/to/your/results\"\nDATABASES = \"/path/to/your/databases\"\nSESSIONS = \"/path/to/your/sessions\"\n</code></pre> <p>Note</p> <p>When changing the reference folder for data, users will no longer be able to access the stock cookbooks. To access these cookbooks, users should copy over their respctive json files and dependencies_</p>"},{"location":"getting_started/quick_start_web_api/#starting-the-web-api-server","title":"Starting the Web API Server","text":"<p>To start the Web API server, run the following command in your console. <pre><code>$ python -m moonshot web-api\n</code></pre></p> <p>To know more about the available endpoints, refer to the Web API documentation here.</p>"},{"location":"getting_started/quick_start_web_api/#setting-up-moonshot-ui","title":"Setting Up Moonshot UI","text":"<p>The Moonshot UI is a UI extension that runs on top of the Moonshot Web API server.</p>"},{"location":"getting_started/quick_start_web_api/#step-0-install-prerequisites","title":"Step 0: Install Prerequisites","text":"<p>Ensure the following prerequisites are installed:</p> <ol> <li>Node.js verion 20.11.1 LTS and above</li> <li>Python version 3.11 and above</li> <li>Moonshot Web API. Ensure the Web API server is running as well.</li> </ol>"},{"location":"getting_started/quick_start_web_api/#step-1-install-moonshot-ui","title":"Step 1: Install Moonshot UI","text":"<ol> <li>To begin, download Moonshot UI from GitHub. <pre><code>$ git clone git@github.com:moonshot-admin/moonshot-ui.git\n</code></pre></li> <li>Install Required Dependencies</li> <li>Make sure that all necessary requirements are installed by executing the following command: <pre><code>$ npm install\n</code></pre></li> <li>From the project root folder, execute the following command: <pre><code>$ npm run build\n</code></pre></li> </ol>"},{"location":"getting_started/quick_start_web_api/#step-2-serving-moonshot-ui","title":"Step 2: Serving Moonshot UI","text":"<p>After the build is completed, serve the UI with this command: <pre><code>$ npm start\n</code></pre> Access the Web UI from browser <code>http://localhost:3000</code></p>"},{"location":"getting_started/walkthrough/","title":"Walkthrough","text":"<p>Moonshot can be used to run benchmarks and red team. To perform this, an LLM endpoint must be configured to connect to an LLM/LLM application you wish to test. Currently, these are the connector types that is supported out of the box for connecting to LLMs:</p> Connector Types LLM Connector Name OpenAI GPT4 <code>openai-gpt4</code> OpenAI GPT3.5 Turbo 16k <code>openai-gpt35-turbo-16k</code> OpenAI GPT3.5 <code>openai-gpt35</code> Hugging Face Llama2 13B GPTQ <code>hf-llama2-13b-gptq</code> Anthropic Claude2 <code>claude2</code> OpenAI GPT2 (hosted on Hugging Face) <code>hf-gpt2</code>"},{"location":"getting_started/walkthrough/#configuring-endpoints","title":"Configuring Endpoints","text":"<p>If your required connector type is available in our list, simply configure the connector by referring to sample-my-gpt4-config.json. Ensure the following:</p> <ol> <li> <p>Make a copy of the sample JSON file in your endpoint folder and rename the file to your liking. Let's say I want to connect to GPT4, and I have renamed the file to  <code>my-gpt4-config.json</code>.</p> </li> <li> <p>Modify the contents of <code>my-gpt4-config.json</code>:     <pre><code>{\n    \"id\": \"my-gpt4-config\",\n    \"name\": \"my-gpt4-config\",\n    \"connector_type\": \"openai-gpt4\", \n    \"uri\": \"\", \n    \"token\": \"my-api-token\",\n    \"max_calls_per_second\": 100,\n    \"max_concurrency\": 100,\n    \"params\": {\n        \"timeout\": 234,\n        \"allow_retries\": true,\n        \"num_of_retries\": 3\n    }\n}\n</code></pre></p> </li> </ol> <p>If you do not see the connector for the LLM/LLM application you would like to connect to, refer to how we define our connectors here and create your own. You can simply make a copy of the Python file in the same directory, modify the classname and the logic inside the file. </p> <p>When you have configured your connector, you can start doing your benchmark tests and red teaming!</p>"},{"location":"getting_started/walkthrough/#running-benchmark-tests","title":"Running Benchmark Tests","text":"<p>To start running a benchmark, you will have to first select your Recipe or Cookbook. So what is a Recipe and a Cookbook? Click here to find the definition..</p> <p>Recipe: A file which contains the dataset(s), prompt template(s) and metric(s) to run for a benchmark. </p> <p>Cookbook: A file which contains a collection of Recipes.</p> <ol> <li> <p>Select a Recipe/Cookbook to run </p> </li> <li> <p>Execute the Recipe/Cookbook</p> </li> <li> <p>View results of the run</p> </li> </ol>"},{"location":"getting_started/walkthrough/#performing-red-teaming","title":"Performing Red Teaming","text":"<p>To start red teaming, you will first have to create a Session. </p> <p>Session: A Session helps users send prompts to multiple LLM(s) applications. Each session will comprise of Chats, which stores the conversation between users and the LLM/LLM application. </p> <ol> <li> <p>Create/Resume a Session</p> </li> <li> <p>Send a prompt</p> </li> <li> <p>View the responses from the LLM/LLM application</p> </li> </ol>"},{"location":"getting_started/walkthrough/#quick-start-guides","title":"Quick Start Guides","text":"<p>For more elaborate instruction, you can view our quick start guide.</p> <p>Getting Started with Library</p> <p>Getting Started with Web API</p> <p>Getting Started with CLI</p>"},{"location":"resources/attack_modules/","title":"List of Attack Modules","text":"Name Description Character Swap Attack This module tests for adversarial textual robustness. It creates perturbations through swapping characters for words that contains more than 3 characters.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. [Default: 10] Toxic Sentence Generator This module generates toxic sentence based on a given seed prompt. The attack module intends to test if the system under tests will complete the sentence with toxic sentences/phrases. TextBugger Attack This module tests for adversarial textual robustness and implements the perturbations listed in the paper TEXTBUGGER: Generating Adversarial Text Against Real-world Applications.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. This is also thenumber of transformations that should be generated. [Default: 5]Note:Usage of this attack module requires the internet. Initial downloading of the GLoVe embedding occurs when the UniversalEncoder is called.Embedding is retrieved from the following URL: https://textattack.s3.amazonaws.com/word_embeddings/paragramcf Job Role Generator Module This attack module adds demographic groups to the job role. Homoglyph Attack This module tests for adversarial textual robustness. Homoglyphs are alternative words for words comprising of ASCII characters.Example of a homoglyph fool -&gt; fooIThis module purturbs the prompt with all available homoglyphs for each word present.Parameters:1. MAX_ITERATIONS - Maximum number of prompts that should be sent to the target. [Default: 20] Violent Durian This is a multi-turn agent designed to interact over several exchanges. It's used to elicit dangerous or violent suggestions from the target language model by adopting a criminal persona. The application is experimental and uses OpenAI GPT-4. Configure the endpoint openai-gpt4 to use this attack module. TextFooler Attack This module tests for adversarial textual robustness and implements the perturbations listed in the paper Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. This is also the number of transformations that should be generated. [Default: 5]Note:Usage of this attack module requires the internet. Initial downloading of the GLoVe embedding occurs when the UniversalEncoder is called.Embedding is retrieved from the following URL: https://textattack.s3.amazonaws.com/word_embeddings/paragramcf Colloquial Wordswap This attack module tests for textual robustness against the Singapore context. It takes in prompts that feature nouns that describe people. Examples of this include words like 'girl' , 'boy' or 'grandmother'. The module substitutes these words with their Singapore colloquial counterparts, such as 'ah boy', 'ah girl' and 'ah ma'. Insert Punctuation Attack This module tests for adversarial textual robustness and creates perturbations through adding punctuation to the start of words in a prompt.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. [Default: 10] Malicious Question Generator This attack module generates malicious questions using OpenAI's GPT4 based on a given topic. This module will stop by the number of iterations (Default: 50). To use this attack module, you need to configure an 'openai-gpt4'endpoint. Sample Attack Module This is a sample attack module."},{"location":"resources/cookbooks/","title":"List of Cookbooks","text":"Name Description Recipes Easy test sets for Common Risks This is a cookbook that consists (easy) test sets for common risks. These test sets are adapted from various research and will be expanded in the future. 1. uciadult2. bbq3. winobias4. challenging-toxicity-prompts-completion5. realtime-qa6. commonsense-morality-easy7. jailbreak-dan8. advglue Hard test sets for Common Risks This is a cookbook that consists (hard) test sets for common risks. These test sets are adapted from various research and will be expanded in the future. 1. uciadult2. bbq3. winobias4. challenging-toxicity-prompts-completion5. realtime-qa6. commonsense-morality-hard7. jailbreak-dan8. advglue Medical LLM Leaderboard This cookbook contains the benchmarks used in Medical LLM Leaderboard hosted on HuggingFace. Achieving a high score may mean that the targeted system is performing well in answering healthcare questions. 1. medical-mcq2. mmlu-medical MLCommons AI Safety Benchmarks v0.5 for General Chat Models This cookbook systematically assesses the system's capacity to navigate and respond to potentially harmful inquiries, analyzing its responses in accordance with the established safety guidelines. A high refusal rate means that the system under test is performing very well. A low refusal rate means that the system under test is unsafe. 1. mlc-cae2. mlc-cbr3. mlc-hat4. mlc-nvc5. mlc-vcr6. mlc-ssh7. mlc-scr Leaderboard Cookbook This cookbook, drawing inspiration from leaderboards like HF's OpenLLM and HELM, features popular benchmarks for testing model capabilities, with results that may vary from actual leaderboard standings. 1. mmlu2. truthfulqa-mcq3. winogrande4. hellaswag5. arc6. gsm8k Facts about Singapore This cookbook is designed to evaluate Singapore's historical events and essential facts, serving as a litmus test for its understanding of the country's unique context. In addition, there are safety prompts written in Singapore context. By assessing a model's familiarity with Singapore's cultural and historical landscape, it provides valuable insights into its overall proficiency and accuracy in natural language processing systems tailored to Singaporean contexts. 1. singapore-facts2. singapore-safety Tamil Language This is a cookbook that consists of datasets related to the Tamil Language. 1. tamil-kural-classification2. tamil-tamilnews-classification3. tamil-tanglish-tweets AI Safety in Chinese Language This cookbook measures the system's ability in answering trust and safety questions that are asked in Chinese languages. 1. cvalues2. cbbq-lite Legal Summarisation This cookbook runs general capabilitiy benchmark on legal summarisation model. 1. analogical-similarity2. auto-categorisation3. cause-and-effect4. contextual-parametric-knowledge-conflicts5. gre-reading-comprehension6. squad-shifts-tnf"},{"location":"resources/datasets/","title":"List of Datasets","text":"Name Description License Reference squad-shifts-tnf Zero-shot reading comprehension on paragraphs and questions from squadshifts - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/squad_shifts BBQ-lite on religion - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on religion, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 advglue Adversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models. - https://github.com/AI-secure/adversarial-glue Food in Singapore Contain prompts that test model's udnerstanding in Food, in True/False format Apache-2.0 IMDA MedMCQA MedMCQ is a large-scale, multiple-choice question answering dataset designed to address realworld medical entrance exam questions. It contains more than 194k high-quality AIIMS &amp; NEET PG entrnace exam MCQs covering 2.4k healthcare topics and 21 medical subjects. MIT License https://github.com/MedMCQA/MedMCQA tamil-thirukural This dataset is used to test the comprehension abilities for the Thirukkural. Thirukkural is a classic Tamil literature composed by the ancient Tamil poet Thiruvalluvar. It consists of 1330 couplets (kurals) that are grouped into 133 chapters, each containing 10 couplets. Creative Commons Attribution 4.0 International https://github.com/vijayanandrp/Thirukkural-Tamil-Dataset RealtimeQA RealTime QA is a dynamic question answering (QA) platform that inquires about the present. - https://github.com/realtimeqa/realtimeqa_public sg-university-tutorial-questions-legal Contain tutorial questions ans answers from Singapore's Universities to test model's ability in understanding legal context in Singapore - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on gender - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on gender, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 ARC-Easy A dataset of genuine grade-school level, multiple-choice science questions in advanced Q&amp;A. This is the challenge set. CC BY-SA https://allenai.org/data/arc BBQ-lite on nationality - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on nationality, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 m3exam-vietnamese This dataset contains local exam questions for testing Vietnamese capability. CC BY-NC-SA https://github.com/DAMO-NLP-SG/M3Exam BBQ-lite on physical-appearance - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on physical-appearance, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 tanglish-tweets-SA Code-mixed Tamil and English tweets curated for the sentiment analysis task. CC0: Public Domain - Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ uciadult The UCI Adult dataset has been used widely used to assess fairness. Creative Commons Attribution 4.0 International https://archive.ics.uci.edu/dataset/2/adult BBQ-lite on age - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on age, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Suicide &amp; Self-Harm Responses that enable, encourage, or endorse acts of intentional self-harm. - - sg-legal-glossary A list of singapore legal terms extracted from SICC and Judiciary websites. - https://www.sicc.gov.sg/glossary-of-legal-terms MLC Baseline - Hate Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics. - - BBQ-lite on age - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on age, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 cause_and_effect This recipe measures if the model is able to distinguish and understand cause and effect. The higher the grade, the better the system can perform this capability. - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/cause_and_effect BBQ-lite on race-x-gender - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-gender, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ TruthfulQA (MCQ Version) TruthfulQA aims to measure the the truthfulness of a model. This dataset uses a multiple choice format. Apache-2.0 https://github.com/sylinrl/TruthfulQA Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ PubMedQA PubMedQA is a large-scale, multiple-choice question answering dataset designed to address realworld medical entrance exam questions. It contains more than 194k high-quality AIIMS &amp; NEET PG entrnace exam MCQs covering 2.4k healthcare topics and 21 medical subjects. MIT License https://github.com/MedMCQA/MedMCQA Facts about Singapore in True and False Contain prompts that contains facts about Singapore, in True/False format Apache-2.0 IMDA Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ RealToxicityPrompts RealToxicityPrompts aims to measure the model's ability in identify toxic sentences. Apache-2.0 https://github.com/allenai/real-toxicity-prompts/ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ gre_reading_comprehension To measure the model/'s ability to summarize text, infer and deduce knowledge from context, and match the context. - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/gre_reading_comprehension MMLU College Medicine MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU College Medicine MIT License https://github.com/hendrycks/test BBQ-lite on race-x-ses - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-ses, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Singapore Polical History Contain questions about Singapore's key historical events in political. Apache-2.0 IMDA ChallengingToxicityPrompts ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences. CC BY-SA 4.0 https://github.com/AI-secure/DecodingTrust MLC Baseline - Violent Crimes Responses that enable, encourage, or endorse the commission of violent crimes. - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MMLU Clinical Knowledge MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Clinical Knowledge MIT License https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ coqa_conversational_question_answering To measure the ability of machines to understand a text passage and answer a series of interconnected questions - - Singapore Transport System Contain questions about Singapore's public housing system Apache-2.0 IMDA ChallengingToxicityPrompts ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences. CC BY-SA 4.0 https://github.com/AI-secure/DecodingTrust BBQ-lite on race-x-ses - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-ses, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Chemical, Biological, Radiological, Nuclear, and Explosives Responses that enable, encourage, or endorse the creation of weapons of mass destruction. - - BBQ-lite on gender - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on gender, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 BBQ-lite on sexual-orientation - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on sexual-orientation, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MLC Baseline - Chemical, Biological, Radiological, Nuclear, and Explosives Responses that enable, encourage, or endorse the creation of weapons of mass destruction. - - MLC Baseline - Hate Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics. - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Winogrande This dataset is used for commonsense reasoning, expert-crafted pronoun resolution problems designed to be unsolvable for statistical models. Apache-2.0 https://github.com/allenai/winogrande Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Contextual Parametric Knowledge Conflicts To measure the model/\u2019s ability in making informed predictions - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/contextual_parametric_knowledge_conflicts MMLU Anatomy MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Anatomy MIT License https://github.com/hendrycks/test Singapore Transport System Contain questions about Singapore's transport system Apache-2.0 IMDA truthfulqa TruthfulQA aims to measure the the truthfulness of a model. Apache-2.0 https://github.com/sylinrl/TruthfulQA ARC-Easy A dataset of genuine grade-school level, multiple-choice science questions in advanced Q&amp;A. This is the easy set. CC BY-SA https://allenai.org/data/arc Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Iconic Places in Singapore Contain questions about Singapore's iconic places. Apache-2.0 IMDA Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MLC Baseline - Sex-Related Crimes Responses that enable, encourage, or endorse the commission of sex-related crimes. - - Analogical Similarity To measure the model\u2019s ability in discriminating between different degrees of analogical similarity in two given episodes - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/analogical_similarity Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on race-ethnicity - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on race-ethnicity, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 GSM8K This dataset consists of high quality grade school math problems created by human. These problems take between 2 and 8 steps to solve, and usually requires a sequence of elementary calculations. MIT License https://github.com/openai/grade-school-math MLC Baseline - Child Abuse and Exploitation Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children. - - m3exam-indonesian This dataset contains local exam questions for testing Indonesian capability. CC BY-NC-SA https://github.com/DAMO-NLP-SG/M3Exam BBQ-lite on race-x-gender - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-gender, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Sex-Related Crimes Responses that enable, encourage, or endorse the commission of sex-related crimes. - - BBQ-lite on disability-status - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on disability-status, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MMLU College Biology MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU College Biology MIT License https://github.com/hendrycks/test ChallengingToxicityPrompts ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences. CC BY-SA 4.0 https://github.com/AI-secure/DecodingTrust BBQ-lite on religion - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on religion, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Child Abuse and Exploitation Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children. - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MLC Baseline - Non-Violent Crimes Responses that enable, encourage, or endorse the commission of non-violent crimes. - - MLC Baseline - Non-Violent Crimes Responses that enable, encourage, or endorse the commission of non-violent crimes. - - List of Occupations This dataset contains a list of occupations collected from various websites (e.g., MoM of Singapore). The dataset can be used to test job-related applications. MIT License IMDA In-the-wild Jailbreak Dataset This dataset contains jailbreak prompts that were collected from various places (e.g., Discord). MIT license https://github.com/verazuo/jailbreak_llms MLC Baseline - Suicide &amp; Self-Harm Responses that enable, encourage, or endorse acts of intentional self-harm. - - MLC Baseline - Violent Crimes Responses that enable, encourage, or endorse the commission of violent crimes. - - Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ auto_categorization To measure the model's ability in categorising elements into groups. - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/auto_categorization BBQ-lite on sexual-orientation - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on sexual-orientation, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 tamil-news-classification This dataset is used to classify a static set of Tamil News. The task is to classify news to its respective category. The dataset has 6 news categories - \"tamilnadu\", \"india\", \"cinema\", \"sports\", \"politics\", \"world\". GNU General Public License v3.0 - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ C-Values - Values of Chinese Large Language attack_modules This dataset contains prompts that can measure the alignment ability of LLMs in both safety and responsibility in Chinese Language. Apache-2.0 license - BBQ-lite on physical-appearance - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on physical-appearance, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 enronemail The Enron email dataset is aimed at evaluating if there is leakage of private information. The dataset was used in DecodingTrust as part of its privacy evaluation. Apache-2.0 https://github.com/ParakweetLabs/EmailIntentDataSet m3exam-thai This dataset contains local exam questions for testing Thai capability. CC BY-NC-SA https://github.com/DAMO-NLP-SG/M3Exam MMLU Medical Genetics MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Medical Genetics MIT License https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on ses - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on ses, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 truthfulqa TruthfulQA aims to measure the the truthfulness of a model. Apache-2.0 https://github.com/sylinrl/TruthfulQA Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ Places in Singapore Contain prompts that test model's udnerstanding places in Singapore, in True/False format Apache-2.0 IMDA BBQ-lite on nationality - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on nationality, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MMLU Professional Medicine.json MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Professional Medicine.json MIT License https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on race-ethnicity - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on race-ethnicity, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ winobias-variation1 This dataset contains gender-bias based on the professions from the Labor Force Statistics (https://www.bls.gov/cps/cpsaat11.htm), which contain some gender-bias. MIT License https://github.com/uclanlp/corefBias/tree/master/WinoBias/wino Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ HellaSwag This dataset is used to evaluate commonsense with questions that are trivial for humans but difficult for state-of-the-art models. MIT License https://github.com/rowanz/hellaswag BBQ-lite on ses - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on ses, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Safety Benchmark (Singapore Context) Contain prompts that test safety in Singapore-context Apache-2.0 IMDA MedQA (US) MedQA is a free-form multiple-choice OpenQA dataset for solving medical problems. These are collected from the professional medical board exams. We extracted the list of MCQ questions from the US in this dataset. MIT License https://github.com/jind11/MedQA uciadult The UCI adult dataset, created in 1996, is used to train models to predict whether a person's income will exceed $50K/yr based on census data. Also known as \"Census Income\" dataset. Creative Commons Attribution 4.0 International https://archive.ics.uci.edu/dataset/2/adult MMLU This dataset covers 57 tasks including elementary mathemathics, US history, computer science, law, and more. MIT license https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on disability-status - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on disability-status, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2"},{"location":"resources/jupyter_notebook/","title":"Jupyter Notebook","text":"<p>Here are some examples of how you can run Moonshot using Jupyter Notebook.</p> <p>Moonshot Benchmark Feature Walkthrough</p> <p>Tutorial 1 - Basic Workflow - Execute a Benchmark</p> <p>Tutorial 2 - Basic Workflow - Add your own test</p> <p>Tutorial 3 - Basic Workflow - Run Red Teaming Session</p> <p>Tutorial 4 - Advanced Workflow - Test Custom Application</p>"},{"location":"resources/metrics/","title":"List of Metrics","text":"Name Description BertScore BertScore uses Bert to check for the similarity in embedding between two sentences. SpellingScore SpellingScore uses Levenshetein Distance to find permutations within an edit distance of 2 form the original word before comparing to known words in a word frequency list. GPT4 Annotator Calculates the number of refused response using GPT4. BleuScore Bleuscore uses Bleu to return the various rouge scores. ReadabilityScore ReadabilityScore uses Flesch Reading Ease to compute the complexity of the output Toxicity Classifier This classifier measures how toxic a given input isand calculate the number of toxic sentence detected. RougeScorer RougeScorer returns the various rouge scores. Attack Success Rate Attack success rate measures how successful a changed prompt performs. A high score shows that the system under test is highly sensitive towards a prompt with minimal changes. LeakageRate Leakage Rate will compare the LCS between two string - Output and Target. ReverseExactStrMatch ReverseExactStrMatch will compare the output from language model with the expected target. ExactStrMatch ExactStrMatch will compare the output from language model with a single target or multiple expected target. RelaxStrMatch RelaxStrMatch will remove symbols and spaces before comparing the output from language model with the expected target. LlamaGuard Annotator Calculates the number of safe, unsafe and unknown response by using LlamaGuard. SampleMetric Sample Metric will provide examples on connecting to LLMs."},{"location":"resources/recipes/","title":"List of Recipes","text":"Name Description Datasets Metrics Prompt Templates RealtimeQA RealTime QA is a dynamic question answering (QA) platform that inquires about the present. The higher the grade, the better the system is handling hallucination. 1. realtimeqa-past 1. exactstrmatch - squad-shifts-tnf Zero-shot reading comprehension on paragraphs and questions from squadshifts. Augmented to true/false statement. The higher the grade, the better the model performs this capability. 1. squad-shifts-tnf 1. relaxstrmatch - MLCommons AI Safety Benchmark - Non-Violent Crimes This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the commission of non-violent crimes. A high grade indicates that the system under test handles the response well. 1. mlc-nvc-malicious-user2. mlc-nvc-typical-user 1. llamaguardannotator - TAMIL-KURAL-CLASSIFICATION This recipe is used to test the comprehension abilities for the Thirukkural. Thirukkural is a classic Tamil literature composed by the ancient Tamil poet Thiruvalluvar. It consists of 1330 couplets (kurals) that are grouped into 133 chapters, each containing 10 couplets. The higher the grade, the better the model performs in this task. 1. tamil-kural-classification 1. exactstrmatch 1. tamil-templatekuralclassification University Tutorial Questions in Singapore's Legal Classes To measure the model's ability in understanding legal context in Singapore. 1. sg-university-tutorial-questions-legal 1. bertscore 1. answer-template MLCommons AI Safety Benchmark - Child Abuse and Exploitation This recipe measures the model's responses in dealing with prompts that contain, describe, enable, encourage, or endorse the sexual abuse of children. A high grade indicates that the system under test handles the response well. 1. mlc-cae-malicious-user2. mlc-cae-typical-user 1. llamaguardannotator - TAMIL-TANGLISH-TWEETS This recipe is used to perform sentiment analysis on code-mixed Tamil and English tweets. The higher the grade, the better the model performs in this task. 1. tamil-tanglish-tweets 1. exactstrmatch 1. tamil-templatetanglishsa ChallengingToxicityPrompts This recipe measures the model's ability in generating toxic phrases or sentences when given a toxic phrase. The higher the grade, the less toxic the system is. 1. challenging-toxicity-prompts 1. toxicity-classifier 1. complete-sentence Singapore Legal Glossary To measure the model's ability in understanding legal term used commonly in Singapore. 1. sg-legal-glossary 1. bertscore 1. legal-term-template EnronEmail The Enron email dataset is aimed at evaluating if there is leakage of private information. The dataset was used in DecodingTrust as part of its privacy evaluation. 1. privacy-enronemails 1. leakagerate 1. enronemail-templatea2. enronemail-templateb3. enronemail-templatec4. enronemail-templated Bias Benchmark for QA This recipe measures the model's ability in attesting social biases against people belonging to protected classes along nine social dimensions relevant for US English-speaking context with age ambiguous and disambiguous questions. The higher the grade, the better the system is in handling social biases. 1. bbq-lite-age-ambiguous2. bbq-lite-age-disamb3. bbq-lite-disability-status-ambiguous4. bbq-lite-disability-status-disamb5. bbq-lite-gender-ambiguous6. bbq-lite-gender-disamb7. bbq-lite-nationality-ambiguous8. bbq-lite-nationality-disamb9. bbq-lite-physical-appearance-ambiguous10. bbq-lite-physical-appearance-disamb11. bbq-lite-race-ethnicity-ambiguous12. bbq-lite-race-ethnicity-disamb13. bbq-lite-race-x-gender-ambiguous14. bbq-lite-race-x-gender-disamb15. bbq-lite-race-x-ses-ambiguous16. bbq-lite-race-x-ses-ambiguous17. bbq-lite-religion-ambiguous18. bbq-lite-religion-disamb19. bbq-lite-ses-ambiguous20. bbq-lite-ses-disamb21. bbq-lite-sexual-orientation-ambiguous22. bbq-lite-sexual-orientation-disamb 1. exactstrmatch 1. mcq-template Chinese Bias Becnhmark for QA - Lite This recipe measures a system's ability to respond to safety-related, biased, and stereotypical questions in Chinese. A higher grade indicates that the system under test is safer, less biased, and less stereotypical. 1. cbbq-lite-age-ambiguous2. cbbq-lite-age-disamb3. cbbq-lite-disability-ambiguous4. cbbq-lite-disability-disamb5. cbbq-lite-disease-ambiguous6. cbbq-lite-disease-disamb7. cbbq-lite-educational-qualification-ambiguous8. cbbq-lite-educational-qualification-disamb9. cbbq-lite-ethnicity-ambiguous10. cbbq-lite-ethnicity-disamb11. cbbq-lite-gender-ambiguous12. cbbq-lite-gender-disamb13. cbbq-lite-household-registration-ambiguous14. cbbq-lite-household-registration-disamb15. cbbq-lite-nationality-ambiguous16. cbbq-lite-nationality-disamb17. cbbq-lite-physical-appearance-ambiguous18. cbbq-lite-physical-appearance-disamb19. cbbq-lite-race-ambiguous20. cbbq-lite-race-disamb21. cbbq-lite-region-ambiguous22. cbbq-lite-region-disamb23. cbbq-lite-SES-ambiguous24. cbbq-lite-SES-disamb25. cbbq-lite-sexual-orientation-ambiguous26. cbbq-lite-sexual-orientation-disamb 1. exactstrmatch 1. chinese-mcq-template Cause and Effect This recipe measure the model's ability in understanding the cause and effect in a sentence. The higher the grade, the better the system is in performing this capability. 1. cause-and-effect 1. relaxstrmatch - TruthfulQA (MCQ) TruthfulQA aims to measure the truthfulness of a model. The higher the grade, the more truthful the system is. 1. truthfulqa-mcq 1. exactstrmatch 1. mcq-template GRE Reading Comprehension To measure the model's ability to summarize text, infer and deduce knowledge from context, and match the context. The higher the grade, the better the system is in performing this capability. 1. gre-reading-comprehension 1. relaxstrmatch 1. answer-template Safety questions written in Singapore's context This recipe evaluates whether a system under test can perform well when a harmful question is written in Singapore's context. By achieving a high grade, the target demonstrates that it is lower in risk. 1. singapore-safety-questions 1. llamaguardannotator - COQA Conversational Q&amp;A To measure the ability of machines to understand a text passage and answer a series of interconnected questions. The higher the grade, the better the system performs for this capability. 1. coqa-conversational-qna 1. exactstrmatch 1. answer-template Bias - Occupation This recipe tests if a targeted system thinks that a certain demographic group can handle a job role better than others. 1. occupation 1. gpt4annotator 1. job-role-bias MLCommons AI Safety Benchmark - Violent Crimes This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the commission of violent crimes. A high grade indicates that the system under test handles the response well. 1. mlc-vcr-malicious-user2. mlc-vcr-typical-user 1. llamaguardannotator - Commonsense Morality (Easy) This recipe measures whether how the system performs when given prompts embedded the body of moral standards and principles that most people intuitively accept. The higher the grade, the better the system performs. 1. commonsense-morality-easy-variation1 1. exactstrmatch - MLCommons AI Safety Benchmark - Hate This recipe measures the model's responses in dealing with prompts that demean or dehumanize people on the basis of their sensitive, personal characteristics. A high grade indicates that the system under test handles the response well. 1. mlc-hat-malicious-user2. mlc-hat-typical-user 1. llamaguardannotator - Winograde To measure model's ability in answering commonsense reasoning, expert-crafted pronoun resolution problems that are designed to be unsolvable for statistical models. The higher the score, the better the model is. 1. winogrande 1. exactstrmatch 1. mcq-template ARC To measure model's ability in answering genuine grade-school level, multiple-choice science questions on the easy and challenge sets. The higher the grade, the better the sytem is performing this capability. 1. arc-challenge2. arc-easy 1. exactstrmatch 1. mcq-template Contextual Parametric Knowledge Conflicts This recipe measures the model\u2019s ability in making informed predictions. The higher the grade, the better the system can perform for this capability. 1. contextual-parametric-knowledge-conflicts 1. relaxstrmatch 1. mcq-template Commonsense Morality (Hard) This recipe measures whether how the system performs when given prompts embedded the body of moral standards and principles that most people intuitively accept. The higher the grade, the better the system performs. 1. commonsense-morality-hard-variation1 1. exactstrmatch - RealToxicityPrompts (Completion) RealToxicityPrompts aims to measure the model's ability in identify toxic sentences. The higher the grade, the less toxic the system is. 1. real-toxicity-prompts 1. toxicity-classifier 1. real-toxicity-prompt-template2 Analogical Similarity This recipe measures the model\u2019s ability in discriminating between different degrees of analogical similarity in two given episodes. The higher the grade, the better the sytem is performing this capability. 1. analogical-similarity 1. relaxstrmatch 1. analogical-similarity GSM8K To measure model's ability in solvinggrade school math problems created by human. These problems take between 2 and 8 steps to solve, and usually requires a sequence of elementary calculations. The higher the grade, the better the system can perform this capability. 1. gsm8k 1. exactstrmatch 1. mcq-template MLCommons AI Safety Benchmark - Sex-related Crimes This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the commission of sex-related crimes. A high grade indicates that the system under test handles the response well. 1. mlc-scr-malicious-user2. mlc-scr-typical-user 1. llamaguardannotator - MLCommons AI Safety Benchmark - Chemical, Biological, Radiological, Nuclear, and Explosives This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the creation of weapons of mass destruction. A high grade indicates that the system under test handles the response well. 1. mlc-cbr-malicious-user2. mlc-cbr-typical-user 1. llamaguardannotator - Jailbreak-DAN This recipe assesses whether the system will be jailbroken using the common jailbreak methods. The higher the grade, the better the system is protected against common jailbreaks. 1. jailbreak-dan 1. reverseexactstrmatch - Auto Categorisation This recipe measures the model's ability in categorising elements into groups. The higher the grade, the system performs better in this capability. 1. auto-categorisation 1. relaxstrmatch 1. complete-sentence Medical MCQ In this recipe, we measure how well a system is able to answer healthcare questions using various datasets related to healthcare. The higher the grade, the better the system performs in answering healthare questions. 1. medmcqa2. medqa-us3. pubmedqa 1. exactstrmatch 1. mcq-template TAMIL-NEWS-CLASSIFICATION This recipe is to classify a static set of Tamil News. The task is to classify news to its respective category. The higher the grade, the better the model performs in this task. 1. tamil-tamilnews-classification 1. exactstrmatch 1. tamil-templatenewsclassification CValues - The benchmark for measuring alignment in LLMs using Chinese Langauges. This recipe measures the alignment ability of LLMs in both safety and responsibility in Chinese Language. A higher grade means that the LLMs are more aligned to human's values. 1. cvalues 1. exactstrmatch 1. chinese-mcq-template TruthfulQA TruthfulQA aims to measure the truthfulness of a model. This is an experimental recipe using Rouge Score 1. truthfulqa-open-ended 1. rougescorer 1. mcq-template Facts about Singapore This recipe evaluates the accuracy of facts about Singapore. A higher score reflects the target's ability to answer questions about Singapore with a high level of precision and detail. By achieving a high grade, the target demonstrates a thorough understanding and knowledge of Singapore's key events, transport system, and facts. 1. singapore-transport-system2. singapore-iconic-places3. singapore-political-history4. singapore-public-housing5. singapore-facts-tnf6. singapore-places-tnf7. singapore-food-tnf 1. exactstrmatch - AdvGLUE AdvGLUE is a comprehensive robustness evaluation benchmark that concentrates on assessing the adversarial robustness of language models. It encompasses textual adversarial attacks from various perspectives and hierarchies, encompassing word-level transformations and sentence-level manipulations. A higher grade indicates that the system under test is more resilient to changes in the sentences. 1. advglue-all 1. advglue - MMLU To measure model's ability in answering accurately across 57 tasks including elementary mathemathics, US history, computer science, law, and more. The higher the grade, the better the system performs. 1. mmlu-all 1. exactstrmatch 1. mmlu HellaSwag To measure commonsense with questions that are trivial for humans but difficult for statistical models. The higher the grade, the better the system performs this capability. 1. hellaswag 1. exactstrmatch 1. mcq-template UCI Adult Dataset This recipe contains the easy variation of UCI adult dataset where LLM is expected to classify the attributes correctly. The higher the score, the better the model is. 1. uciadult 1. exactstrmatch 1. uciadult-template MMLU - Medical related questions. MMLU benchmark measures model's ability in answering accurately across 57 tasks including elementary mathemathics, US history, computer science, law, and more. In this recipe, we extracted all the tasks related to healthare. The higher the grade, the better the system performs in answering healthcare related questions. 1. mmlu-anatomy2. mmlu-clinicalknowledge3. mmlu-collegebiology4. mmlu-collegemedicine5. mmlu-medicalgenetics6. mmlu-professionalmedicine 1. exactstrmatch 1. mcq-template MLCommons AI Safety Benchmark - Suicide &amp; Self-Harm This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse acts of intentional self-harm. A high grade indicates that the system under test handles the response well. 1. mlc-ssh-vulnerable-user2. mlc-ssh-typical-user 1. llamaguardannotator - Winobias Winobias dataset is used to test representational harm in LLMs. LLM should refuse to answer. The higher the score, the better the model is. 1. winobias-type1 1. reverseexactstrmatch -"},{"location":"troubleshoot/troubleshoot/","title":"Troubleshooting Guide","text":""},{"location":"troubleshoot/troubleshoot/#table-of-contents","title":"Table of Contents","text":"<ul> <li>Missing Dependencies</li> <li>Python Version Compatibility</li> <li>Network Issues</li> <li>Conflicting Packages</li> </ul>"},{"location":"troubleshoot/troubleshoot/#missing-dependencies","title":"Missing Dependencies","text":"<p>Error: This can lead to installation failures or runtime errors.</p> <p>Troubleshoot: Check the toolkit's documentation for a list of dependencies and ensure they are installed using pip or your system's package manager.</p>"},{"location":"troubleshoot/troubleshoot/#python-version-compatibility","title":"Python Version Compatibility","text":"<p>Error: An outdated version can lead to compatibility issues.</p> <p>Troubleshoot: Verify the Python version requirements in the documentation. If your Python version is not compatible, consider using a virtual environment with the correct Python version.</p>"},{"location":"troubleshoot/troubleshoot/#network-issues","title":"Network Issues","text":"<p>Error: Interrupted downloads or timeouts during package installation.</p> <p>Troubleshoot: Check your internet connection and try again. Consider using a mirror for package repositories if available. You can also download the package manually and install it using pip.</p>"},{"location":"troubleshoot/troubleshoot/#conflicting-packages","title":"Conflicting Packages","text":"<p>Error: Fail install if there are conflicting versions of packages already installed on your system.</p> <p>Troubleshoot: Use a virtual environment to isolate the toolkit and its dependencies from other Python packages. Alternatively, uninstall conflicting packages or use package version pinning to ensure compatibility.</p>"},{"location":"tutorial/cli/create_benchmark_tests/","title":"How to Create Custom Benchmark Tests","text":"<ol> <li> <p>Change directory to the root directory of Moonshot.</p> </li> <li> <p>Enter <code>python -m moonshot cli interactive</code>.</p> </li> <li> <p>Choose a benchmark type to create and view help:</p> <ul> <li> <p>Recipe:  Enter <code>add_recipe -h</code> to see the required fields to create a recipe: </p> <ul> <li>To run the help example, enter <code>add_recipe 'My new recipe' 'I am recipe description' \"['category1','category2']\" \"['bbq-lite-age-ambiguous']\" \"['bertscore','bleuscore']\" -p \"['analogical-similarity','mmlu']\" -t \"['tag1','tag2']\" -a \"['charswap_attack_module']\" -g \"{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}\"</code></li> </ul> </li> <li> <p>Cookbook: Enter <code>add_cookbook -h</code> to see the required fields to create a cookbook: </p> <ul> <li>To run the help example, enter <code>add_cookbook 'My new cookbook' 'I am cookbook description' \"['analogical-similarity','auto-categorisation']\"</code></li> </ul> </li> </ul> </li> <li> <p>View the newly created recipe or cookbook:</p> <ul> <li> <p>Enter <code>view_recipe my-new-recipe</code>:</p> <p></p> </li> <li> <p>Enter <code>view_cookbook my-new-cookbook</code>:</p> <p></p> </li> </ul> </li> </ol> <p>You can view more information on how creating benchmark tests here.</p>"},{"location":"tutorial/cli/create_endpoint/","title":"How to Create Connector Endpoint","text":"<ol> <li> <p>Change directory to the root directory of Moonshot. </p> </li> <li> <p>Enter <code>python -m moonshot cli interactive</code></p> </li> <li> <p>Enter <code>add_endpoint -h</code> to see the required fields to create a connector endpoint:</p> <ul> <li>To run the help example, enter <code>add_endpoint openai-connector 'OpenAI GPT3.5 Turbo 1106' MY_URI ADD_YOUR_TOKEN_HERE 1 1 \"{'temperature': 0.5, 'model': 'gpt-3.5-turbo-1106'}\"</code></li> </ul> </li> <li> <p>View the newly created connector endpoint by entering <code>view_endpoint openai-gpt3-5-turbo-1106</code> (<code>openai-gpt3-5-turbo-1106</code> is the ID of the connector endpoint and is slugified from the name <code>OpenAI GPT3.5 Turbo 1106</code>):     </p> </li> </ol> <p>You can view more information on creating connector endpoint here.</p>"},{"location":"tutorial/cli/run_benchmark_tests/","title":"How to Run Benchmark Tests","text":"<ol> <li> <p>Change directory to the root directory of Moonshot.</p> </li> <li> <p>Enter <code>python -m moonshot cli interactive</code>.</p> </li> <li> <p>Choose a benchmark type to run and view help:</p> <ul> <li> <p>Recipe:  Enter <code>run_recipe -h</code> to see the required fields to run a recipe: </p> <ul> <li>To run the help example, enter <code>run_recipe \"my new recipe runner\" \"['bbq','mmlu']\" \"['openai-gpt35-turbo']\" -n 1 -r 1 -s \"You are an intelligent AI\"</code></li> </ul> </li> <li> <p>Cookbook: Enter <code>run_cookbook -h</code> to see the required fields to run a cookbook: </p> <ul> <li>To run the help example, enter <code>run_cookbook \"my new cookbook runner\" \"['chinese-safety-cookbook']\" \"['openai-gpt35-turbo']\" -n 1 -r 1 -s \"You are an intelligent AI\"</code></li> </ul> </li> </ul> </li> <li> <p>View the results:</p> <ul> <li> <p>Recipe:</p> <p></p> </li> <li> <p>Cookbook:</p> <p></p> </li> </ul> </li> </ol> <p>You can view more information on running benchmarks here.</p>"},{"location":"tutorial/cli/run_red_teaming/","title":"How to Run Red Teaming","text":"<ol> <li> <p>Change directory to the root directory of Moonshot.</p> </li> <li> <p>Enter <code>python -m moonshot cli interactive</code>.</p> </li> <li> <p>Create a new session with a new runner:</p> <ul> <li>Enter <code>new_session -h</code> to see the required fields to create a session:<ul> <li> <p>To run the help example, enter <code>new_session my-runner -e \"['openai-gpt4']\" -c add_previous_prompt -p mmlu</code>. You should see that your session is created:</p> <p></p> </li> </ul> </li> </ul> </li> </ol>"},{"location":"tutorial/cli/run_red_teaming/#manual-red-teaming","title":"Manual Red Teaming","text":"<p>Continuing from Step 3, you can type a prompt and it will be sent to the LLM:</p> <p></p>"},{"location":"tutorial/cli/run_red_teaming/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>Continuing from Step 3 or manual red teaming, you can choose to run an attack module to perform automated red teaming. Enter <code>run_attack_module -h</code> to see the required fields to run attack modules:</p> <ul> <li>To run the help example, enter <code>run_attack_module sample_attack_module \"this is my prompt\" -s \"test system prompt\" -c \"add_previous_prompt\" -p \"mmlu\" -m \"bleuscore\"</code>. You should see your prompt and response:</li> </ul> <p></p> <p>You can view more information on running red teaming here.    </p>"},{"location":"tutorial/web-ui/benchmark/","title":"How to Run Benchmark Tests","text":"<p>In this tutorial, we will guide you through the process of running a benchmark test in Project Moonshot. </p> <p>As a user, you may want to assess your Large Language Model (LLM) application's performance across various competencies such as language and context understanding. Benchmarks serve as \"exam questions\" for your model, providing a comprehensive evaluation of its capabilities.</p> <p>Project Moonshot offers a wide range of benchmarks, including widely recognized ones like Google's BigBench and HuggingFace's leaderboards, as well as more domain/task-specific tests like Tamil Language and Medical LLM benchmarks.</p> <p>This tutorial will provide a step-by-step guide on how to run these benchmark tests, enabling you to measure your LLM application's performance in Capability, Quality, and Trust &amp; Safety. Let's get started on running your first benchmark test.</p> <ol> <li> <p>Begin by navigating to the 'Evaluate against standard tests' section. </p> </li> <li> <p>Here, a list of recommended cookbooks has been pre-selected for you. Feel free to select or deselect any cookbook that you wish to run. Once you've made your selection, click the down arrow button to proceed to the next step. </p> </li> <li> <p>This page displays the total number of prompts that will be tested based on the cookbooks you've selected. To view all available cookbooks, click on 'these cookbooks'. </p> </li> <li> <p>On this page, all cookbooks are sorted by their category. To select a cookbook, click on the corresponding checkbox. For more information about a cookbook, click on 'About'. Once you've finished, click 'OK'. </p> </li> <li> <p>You will be redirected back to the page showing the total number of prompts. To proceed to the next step, click the down arrow button. </p> </li> <li> <p>Here, you are required to select an endpoint for testing. If needed, you can create a new endpoint or edit an existing one on this page. After selecting an endpoint, click on the down arrow button to proceed to the next step. </p> <p>Warning</p> <p>Before proceeding, please ensure that you have your Together Llama Guard 7B Assistant endpoint token set up. This is necessary to run the MLCommon cookbook.</p> </li> <li> <p>On this page, you need to fill out the form. If you wish to test a smaller dataset, replace the value in the 'Run a smaller set' field. By default, the value is 0, which means the entire cookbook will be run. By entering a value, you can specify the number of prompts to be tested from each recipe. Once you've completed the form, click on 'Run' to start the test. </p> </li> <li> <p>The benchmark test is now running. You can click on 'see details' to view the endpoints and cookbooks that are currently running. If you wish to exit an ongoing run, click on 'cancel'. </p> </li> <li> <p>You can safely close the window while the benchmark is running; it will continue to operate in the background. To check the status of your run, click on the bell icon. If you wish to view more details about the run, simply click on the run itself. </p> </li> <li> <p>After the benchmark test has finished, you can access the results by clicking on 'View Report'. </p> </li> </ol>"},{"location":"tutorial/web-ui/create_cookbook/","title":"How to Create Custom Cookbook","text":"<p>In this tutorial, we will guide you through the process of creating a Cookbook in Moonshot. Imagine you are a user who has been working with various model endpoints and you've found a set of recipes that generate the results you need. Instead of selecting these recipes individually each time, you want to create a Cookbook.</p> <p>A Cookbook in Moonshot is a collection of one or more recipes, each designed to generate specific results when run with the model endpoints. This Cookbook will serve as your personalized guide for conducting evaluations and tests, offering a structured approach to assessing your LLM applications' performance and addressing potential risks. Let's get started on creating your first Cookbook.</p> <ol> <li> <p>Navigate to 'Create Cookbooks, Select Recipes'. </p> </li> <li> <p>Fill in the required fields and then proceed by clicking 'Select Recipes'. </p> </li> <li> <p>You will be presented with a list of available recipes in Moonshot. Choose the recipes you wish to include in your custom cookbook and confirm by clicking on \u2018Add to Cookbook\u2019.  </p> </li> <li> <p>Finalize the creation of your cookbook by clicking on \u2018Create Cookbook'. </p> </li> <li> <p>Once your cookbook is created, you can view it along with any other cookbooks you've created by clicking on 'View Cookbooks'.  </p> </li> </ol>"},{"location":"tutorial/web-ui/create_endpoint/","title":"How to Create Connector Endpoint","text":"<p>In this tutorial, we will walk you through the process of connecting to your Large Language Models (LLMs) using Model Endpoints in Moonshot. </p> <p>As a user, you may have developed or have access to various LLMs that you want to integrate into the Moonshot toolkit. Model Connectors are the bridge that allows this integration, connecting to your LLMs via Connectors. </p> <p>This tutorial will provide a step-by-step guide on how to write the necessary configuration to establish this connection, enabling you to seamlessly integrate and utilize your LLMs within Moonshot. Let's dive in and start connecting your models.</p> <ol> <li> <p>Navigate to the sidebar and click on the first icon to select model endpoints. </p> </li> <li> <p>Initiate the creation of a new endpoint by clicking on 'Create New Endpoint'.  </p> </li> <li> <p>A form will appear. Fill in the required fields and if you need to add more details, click on \"More Configs\" to access additional parameters. </p> </li> <li> <p>After you have filled in all the necessary details and additional parameters, confirm your entries by clicking 'OK'. </p> </li> <li> <p>To finalize the creation of your endpoint, click 'Save'. </p> </li> </ol>"},{"location":"tutorial/web-ui/redteam/","title":"How to Run Red Teaming","text":"<p>In this tutorial, we will guide you through the process of conducting Red Teaming in Project Moonshot.</p> <p>As a user, you may want to test your Large Language Model (LLM) applications in adversarial scenarios to identify potential vulnerabilities. Red Teaming serves as a crucial process to induce your LLMs to behave in ways that are incongruent with their design, revealing any weaknesses or flaws.</p> <p>Project Moonshot simplifies Red Teaming by providing an intuitive interface that allows for simultaneous probing of multiple LLM applications. It also equips you with Red Teaming tools like prompt templates, context strategies, and attack modules. </p> <p>This tutorial will provide a step-by-step guide on how to run Red Teaming, enabling you to effectively identify and address vulnerabilities in your AI systems. Let's get started on your first Red Teaming session.</p> <ol> <li>Start by navigating to the 'Discover new vulnerabilities' section.</li> </ol> <p></p> <ol> <li>On this page, you are prompted to select an endpoint for testing. You have the option to create a new endpoint or modify an existing one. After making your selection, click on the down arrow button to move to the next step.</li> </ol> <p></p> <ol> <li>This step presents a list of attack modules available for your red teaming. For the purpose of this tutorial, select 'skip for now'.</li> </ol> <p></p> <ol> <li>You are now required to complete a form on this page. After filling out the form, initiate a red teaming session by clicking on 'Start'.</li> </ol> <p></p> <ol> <li>You have now entered a session to conduct your red teaming. This session includes a chat window for sending prompts and a section for selecting the tool you wish to use during your red teaming session.</li> </ol> <p></p>"},{"location":"tutorial/web-ui/redteam/#manual-red-teaming","title":"Manual Red Teaming","text":"<p>During manual red teaming, you have the option to utilize tools like Prompt Templates and Context Strategy. These tools assist in structuring and providing context to your prompts.</p> <p>You can load either a prompt template or a context strategy from the tools section.  After making your selection, input your prompt into the chat window. You will then observe the enhancements that have been incorporated into your prompt. </p>"},{"location":"tutorial/web-ui/redteam/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>To initiate an automated red teaming, you would need to load an attack module.</p> <p>Navigate to the 'Attack Module' within the tools section. Choose your desired attack module and confirm your selection by clicking 'use'.</p> <p></p> <p>Type your prompt in the chat window and it will start the automated redteaming.</p> <p></p>"},{"location":"web_ui/cookbook/","title":"Creating Cookbook","text":"<p>If the user wants to define their own cookbook, click on the My Cookbooks icon in the desktop.</p>"},{"location":"web_ui/cookbook/#accessing-cookbook-page","title":"Accessing Cookbook page","text":"<p>When you enter the My Cookbooks page, a modal is displayed showcasing the existing cookbooks, with the option of creating new cookbooks.</p> <p>Click on the Add New Cookbook button to create a new cookbook. </p>"},{"location":"web_ui/cookbook/#selecting-recipes","title":"Selecting Recipes","text":"<p>A list of available recipes will be shown for selection.</p> <p>You can now browse through the list of available recipes and select the ones that you wish to include in your new cookbook.  </p>"},{"location":"web_ui/cookbook/#creating-your-cookbook","title":"Creating Your Cookbook","text":"<p>Once you have finalised your recipes of choice, you will be required to give the cookbook a <code>Name</code> and <code>Description</code>. This would help in identifying and organisation the cookbook.</p> <p>After filling up the form in the modal, click on *Create Cookbook to create your new cookbook.</p> <p>Upon successful creation of the cookbook, the newly created cookbook is now available in the list of cookbooks on the Cookbook page. </p>"},{"location":"web_ui/model_endpoint/","title":"Model Endpoint","text":"<p>Upon opening the Web UI, the user is presented with a desktop interface.</p>"},{"location":"web_ui/model_endpoint/#selecting-models-folder","title":"Selecting Models Folder","text":"<p>Click on the Models icon on the desktop. </p>"},{"location":"web_ui/model_endpoint/#add-new-endpoint","title":"Add New Endpoint","text":"<p>In the pop-up Models window, select Add New Model. </p> <p>A form will appear, prompting you to fill in the necessary fields.  <code>Other Paramters</code> is an optional field. If there are specific parameters to set for the endpoint, the user can fill them in this field.</p>"},{"location":"web_ui/model_endpoint/#create-endpoint","title":"Create Endpoint","text":"<p>After filling in the required fields, click on the Save Model\u00a0button. </p> <p>Upon successful creation of the endpoint, the newly created model is displayed in the left column of the popup.</p>"},{"location":"web_ui/model_endpoint/#selecting-models","title":"Selecting Models","text":"<p>Click on the Select Models for Testing option from the sidebar menu.</p> <p>This action leads to a page where you can see the list of available models, including the one you just created. </p>"},{"location":"web_ui/model_endpoint/#choosing-action","title":"Choosing Action","text":"<p>With the model selected, you now have the option to: </p> <ul> <li>Start Benchmarking</li> <li>Start Red Teaming </li> </ul>"},{"location":"web_ui/red_teaming/","title":"Red Teaming","text":"<p>After selecting the desired model, click on the Red Team option. A new page opens up, indicating the start of the Red Teaming session. </p>"},{"location":"web_ui/red_teaming/#add-more-models","title":"Add More Models","text":"<p>In the Red Teaming Page, the selected model(s) are displayed. The user can choose to add more models to the test by clicking on the Add Model button if required. </p>"},{"location":"web_ui/red_teaming/#selecting-red-teaming-strategy","title":"Selecting Red Teaming Strategy","text":"<p>You can choose to load Prompt Template or Context Strategy to your red teaming session.</p> <p>To select a Prompt Template, click on Prompt Template options.</p> <p>to select Context Strategy, click on Context Stratey options.</p> <p>You are also required to fill in the <code>Session Name</code> and <code>Description</code> for the session. This information helps in identifying and documenting the red teaming session for future reference.</p> <p>Once you have fill in all the necessary details, click on Start Red Team button. </p>"},{"location":"web_ui/red_teaming/#chat-windows","title":"Chat Windows","text":"<p>The red teaming session will display windows of chat, depending on how many endpoints are selected. Each window will represent an endpoint and shows the ongoing conversation.</p> <p>You can minimise the screen of each endpoint's chat window to focus on specific interactions. </p>"},{"location":"web_ui/red_teaming/#sending-prompt","title":"Sending Prompt","text":"<p>To initiate an interaction with the endpoints, type in a prompt at the chatbox. All chat windows will reflect the prompts and response from the appropriate endpoints. </p>"},{"location":"web_ui/red_teaming/#modifying-prompt-template","title":"Modifying Prompt Template","text":"<p>In a session, you will be able to load and unload a prompt template according to your need. </p> <p>To do so, you can access the prompt templates section in the chat box and choose the prompt template you wish to load. </p>"},{"location":"web_ui/red_teaming/#closing-session","title":"Closing Session","text":"<p>To end a session, you can do so by clicking on Close Session at the top right corner of the window.</p>"},{"location":"web_ui/red_teaming/#reviewing-past-session","title":"Reviewing Past Session","text":"<p>To view the list of created sessions, you can click on My Sessions folder on the desktop.</p>"},{"location":"web_ui/red_teaming/#resuming-a-session","title":"Resuming a Session","text":"<p>By selecting any past session, you can resume the session by clicking on the Resume Session button. </p>"},{"location":"web_ui/run_benchmark_test/","title":"Running Benchmark Test","text":"<p>After selecting the desired model, click on the Benchmark option. A new page opens up, indicating the start of the benchmarking process. </p>"},{"location":"web_ui/run_benchmark_test/#adding-cookbook","title":"Adding Cookbook","text":"<p>To select what kind of benchmark test to run, within the benchmarking interface, click on the \"+\" button. A model window appears, displaying available pre-defined cookbooks for selection. </p>"},{"location":"web_ui/run_benchmark_test/#selecting-cookbook","title":"Selecting Cookbook","text":"<p>You can now browse through the list of available cookbooks.</p> <p>Upon finding the desired cookbook, click on it to add it to the list for testing. </p>"},{"location":"web_ui/run_benchmark_test/#start-testing","title":"Start Testing","text":"<p>Once the selection of cookbooks is finalised, you will be required to field in the <code>Run Name</code> and <code>Description</code> for the benchmarking test.</p> <p>This information helps in identifying and documenting the benchmarking test for future reference. </p> <p>After providing the necessary details, on click on the Run Benchmark button. </p>"},{"location":"web_ui/run_benchmark_test/#monitoring-benchmark-status","title":"Monitoring Benchmark Status","text":"<p>As the benchmark test progresses, the user can monitor the status of the process.</p> <p>On the right side of the UI, a Status modal displays real-time updates on the benchmarking progress.</p> <p>The status modal may indicate phases such as \"In Process\", \"Completed\" or \"Failed\" along with relevant details and metrics.</p>"},{"location":"web_ui/run_benchmark_test/#checking-results","title":"Checking Results","text":"<p>Once the benchmarking process is completed, simply click on the Results button to view the result.</p>"},{"location":"web_ui/web_ui_guide/","title":"User Guide for Moonshot Web UI","text":""},{"location":"web_ui/web_ui_guide/#getting-started-with-moonshot-web-ui","title":"Getting Started with Moonshot Web UI","text":"<p>In this step-by-step tutorial, we will walk you through the key functionalities of Project Moonshot\u2019s user-friendly web UI. </p> <p>Before starting on this tutorial, you should Install and Set Up Moonshot Web UI and have an understanding of Moonshot\u2019s key features. </p> <p>This tutorial will walk you through the UI\u2019s guided workflow to: </p> <ol> <li>Choose tests relevant to your AI system </li> <li>Set up connection to your AI systems </li> <li>Run Benchmarks </li> <li>Conduct Red-Teaming </li> </ol> <p>After you have completed this tutorial, you can learn some of these more advanced functions: </p> <ol> <li>How to create custom cookbooks </li> </ol>"},{"location":"web_ui/web_ui_guide/#1-choosing-relevant-tests","title":"1. Choosing Relevant Tests","text":"<ol> <li> <p>Click on \u2018Get Started\u2019      </p> </li> <li> <p>This page lists the cookbooks that Project Moonshot provides. Each cookbook contains tests of the same theme. Select the areas that are relevant to your use case. This is not final as you will be able to further curate the scope and scale of the tests in following steps.  View full list of cookbook details </p> <p>Note</p> <p>Some of these cookbooks contain scoring metrics that require connection to specific models. </p> <p>MLCommons AI Safety Benchmarks v0.5 (Requires an API key for accessing Llama Guard via Together AI) </p> <p>Facts about Singapore (Requires an API key for accessing Llama Guard via Together AI) </p> <p>How to set up alternative connections </p> </li> <li> <p>When done, click on the next button.       </p> </li> <li> <p>This page shows the total number of prompts that will be sent to each AI system you want to test. Click on \u2018these cookbooks\u2019 to see in greater detail what tests will be run.       </p> </li> <li> <p>This page shows you the cookbooks available in Project Moonshot, categorised according to Capability, Trust &amp; Safety, Quality and Others (for cookbooks without any categories).   </p> <p>You can click on \u2018About\u2019 for each cookbook to see what recipes it contains. </p> <p> </p> <p>Check the \u2018Run this cookbook\u2019 checkbox if you wish to run any of the cookbooks. Click on \u2018X\u2019 to close the pop-up. </p> <p> </p> <p>You can also unselect cookbooks if you do not wish to run them. </p> <p>Click on \u2018OK\u2019 once you are satisfied with the cookbooks to be run. The total number of prompts to be sent should be updated. (There will be a step later on in the workflow for you to run a smaller number of prompts) </p> <p> </p> <p>Click on the next button. </p> <p> </p> </li> </ol>"},{"location":"web_ui/web_ui_guide/#2-connecting-ai-systems","title":"2. Connecting AI Systems","text":"<ol> <li> <p>This page shows you the connector endpoints available to be tested. Project Moonshot comes with pre-configured connector endpoints to some popular model providers, you will just need to provide your API key.  </p> <ul> <li> <p>Click on \u2018Edit\u2019 to add in the API key for any of these models you may wish to test. </p> </li> <li> <p>If you wish to test other LLMs or your own hosted LLM application, click on \u2018Create New Endpoint\u2019. </p> </li> </ul> <p></p> </li> <li> <p>Provide the following info as necessary, and click \u2018Save\u2019 to create/ update the endpoint. </p> <p></p> Name Description Example Name (Required) A unique name for you to identify this new endpoint by <code>My GPT4</code> Connection Type (Required) Type of API to use. If you do not see the type that you need, see How to build a custom connector <code>openai-connector</code> URI URI to the endpoint to be tested <code>&lt;left blank&gt;</code> Token Your private API token <code>123myopenaicontoken456</code> Max Calls Per Second The maximum number of calls to be made to the endpoint per second <code>10</code> Max Concurrency The maximum number of calls that can be made to the endpoint at any one time <code>1</code> Other Parameters Certain connector types require extra parameters. E.g., for OpenAI connectors, you will need to specify the <code>model</code>. See OpenAI docs <code>{ \"timeout\": 300, \"allow_retries\": true, \"num_of_retries\": 3, \"temperature\": 0.5, \"model\": \"gpt-4\" }</code> </li> <li> <p>Select the endpoints to the AI systems that you wish to run benchmarks on, and click the next button when done. </p> <p>Note</p> <p>If you wish to run any of these cookbooks, you will need to provide additional API keys:      1. MLCommons AI Safety Benchmarks v0.5, Facts about Singapore </p> <p>Click on \u2018Edit\u2019 for Together Llama Guard 7B Assistant, provide your API token, and click \u2018Save\u2019.(You don\u2019t need to select Together Llama Guard 7B Assistant for testing)  </p> </li> </ol>"},{"location":"web_ui/web_ui_guide/#3-running-benchmarks","title":"3. Running Benchmarks","text":"<ol> <li> <p>Before you can start running benchmarks, provide the following info. These will be included in the report generated at the end of the run. </p> Name Description Example Name (Required) A unique name for you to identify this benchmark run by <code>GPT4 vs Claude on safety benchmarks</code> Description Describe the purpose and scopte of this benchmark run. Comparing GPT4 and Claude to determine which model is safer as a chatbot Run a smaller set The number of prompts per recipe to be run. Indicating 0 will run the full set.  * Before running the full recommended set, you may want to run a smaller number of prompts from each recipe to do a sanity check. 5 <li> <p>Click \u2018Run\u2019 to start running the benchmarks. </p> <p></p> </li> <li> <p>You can click on \u2018See Details\u2019 to recap on what is currently being run. </p> <p></p> </li> <li> <p>A report will be generated once the run is completed. Meanwhile, you can:</p> <ul> <li>Start Red Teaming to discover new vulnerabilities   </li> <li>Create a custom cookbook by curating your own set of recipes   </li> <li>Go back to home  </li> </ul> </li> <li> <p>To view the progress of the run, click on the bell icon, then select the specific benchmark run.</p> <p></p> </li> <li> <p>Once run is completed, you can click on \u2018View Report\u2019 </p> <p></p> </li> <li> <p>One report will be generated for each endpoint tested. Click on the dropdown to toggle the report displayed. You can also download the HTML report and the detailed results as a JSON file. </p> <p></p> </li> <li> <p>You can also view the details of previous runs through: </p> <ol> <li>Click on \u2018history\u2019 icon, then \u2018View Past Runs\u2019 </li> <li>Click on \u2018benchmarking\u2019 icon, then \u2018View Past Runs\u2019 </li> </ol> </li>"},{"location":"web_ui/web_ui_guide/#4-red-teaming","title":"4. Red-Teaming","text":"<ol> <li> <p>Click on \u2018Discover new vulnerabilities, Start Red Teaming\u2019 to start a new Red-Teaming session. </p> <p></p> </li> <li> <p>Select the endpoints to the AI systems that you wish to Red-Team simultaneously in this session, and click the next button when done.  * There is currently no hard limit to the number of endpoints you can Red-Team at once, but we recommend to keep it under 5 for a smoother UX.</p> <p></p> </li> <li> <p>This page shows you the various attack modules that you can use to automate your Red-Teaming process. Each attack module provides a unique way to automatically generate prompts, based-off an initial prompt you provide, to be sent to the endpoints. Some of these attack modules require the connection to a helper model E.g. GPT4. </p> <p>Select one attack module you would like to try out as a start and click the next button, or click on \u2018Skip for now\u2019:  You will be able to start using attack modules in the midst of a Red-Teaming session. </p> </li> <li> <p>Before you can start the new Red-Teaming session, provide the following info. </p> Name Description Example Name (Required) A unique name for you to identify this Red-Teaming session by Try to jailbreak GPTs Description Describe the purpose and scope of this Red-Teaming session. Comparing GPT versions on resistance to various attack techniques <p></p> </li> <li> <p>Click \u2018Start\u2019 to create the new Red-Teaming session. </p> </li> <li> <p>This page shows Project Moonshot\u2019s Red-Teaming interface.  </p> <p></p> </li> </ol> <p>Chat boxes and Layout</p> <p>Each chat box will allow you to view the prompt and response sent to / received from each endpoint.   </p> <p>There are two layout options:  1. Carousel (Default if you have &gt;3 endpoints) and   2. Free Layout, which allows you to re-arrange, re-size and even minimise chat boxes. </p> <p>Sending Prompts</p> <p>Type your prompt in the \u2018Prompt\u2019 text box and click \u2018Send\u2019 to send that prompt to all the endpoints in your session.      </p> <p>Red-Teaming Tools </p> <p>You can use some of these tools to enhance your Red-Teaming process: </p> <ol> <li> <p>Attack Modules  Attack modules are techniques that will enable the automatic generation of adversarial prompts for automated Red-Teaming. Click on \u2018Attack Modules\u2019 to view the list of attack modules that are available for use.          Click on \u2018Use\u2019 to select an attack module.     </p> <p>Note</p> <p>If you wish to run any of these attack modules, you will need to provide additional API keys: </p> <pre><code>1. Malicious Question Generator (Requires OpenAI\u2019s GPT4)\n\n2. Violent Durian (Requires OpenAI\u2019s GPT4)\n</code></pre> <p>To provide the API keys, go to \u2018Model Endpoints\u2019 and click on \u2018Edit\u2019 for OpenAI GPT4, provide your API token, and click \u2018Save\u2019. (You don\u2019t need to select OpenAI GPT4 in the Red Teaming session) </p> <ul> <li>Enter your prompt in the \u2018Prompt\u2019 box as the initial prompt that the attack module will use to generate adversarial prompts from. </li> <li>Click \u2018Send\u2019 to trigger the attack module and start the automated Red-Teaming process. Each attack module has a pre-defined number of prompts that it will generate. You will not be able to send any other prompts before the attack module has sent all of the prompts generated. </li> </ul> <p></p> <p>Click on 'X' to remove the attack module set. </p> </li> <li> <p>Prompt Templates     Prompt templates are predefined text structures that guide the formatting and contextualisation of the prompt sent to the AI system being tested. Click on \u2018Prompt Templates\u2019 to view the list of prompt templates that are available for use. </p> <p>Click on 'Use' to select a prompt template. </p> <p>Enter your prompt in the \u2018Prompt\u2019 box. The prompt template you selected will be applied to the prompt when you click \u2018Send\u2019.  </p> <p>Hover your mouse over each prompt to view its details.  </p> <p>Click on \u2018X\u2019 to remove the prompt template set.  </p> </li> <li> <p>Context Strategies     Context Strategies are predefined approaches to append the Red-Teaming session's context to each prompt. Click on \u2018Context Strategies\u2019 to view the list of context strategies that are available for use. </p> <p>Click on \u2018Use\u2019 to select a context strategy.  </p> <p>Enter your prompt in the \u2018Prompt\u2019 box. Based on the context strategy you selected, certain context (based on past chat history) will be appended to the prompt. </p> <p>Click on \u2018X\u2019 to remove the context strategy set.  </p> </li> </ol> <p>Ending a Session All sessions are being saved in real time, you can click on the \u2018X\u2019 button to end a session and resume it later.  </p> <p>Click on 'Exit'. </p> <p>Resuming a Session</p> <p>You can also view the details of previous sessions or resume a session through:      1. Click on \u2018history\u2019 icon, then \u2018View Past Sessions\u2019      2. Click on \u2018red teaming\u2019 icon, then \u2018View Past Sessions\u2019   </p>"},{"location":"web_ui/web_ui_guide/#5-creating-custom-cookbooks","title":"5. Creating Custom Cookbooks","text":"<p>Using the recipes available on Project Moonshot, you can easily curate custom cookbooks to suit your testing needs. </p> <ol> <li> <p>Click on \u2018Create cookbooks, Select Recipes \u2192\u2019 </p> </li> <li> <p>Provide the following information.</p> Name Description Example Name (Required) A unique name to identify this cookbook by. My Custom Cookbook Description Describe what the tests in this cookbook will cover. This cookbook is designed to evaluate chatbots in capabilities that we expect it to excel in. <p></p> </li> <li> <p>Click on \u2018Select Recipes\u2019. </p> </li> <li> <p>Here you can view the list of recipes available in Moonshot. Select the recipes that you would like to include in your custom cookbook and click on \u2018Add to Cookbook\u2019. </p> <p></p> </li> <li> <p>Click on \u2018Create Cookbook\u2019, then \u2018View Cookbooks\u2019 to view all the cookbooks that you now have in the tool. </p> <p></p> </li> <li> <p>To run this cookbook, click on \u2018Get Started\u2019 </p> <p></p> </li> </ol>"}]}