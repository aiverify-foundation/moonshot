{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#welcome-to-moonshots-documentation","title":"Welcome to Moonshot's Documentation","text":"<p>Moonshot is a tool designed for AI developers and security experts to test and evaluate AI systems. Moonshot seamlessly integrates into your model development workflow, enabling repeatable tests through interactive use via command line interface (CLI), Python notebooks, or a Web UI.</p> <p>Below are some useful links to help you get started with Moonshot.</p> <ul> <li>If you want to quickly start on Moonshot, look at getting started.</li> <li>If you want to learn how to use Moonshot-UI, the Web UI guide is the best place.</li> <li>If you want to integrate our library with your CI/CD pipeline, we suggest taking a look at our API reference.</li> </ul>"},{"location":"contributing/","title":"Moonshot Contribution Guide","text":""},{"location":"contributing/#welcome","title":"Welcome","text":"<p>Welcome to Moonshot's Contributor Guide!</p> <p>We always welcome community contributions to Moonshot, and the Moonshot team appreciates any help the community can give to make Moonshot better. This guide will help you understand how to contribute to the test assets in Moonshot.</p> <ul> <li>Submit your changes directly with a pull request</li> <li>Log a bug or make a feature request with an issue</li> </ul> <p>It is recommended that you follow these steps in order:</p> <ul> <li>Prerequisites - what you need to do first before you can start contributing to Moonshot</li> <li>Your First Contribution - things you need to do to make your first contribution</li> <li>Contributing by Pull Requests - contribute to our repository</li> </ul>"},{"location":"contributing/#prerequisites","title":"Prerequisites","text":"<p>Before contributing to Moonshot's test assets, you should first ensure that you have these ready:</p>"},{"location":"contributing/#create-a-github-account","title":"Create a Github Account","text":"<p>You will need to sign up for a Github user account.</p>"},{"location":"contributing/#setting-up-your-development-environment","title":"Setting up your development environment","text":"<p>You will need to install both <code>moonshot</code> and <code>moonshot-data</code> to test your test assets.</p> <p>Visit this page to learn how to install the necessary dependencies.</p>"},{"location":"contributing/#contribution-scope","title":"Contribution Scope","text":"<p>Currently, Moonshot is only accepting contributions for <code>moonshot-data</code>. This includes <code>connectors</code>, <code>metrics</code>, <code>benchmarks</code> (in the form of <code>dataset</code>, <code>recipe</code> and <code>cookbook</code>).</p>"},{"location":"contributing/#your-first-contribution","title":"Your First Contribution","text":""},{"location":"contributing/#adding-a-new-connector","title":"Adding a new connector","text":"<p>You can find a list of available connectors here.</p> <p>For more details, you may refer to the HOW-TO guide on how to add a new connector.</p>"},{"location":"contributing/#adding-a-new-metric","title":"Adding a new metric","text":"<p>You can find a list of available metrics here.</p> <p>The best way to start developing a new metric is to learn by an example. We have included a sample metric, samplemetric.py.</p>"},{"location":"contributing/#modify-your-metric-metadata","title":"Modify Your Metric Metadata","text":"<p>Using <code>samplemetric.py</code> as an example, you can edit the following elements from line 20 to line 22.</p> <ol> <li><code>id</code>: This is the identifier of the metric that the user will use in their recipe or red teaming module. This should be the file name.</li> <li><code>name</code>: This is the name of the metric. This will be shown when the user lists the metrics.</li> <li><code>description</code>: This is the description of the metrics. This will be shown when the user lists the metrics. The description should describe what the metrics measure.</li> </ol>"},{"location":"contributing/#add-evaluation-code","title":"Add Evaluation Code","text":"<p>The core code should be written in <code>get_results</code>. In this function, you will have access to three parameters:</p> <ol> <li><code>prompts</code>: the list of prompts used to generate the predictions</li> <li><code>predicted_results</code>: the list of predicted responses based on the prompts</li> <li><code>targets</code>: the list of ground truth</li> </ol> <p>In addition to these 3 parameters, you can also access user-defined metric configurations at line 23. Users provide their configurations through the <code>metrics_config.json</code> file. <pre><code>{\n    \"samplemetric\":{\n        \"endpoints\": [\n            \"openai-gpt35-turbo-16k\",\n            \"openai-gpt35-turbo\"\n        ],\n        \"threshold_value\": \"0.35\",\n        \"num_of_prompts_to_calculate\": 1\n    }\n}\n</code></pre></p> <p>Note</p> <p>Do you need to use an external model for your metric? You have the flexibility to do so. For instance, you can use the transformers library to download a model from HuggingFace and run inference on the predicted responses.</p>"},{"location":"contributing/#prepare-results","title":"Prepare Results","text":"<p>The output of a metric module must be a dictionary.</p> <pre><code>result = {\n    \"samplemetric\": {\"num_above_threshold\": count},\n    \"grading_criteria\": {\"num_above_threshold\": count},\n}\n</code></pre> <p>The <code>grading_criteria</code> will be used by the grading scale in the recipe to assess the outcome of the test. The key <code>grading_criteria</code> must be present in the returned dictionary, but its value can be an empty dictionary. If the value is an empty dictionary, the report generated from the UI will display '-' as the grade.</p>"},{"location":"contributing/#adding-a-new-dataset","title":"Adding a new dataset.","text":"<p>You can find a list of available datasets here.</p> <p>To create a Moonshot-compatible dataset, you can convert your raw dataset into this format:</p> <pre><code>{\n    \"name\": \"name of the dataset\",\n    \"description\": \"description\",\n    \"license\": \"\",\n    \"reference\": \"\",\n    \"examples\": [\n        {\n            \"input\": \"prompt 1\",\n            \"target\": \"ground truth\"\n        },\n\n        {\n            \"input\": \"prompt 2\",\n            \"target\": \"ground truth\"\n        }\n        ....\n    ]\n}\n</code></pre> <p>To run your dataset, you need to create a recipe so that Moonshot knows how it can be evaluated. The filename of the dataset will serve as the unique identifier in the recipe. </p>"},{"location":"contributing/#adding-a-new-recipe","title":"Adding a new recipe","text":"<p>You can find a list of available recipes here.</p> <p>To create a recipe, you can copy one of the recipe files and edit the following elements:</p> <ol> <li><code>id</code>: This is an unique identifier that will be used by the user. This should be the file name.</li> <li><code>name</code>: This is the name of the recipe, which will be displayed when a recipe is listed.</li> <li><code>description</code>: This describes what the recipe tests. We recommend also including what constitutes a better score and what that implies..</li> <li><code>tags</code>: This is a list of tags, which can help the user to find your recipe. We suggest to insert some relevant keywords related to domain and nature of the test.</li> <li><code>categories</code>: This helps to group the recipe. We suggest using <code>Trust &amp; Safety</code>, <code>Capability</code> and <code>Quality</code>.</li> <li><code>datasets</code>: This contains a list of dataset identifiers used in this recipe. This dataset must be included in this folder.</li> <li><code>prompt_templates</code>: This contains a list of prompt templates used in this recipe. This prompt template must be found in this folder.</li> <li><code>attack_modules</code>: A list of attack modules that is used in this recipe. The attack modules must be available in this folder.</li> <li><code>metrics</code>: This contains a list of metric identifiers used in this recipe. This metric must be included in this folder.</li> <li><code>grading_scale</code>: This grading scale helps to determine the outcome of the test. Leaving this empty will result in '-' as its grade in the report.</li> </ol> <p>Here's an example recipe:</p> <pre><code>{\n    \"id\": \"recipe1\",\n    \"name\": \"Recipe 1\",\n    \"description\": \"This recipe measures performance of the system.\",\n    \"tags\": [\"Safety\"],\n    \"categories\": [\"Trust &amp; Safety\"],\n    \"datasets\": [\"dataset1\"],\n    \"prompt_templates\": [],\n    \"metrics\": [\"exactstrmatch\"],\n    \"attack_modules\": [],\n    \"grading_scale\": {\n        \"A\": [\n            80,\n            100\n        ],\n        \"B\": [\n            60,\n            79\n        ],\n        \"C\": [\n            40,\n            59\n        ],\n        \"D\": [\n            20,\n            39\n        ],\n        \"E\": [\n            0,\n            19\n        ]\n    }\n}\n</code></pre>"},{"location":"contributing/#adding-a-new-cookbook","title":"Adding a new cookbook","text":"<p>You can find a list of available cookbooks here.</p> <p>To create a cookbook, you can copy one of the cookbook files and edit the following elements:</p> <ol> <li><code>id</code>: This is an unique identifier that will be used by the user. This should be the file name.</li> <li><code>name</code>: This is the name of the recipe, which will be displayed when a recipe is listed.</li> <li><code>description</code>: This describes what the recipe test.</li> <li><code>recipes</code>: This contains a list of recipe identifiers that this cookbook will execute. These recipes must be found in this folder.</li> </ol> <p>Here's an example cookbook:</p> <pre><code>{\n    \"id\": \"example-cookbook\",\n    \"name\": \"Example Cookbook\",\n    \"description\": \"This cookbook measures the system performance. \",\n    \"recipes\": [\n        \"recipe1\",\n        \"recipe2\"\n    ]\n}\n</code></pre>"},{"location":"contributing/#contributing-by-pull-requests-prs","title":"Contributing by Pull Requests (PRs)","text":"<p>Any contributions are greatly appreciated.</p> <p>Please fork the repo and create a pull request. You can also open an issue with the tag <code>\"enhancement\"</code>. Do give the project a star too!</p> <ol> <li>Fork the <code>moonshot-data</code> Project</li> <li>Install <code>moonshot</code> (to run your test assets)</li> <li>Create your branch (<code>git checkout -b connector/X</code> or <code>git checkout -b metric/X</code> or <code>git checkout -b cookbook/X</code> or <code>git checkout -b recipe/X</code> or ... )</li> <li>Push to the branch (<code>git push origin metric/X</code>)</li> <li>Open a Pull Request</li> </ol>"},{"location":"faq/","title":"FAQ","text":""},{"location":"faq/#installation","title":"Installation","text":""},{"location":"faq/#how-do-i-get-started","title":"How do I get started?","text":"<p>To install Moonshot, please follow our quick start guide or quick install page </p>"},{"location":"faq/#what-are-moonshots-prerequisites","title":"What are Moonshot's prerequisites?","text":"<p>Here are the requirements. You can also find this table in our quick install page.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git"},{"location":"faq/#should-i-use-the-stable-version-or-development-version","title":"Should I use the stable version or development version?","text":"<p>If you are using Moonshot in production, you should use a stable release. We do not encourage our users to use codes in our development branches as things may be breaking as we pack Moonshot with more features.</p>"},{"location":"faq/#where-can-i-go-to-get-help","title":"Where can I go to get help?","text":"<p>If this page doesn't contain an answer to your question, you might want to raise an issue on our Github. Feel free to ask any question!</p>"},{"location":"faq/#what-should-i-do-when-i-face-missing-dependency-errors","title":"What should I do when I face missing dependency errors?","text":"<p>We highly recommend using <code>pypi</code> to install our latest release.</p>"},{"location":"faq/#what-happens-if-im-not-using-python-311","title":"What happens if I'm not using Python 3.11?","text":"<p>You may face issues installing some of the dependencies. We suggest using virtual environment of your choice and use Python 3.11 with Moonshot.</p>"},{"location":"faq/#what-happens-if-i-experience-timeouts-during-package-installation","title":"What happens if I experience timeouts during package installation?","text":"<p>Some of the functions may not work as expected. We suggest users to reinstall Moonshot to ensure that all libraries are installed successfully.</p>"},{"location":"faq/#using-moonshot","title":"Using Moonshot","text":""},{"location":"faq/#my-tests-are-all-completed-with-errors-i-cant-view-any-report","title":"My tests are all completed with errors! I can't view any report!","text":"<p>Some benchmark tests and attack modules require connector endpoints to be configured beforehand. You may encounter this type of error:</p> <p></p> <p>Some examples are:</p> Test Model Required Name of the Endpoint MLCommons AI Safety Benchmarks v0.5 (Cookbook) Meta LlamaGuard Together Llama Guard 7B Assistant Singapore Safety (Recipe) Meta LlamaGuard Together Llama Guard 7B Assistant Malicious Question Generator (Attack Module) OpenAI GPT4 OpenAI GPT4 Violent Durian (Attack Module) OpenAI GPT4 OpenAI GPT4 <p>If you are not running any of the above, you should check the details of the specific attack module/ recipe\u2019s metric that you are using, on what model connection is needed.</p> <p>If you do not have tokens for Llama Guard via Together AI, </p> <ol> <li>Create a new connector endpoint to your alternative Llama Guard 7B assistant and note down the endpoint ID of this connector endpoint created.</li> <li>Open up <code>moonshot-data/metrics_config.json</code> in a code editor</li> <li>Replace <code>together-llama-guard-7b-assistant</code> with your new endpoint ID.</li> <li>Save the file and run your test.</li> </ol>"},{"location":"faq/#i-cant-delete-my-runner-in-the-cli-on-windows","title":"I can't delete my runner in the CLI on Windows.","text":"<p>We are aware that there is an issue deleting runner in the CLI if you are using Windows operating system. You may see the following error when you attempt to delete one of the runners using CLI:</p> <pre><code>moonshot &gt; delete_runner new-recipe\nAre you sure you want to delete the runner (y/N)? y\n[Runner] Failed to delete runner: [WinError 32] The process cannot access the file because it is being used by another process: 'moonshot-data-test\\\\generated-outputs\\\\databases\\\\new-recipe.db'\n[delete_runner]: [WinError 32] The process cannot access the file because it is being used by another process: 'moonshot-data-test\\\\generated-outputs\\\\databases\\\\new-recipe.db'\n</code></pre> <p>We are working to produce a fix. In the meanwhile, please exit the program and delete it via your file explorer.</p>"},{"location":"faq/#i-cant-save-my-token-for-the-connector-endpoint","title":"I can't save my token for the connector endpoint!","text":"<p>We acknowledge a potential issue with saving tokens via the UI. As a workaround, you can directly access the JSON file of your endpoint. This file is located in the <code>moonshot-data/connector-endpoints</code> directory, which was created during the installation process.</p> <p>Open your preferred code editor, locate the <code>token</code> field, and replace <code>ADD_API_TOKEN</code> with your actual API token. <pre><code>{\n  \"id\": \"example-connector-endpoint\",\n  \"name\": \"Example Endpoint\",\n  \"connector_type\": \"...\",\n  \"uri\": \"\",\n  \"token\": \"ADD_API_TOKEN\",\n  \"max_calls_per_second\": 1,\n  \"max_concurrency\": 1,\n  \"params\": {\n      ...\n  }\n}\n</code></pre></p>"},{"location":"faq/#i-cannot-see-my-newly-created-endpoints-in-the-model-endpoint-page","title":"I cannot see my newly created endpoints in the model endpoint page.","text":"<p>Please refresh the page.</p>"},{"location":"faq/#i-am-unable-to-install-pytorch","title":"I am unable to install PyTorch","text":"<p>If you are operating on an x86 MacOS, you may encounter difficulties when attempting to install the PyTorch requirement from the moonshot-data. To resolve this issue, it is recommended to manually install PyTorch version 2.2.0, which is compatible with your computer's architecture.</p>"},{"location":"api_reference/api_bookmark/","title":"Bookmark API","text":""},{"location":"api_reference/api_bookmark/#moonshot.src.api.api_bookmark.api_delete_all_bookmark","title":"<code>api_delete_all_bookmark()</code>","text":"<p>Removes all bookmarks from the database.</p> Source code in <code>moonshot/src/api/api_bookmark.py</code> <pre><code>def api_delete_all_bookmark() -&gt; dict:\n    \"\"\"\n    Removes all bookmarks from the database.\n    \"\"\"\n    return Bookmark.get_instance().delete_all_bookmark()\n</code></pre>"},{"location":"api_reference/api_bookmark/#moonshot.src.api.api_bookmark.api_delete_bookmark","title":"<code>api_delete_bookmark(bookmark_name)</code>","text":"<p>Removes a bookmark from the database using its name.</p> <p>Parameters:</p> Name Type Description Default <code>bookmark_name</code> <code>str</code> <p>The name of the bookmark to be removed.</p> required Source code in <code>moonshot/src/api/api_bookmark.py</code> <pre><code>def api_delete_bookmark(bookmark_name: str) -&gt; dict:\n    \"\"\"\n    Removes a bookmark from the database using its name.\n\n    Args:\n        bookmark_name (str): The name of the bookmark to be removed.\n    \"\"\"\n    return Bookmark.get_instance().delete_bookmark(bookmark_name)\n</code></pre>"},{"location":"api_reference/api_bookmark/#moonshot.src.api.api_bookmark.api_export_bookmarks","title":"<code>api_export_bookmarks(export_file_name='bookmarks')</code>","text":"<p>Exports bookmarks to a specified file.</p> <p>Parameters:</p> Name Type Description Default <code>export_file_name</code> <code>str</code> <p>The name of the file to export the bookmarks to.</p> <code>'bookmarks'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The filepath of where the file is written.</p> Source code in <code>moonshot/src/api/api_bookmark.py</code> <pre><code>def api_export_bookmarks(export_file_name: str = \"bookmarks\") -&gt; str:\n    \"\"\"\n    Exports bookmarks to a specified file.\n\n    Args:\n        export_file_name (str): The name of the file to export the bookmarks to.\n\n    Returns:\n        str: The filepath of where the file is written.\n    \"\"\"\n    return Bookmark.get_instance().export_bookmarks(export_file_name)\n</code></pre>"},{"location":"api_reference/api_bookmark/#moonshot.src.api.api_bookmark.api_get_all_bookmarks","title":"<code>api_get_all_bookmarks()</code>","text":"<p>Retrieves a list of all bookmarks from the database.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of bookmarks, each represented as a dictionary.</p> Source code in <code>moonshot/src/api/api_bookmark.py</code> <pre><code>def api_get_all_bookmarks() -&gt; list[dict]:\n    \"\"\"\n    Retrieves a list of all bookmarks from the database.\n\n    Returns:\n        list[dict]: A list of bookmarks, each represented as a dictionary.\n    \"\"\"\n    return Bookmark.get_instance().get_all_bookmarks()\n</code></pre>"},{"location":"api_reference/api_bookmark/#moonshot.src.api.api_bookmark.api_get_bookmark","title":"<code>api_get_bookmark(bookmark_name)</code>","text":"<p>Retrieves the details of a specific bookmark by its name.</p> <p>Parameters:</p> Name Type Description Default <code>bookmark_name</code> <code>int</code> <p>The name of the bookmark to retrieve.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>The bookmark details corresponding to the provided ID.</p> Source code in <code>moonshot/src/api/api_bookmark.py</code> <pre><code>def api_get_bookmark(bookmark_name: str) -&gt; dict:\n    \"\"\"\n    Retrieves the details of a specific bookmark by its name.\n\n    Args:\n        bookmark_name (int): The name of the bookmark to retrieve.\n\n    Returns:\n        dict: The bookmark details corresponding to the provided ID.\n    \"\"\"\n    return Bookmark.get_instance().get_bookmark(bookmark_name)\n</code></pre>"},{"location":"api_reference/api_bookmark/#moonshot.src.api.api_bookmark.api_insert_bookmark","title":"<code>api_insert_bookmark(name, prompt, prepared_prompt, response, context_strategy='', prompt_template='', attack_module='', metric='')</code>","text":"<p>Inserts a new bookmark into the database.</p> <p>This function constructs a BookmarkArguments object with the provided details and invokes the add_bookmark method of a Bookmark instance to persist the new bookmark.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The unique name of the bookmark.</p> required <code>prompt</code> <code>str</code> <p>The associated prompt text for the bookmark.</p> required <code>response</code> <code>str</code> <p>The corresponding response text for the bookmark.</p> required <code>context_strategy</code> <code>str</code> <p>The strategy used for context management in the bookmark.</p> <code>''</code> <code>prompt_template</code> <code>str</code> <p>The template used for generating the prompt.</p> <code>''</code> <code>attack_module</code> <code>str</code> <p>The attack module linked with the bookmark.</p> <code>''</code> Source code in <code>moonshot/src/api/api_bookmark.py</code> <pre><code>def api_insert_bookmark(\n    name: str,\n    prompt: str,\n    prepared_prompt: str,\n    response: str,\n    context_strategy: str = \"\",\n    prompt_template: str = \"\",\n    attack_module: str = \"\",\n    metric: str = \"\",\n) -&gt; dict:\n    \"\"\"\n    Inserts a new bookmark into the database.\n\n    This function constructs a BookmarkArguments object with the provided details and\n    invokes the add_bookmark method of a Bookmark instance to persist the new bookmark.\n\n    Args:\n        name (str): The unique name of the bookmark.\n        prompt (str): The associated prompt text for the bookmark.\n        response (str): The corresponding response text for the bookmark.\n        context_strategy (str): The strategy used for context management in the bookmark.\n        prompt_template (str): The template used for generating the prompt.\n        attack_module (str): The attack module linked with the bookmark.\n    \"\"\"\n    # Create a new BookmarkArguments object\n    bookmark_args = BookmarkArguments(\n        id=0,  # id will be auto-generated by the database\n        name=name,\n        prompt=prompt,\n        prepared_prompt=prepared_prompt,\n        response=response,\n        context_strategy=context_strategy,\n        prompt_template=prompt_template,\n        attack_module=attack_module,\n        metric=metric,\n        bookmark_time=\"\",  # bookmark_time will be set to current time in add_bookmark method\n    )\n    return Bookmark.get_instance().add_bookmark(bookmark_args)\n</code></pre>"},{"location":"api_reference/api_connector/","title":"Connector API","text":""},{"location":"api_reference/api_connector/#moonshot.src.api.api_connector.api_create_connector_from_endpoint","title":"<code>api_create_connector_from_endpoint(ep_id)</code>","text":"<p>Creates a connector based on the provided endpoint ID.</p> <p>This function retrieves the endpoint arguments using the provided endpoint ID and then creates a connector based on those arguments. It utilizes the ConnectorManager's read_endpoint method to fetch the endpoint arguments and then calls the create_connector method to initialize and return the connector.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint for which to create a connector.</p> required <p>Returns:</p> Name Type Description <code>Connector</code> <code>Connector</code> <p>An initialized Connector object.</p> Source code in <code>moonshot/src/api/api_connector.py</code> <pre><code>@validate_call\ndef api_create_connector_from_endpoint(ep_id: str) -&gt; Connector:\n    \"\"\"\n    Creates a connector based on the provided endpoint ID.\n\n    This function retrieves the endpoint arguments using the provided endpoint ID and then creates a connector\n    based on those arguments. It utilizes the ConnectorManager's read_endpoint method to fetch the endpoint\n    arguments and then calls the create_connector method to initialize and return the connector.\n\n    Args:\n        ep_id (str): The ID of the endpoint for which to create a connector.\n\n    Returns:\n        Connector: An initialized Connector object.\n    \"\"\"\n    return Connector.create(ConnectorEndpoint.read(ep_id))\n</code></pre>"},{"location":"api_reference/api_connector/#moonshot.src.api.api_connector.api_create_connectors_from_endpoints","title":"<code>api_create_connectors_from_endpoints(ep_ids)</code>","text":"<p>Creates connectors for multiple endpoints based on their IDs.</p> <p>This function takes a list of endpoint IDs, retrieves the corresponding endpoint arguments for each ID, and then creates a connector for each set of arguments. It utilizes the ConnectorEndpoint's read method to fetch the endpoint arguments and then calls the Connector's create method to initialize the connectors.</p> <p>Parameters:</p> Name Type Description Default <code>ep_ids</code> <code>conlist(str, min_length=1</code> <p>A list of endpoint IDs for which to create connectors.</p> required <p>Returns:</p> Type Description <code>list[Connector]</code> <p>list[Connector]: A list of initialized Connector objects.</p> Source code in <code>moonshot/src/api/api_connector.py</code> <pre><code>@validate_call\ndef api_create_connectors_from_endpoints(\n    ep_ids: conlist(str, min_length=1)\n) -&gt; list[Connector]:\n    \"\"\"\n    Creates connectors for multiple endpoints based on their IDs.\n\n    This function takes a list of endpoint IDs, retrieves the corresponding endpoint arguments for each ID,\n    and then creates a connector for each set of arguments. It utilizes the ConnectorEndpoint's read method\n    to fetch the endpoint arguments and then calls the Connector's create method to initialize the connectors.\n\n    Args:\n        ep_ids (conlist(str, min_length=1)): A list of endpoint IDs for which to create connectors.\n\n    Returns:\n        list[Connector]: A list of initialized Connector objects.\n    \"\"\"\n    return [Connector.create(ConnectorEndpoint.read(ep_id)) for ep_id in ep_ids]\n</code></pre>"},{"location":"api_reference/api_connector/#moonshot.src.api.api_connector.api_get_all_connector_type","title":"<code>api_get_all_connector_type()</code>","text":"<p>Retrieves a list of all available connector types.</p> <p>This function calls the ConnectorManager's get_available_connector_types method to retrieve a list of all available connector types. It returns the list of connector types.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of connector types.</p> Source code in <code>moonshot/src/api/api_connector.py</code> <pre><code>def api_get_all_connector_type() -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of all available connector types.\n\n    This function calls the ConnectorManager's get_available_connector_types method to retrieve a list of all available\n    connector types. It returns the list of connector types.\n\n    Returns:\n        list[str]: A list of connector types.\n    \"\"\"\n    return Connector.get_available_items()\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/","title":"Connector Endpoint API","text":""},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_create_endpoint","title":"<code>api_create_endpoint(name, connector_type, uri, token, max_calls_per_second, max_concurrency, params)</code>","text":"<p>Creates a new connector endpoint.</p> <p>This function creates a new connector endpoint with the specified parameters. It initializes a ConnectorEndpointArguments instance and then uses the ConnectorEndpoint class to create the endpoint.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the endpoint.</p> required <code>connector_type</code> <code>str</code> <p>The type of the connector.</p> required <code>uri</code> <code>str</code> <p>The URI for the connector.</p> required <code>token</code> <code>str</code> <p>The token for authentication with the connector.</p> required <code>max_calls_per_second</code> <code>int</code> <p>The maximum number of calls allowed per second.</p> required <code>max_concurrency</code> <code>int</code> <p>The maximum number of concurrent calls allowed.</p> required <code>params</code> <code>dict</code> <p>Additional parameters for the connector.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created connector endpoint.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_create_endpoint(\n    name: str,\n    connector_type: str,\n    uri: str,\n    token: str,\n    max_calls_per_second: int,\n    max_concurrency: int,\n    params: dict,\n) -&gt; str:\n    \"\"\"\n    Creates a new connector endpoint.\n\n    This function creates a new connector endpoint with the specified parameters. It initializes\n    a ConnectorEndpointArguments instance and then uses the ConnectorEndpoint class to create\n    the endpoint.\n\n    Args:\n        name (str): The name of the endpoint.\n        connector_type (str): The type of the connector.\n        uri (str): The URI for the connector.\n        token (str): The token for authentication with the connector.\n        max_calls_per_second (int): The maximum number of calls allowed per second.\n        max_concurrency (int): The maximum number of concurrent calls allowed.\n        params (dict): Additional parameters for the connector.\n\n    Returns:\n        str: The ID of the newly created connector endpoint.\n    \"\"\"\n    # Create a new connector endpoint arguments instance.\n    # We do not need to provide id and created_date.\n    # This is because during creation:\n    #   1. the id is slugify from the name and stored as id.\n    #   2. the created_date is based on the os file created date and time.\n    connector_endpoint_args = ConnectorEndpointArguments(\n        id=\"\",\n        name=name,\n        connector_type=connector_type,\n        uri=uri,\n        token=token,\n        max_calls_per_second=max_calls_per_second,\n        max_concurrency=max_concurrency,\n        params=params,\n        created_date=\"\",\n    )\n    return ConnectorEndpoint.create(connector_endpoint_args)\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_delete_endpoint","title":"<code>api_delete_endpoint(ep_id)</code>","text":"<p>Deletes an endpoint from the connector manager.</p> <p>This function deletes an endpoint from the connector manager using the provided endpoint ID.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the deletion was successful.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the endpoint with the given ID does not exist or the deletion failed.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_delete_endpoint(ep_id: str) -&gt; bool:\n    \"\"\"\n    Deletes an endpoint from the connector manager.\n\n    This function deletes an endpoint from the connector manager using the provided endpoint ID.\n\n    Args:\n        ep_id (str): The ID of the endpoint to delete.\n\n    Returns:\n        bool: True if the deletion was successful.\n\n    Raises:\n        RuntimeError: If the endpoint with the given ID does not exist or the deletion failed.\n    \"\"\"\n    return ConnectorEndpoint.delete(ep_id)\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_get_all_endpoint","title":"<code>api_get_all_endpoint()</code>","text":"<p>Retrieves a list of all available endpoints.</p> <p>This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available endpoints and their details. It then converts each ConnectorEndpointArguments object into a dictionary for easier consumption by the caller.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing an endpoint's details.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>def api_get_all_endpoint() -&gt; list[dict]:\n    \"\"\"\n    Retrieves a list of all available endpoints.\n\n    This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available\n    endpoints and their details. It then converts each ConnectorEndpointArguments object into a dictionary for easier\n    consumption by the caller.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing an endpoint's details.\n    \"\"\"\n    _, endpoints = ConnectorEndpoint.get_available_items()\n    return [endpoint.to_dict() for endpoint in endpoints]\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_get_all_endpoint_name","title":"<code>api_get_all_endpoint_name()</code>","text":"<p>Retrieves a list of all endpoint names.</p> <p>This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available endpoint names. It extracts the names from the tuple returned by get_available_endpoints, which contains a list of endpoint names and a list of ConnectorEndpointArguments objects.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of endpoint names.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>def api_get_all_endpoint_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of all endpoint names.\n\n    This function calls the ConnectorManager's get_available_endpoints method to retrieve a list of all available\n    endpoint names. It extracts the names from the tuple returned by get_available_endpoints, which contains a list\n    of endpoint names and a list of ConnectorEndpointArguments objects.\n\n    Returns:\n        list[str]: A list of endpoint names.\n    \"\"\"\n    endpoints_names, _ = ConnectorEndpoint.get_available_items()\n    return endpoints_names\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_read_endpoint","title":"<code>api_read_endpoint(ep_id)</code>","text":"<p>Reads an endpoint from the connector manager.</p> <p>This function reads an endpoint from the connector manager using the provided endpoint ID.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint to read.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the endpoint information.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_read_endpoint(ep_id: str) -&gt; dict:\n    \"\"\"\n    Reads an endpoint from the connector manager.\n\n    This function reads an endpoint from the connector manager using the provided endpoint ID.\n\n    Args:\n        ep_id (str): The ID of the endpoint to read.\n\n    Returns:\n        dict: A dictionary containing the endpoint information.\n    \"\"\"\n    return ConnectorEndpoint.read(ep_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_connector_endpoint/#moonshot.src.api.api_connector_endpoint.api_update_endpoint","title":"<code>api_update_endpoint(ep_id, **kwargs)</code>","text":"<p>Updates an existing endpoint with new values.</p> <p>This function updates an existing endpoint in the connector manager using the provided endpoint ID and keyword arguments.</p> <p>Each keyword argument corresponds to an attribute of the endpoint that should be updated.</p> <p>Parameters:</p> Name Type Description Default <code>ep_id</code> <code>str</code> <p>The ID of the endpoint to update.</p> required <code>**kwargs</code> <p>Arbitrary keyword arguments representing the attributes to update.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the update was successful.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the endpoint with the given ID does not exist or the update failed.</p> Source code in <code>moonshot/src/api/api_connector_endpoint.py</code> <pre><code>@validate_call\ndef api_update_endpoint(ep_id: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Updates an existing endpoint with new values.\n\n    This function updates an existing endpoint in the connector manager using the provided endpoint ID and\n    keyword arguments.\n\n    Each keyword argument corresponds to an attribute of the endpoint that should be updated.\n\n    Args:\n        ep_id (str): The ID of the endpoint to update.\n        **kwargs: Arbitrary keyword arguments representing the attributes to update.\n\n    Returns:\n        bool: True if the update was successful.\n\n    Raises:\n        RuntimeError: If the endpoint with the given ID does not exist or the update failed.\n    \"\"\"\n    # Check if the endpoint exists\n    try:\n        existing_endpoint = ConnectorEndpoint.read(ep_id)\n    except Exception:\n        raise RuntimeError(\n            f\"[api_update_endpoint]: Endpoint with ID '{ep_id}' does not exist\"\n        )\n\n    # Update the fields of the existing endpoint with the provided kwargs\n    for key, value in kwargs.items():\n        if hasattr(existing_endpoint, key):\n            setattr(existing_endpoint, key, value)\n\n    # Perform pydantic check on the updated existing endpoint\n    ConnectorEndpointArguments.model_validate(existing_endpoint.to_dict())\n\n    # Update the endpoint\n    return ConnectorEndpoint.update(existing_endpoint)\n</code></pre>"},{"location":"api_reference/api_context_strategy/","title":"Context Strategy API","text":""},{"location":"api_reference/api_context_strategy/#moonshot.src.api.api_context_strategy.api_delete_context_strategy","title":"<code>api_delete_context_strategy(cs_id)</code>","text":"<p>Deletes a context strategy identified by its ID.</p> <p>This API endpoint interfaces with the <code>ContextStrategy.delete</code> method to remove a context strategy from the system. It is used to manage the available context strategies by allowing for their removal when they are no longer needed.</p> <p>Parameters:</p> Name Type Description Default <code>cs_id</code> <code>str</code> <p>The unique identifier of the context strategy to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the context strategy was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_context_strategy.py</code> <pre><code>@validate_call\ndef api_delete_context_strategy(cs_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a context strategy identified by its ID.\n\n    This API endpoint interfaces with the `ContextStrategy.delete` method to remove a context strategy from the system.\n    It is used to manage the available context strategies by allowing for their removal when they are no longer needed.\n\n    Args:\n        cs_id (str): The unique identifier of the context strategy to be deleted.\n\n    Returns:\n        bool: True if the context strategy was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return ContextStrategy.delete(cs_id)\n</code></pre>"},{"location":"api_reference/api_context_strategy/#moonshot.src.api.api_context_strategy.api_get_all_context_strategies","title":"<code>api_get_all_context_strategies()</code>","text":"<p>Retrieves and returns the names of all context strategies currently available.</p> <p>This API endpoint interfaces with the <code>ContextStrategy.get_all_context_strategy_names</code> method to fetch a list of all context strategy names. It's designed for clients that need to know what context strategies are available for use in sessions or other components of the system.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing the name of a context strategy.</p> Source code in <code>moonshot/src/api/api_context_strategy.py</code> <pre><code>def api_get_all_context_strategies() -&gt; list[str]:\n    \"\"\"\n    Retrieves and returns the names of all context strategies currently available.\n\n    This API endpoint interfaces with the `ContextStrategy.get_all_context_strategy_names` method to fetch a list\n    of all context strategy names. It's designed for clients that need to know what context strategies are available for\n    use in sessions or other components of the system.\n\n    Returns:\n        list[str]: A list of strings, each representing the name of a context strategy.\n    \"\"\"\n    return ContextStrategy.get_all_context_strategies()\n</code></pre>"},{"location":"api_reference/api_context_strategy/#moonshot.src.api.api_context_strategy.api_get_all_context_strategy_metadata","title":"<code>api_get_all_context_strategy_metadata()</code>","text":"<p>Retrieves metadata for all context strategy modules.</p> <p>This function retrieves the metadata for all available context strategies and returns a list of metadata dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing the details of a context strategy metadata.</p> Source code in <code>moonshot/src/api/api_context_strategy.py</code> <pre><code>def api_get_all_context_strategy_metadata() -&gt; list[dict]:\n    \"\"\"\n    Retrieves metadata for all context strategy modules.\n\n    This function retrieves the metadata for all available context strategies and\n    returns a list of metadata dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing the details of a context strategy metadata.\n    \"\"\"\n\n    return [\n        ContextStrategy.load(context_strategy_name).get_metadata()  # type: ignore ; ducktyping\n        for context_strategy_name in ContextStrategy.get_all_context_strategies()\n    ]\n</code></pre>"},{"location":"api_reference/api_cookbook/","title":"Cookbook API","text":""},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_create_cookbook","title":"<code>api_create_cookbook(name, description, recipes)</code>","text":"<p>Creates a new cookbook.</p> <p>This function takes the name, description, and recipes for a new cookbook as input. It then creates a new CookbookArguments object with these details and an empty id. The id is left empty because it will be generated from the name during the creation process. The function then calls the Cookbook's create_cookbook method to create the new cookbook.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new cookbook.</p> required <code>description</code> <code>str</code> <p>A brief description of the new cookbook.</p> required <code>recipes</code> <code>list[str]</code> <p>A list of recipes to be included in the new cookbook.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created cookbook.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_create_cookbook(name: str, description: str, recipes: list[str]) -&gt; str:\n    \"\"\"\n    Creates a new cookbook.\n\n    This function takes the name, description, and recipes for a new cookbook as input. It then creates a new\n    CookbookArguments object with these details and an empty id. The id is left empty because it will be generated\n    from the name during the creation process. The function then calls the Cookbook's create_cookbook method to\n    create the new cookbook.\n\n    Args:\n        name (str): The name of the new cookbook.\n        description (str): A brief description of the new cookbook.\n        recipes (list[str]): A list of recipes to be included in the new cookbook.\n\n    Returns:\n        str: The ID of the newly created cookbook.\n    \"\"\"\n    # Create a new cookbook\n    # We do not need to provide the id.\n    # This is because during creation:\n    # 1. the id is slugify from the name and stored as id.\n    cb_args = CookbookArguments(\n        id=\"\",\n        name=name,\n        description=description,\n        recipes=recipes,\n    )\n    return Cookbook.create(cb_args)\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_delete_cookbook","title":"<code>api_delete_cookbook(cb_id)</code>","text":"<p>Deletes a cookbook based on the provided cookbook ID.</p> <p>This function calls the <code>delete</code> method of the <code>Cookbook</code> class with the given cookbook ID. If the cookbook is successfully deleted, the method returns True, otherwise it returns False.</p> <p>Parameters:</p> Name Type Description Default <code>cb_id</code> <code>str</code> <p>The ID of the cookbook to delete.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the cookbook was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_delete_cookbook(cb_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a cookbook based on the provided cookbook ID.\n\n    This function calls the `delete` method of the `Cookbook` class with the given cookbook ID. If the cookbook\n    is successfully deleted, the method returns True, otherwise it returns False.\n\n    Args:\n        cb_id (str): The ID of the cookbook to delete.\n\n    Returns:\n        bool: True if the cookbook was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Cookbook.delete(cb_id)\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_get_all_cookbook","title":"<code>api_get_all_cookbook()</code>","text":"<p>Retrieves all available cookbooks.</p> <p>This function calls the <code>get_available_cookbooks</code> method of the <code>Cookbook</code> class, which returns a tuple containing a list of cookbook IDs and a list of <code>CookbookArguments</code> objects. The function then returns a list of dictionaries, each representing a cookbook.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a cookbook.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>def api_get_all_cookbook() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available cookbooks.\n\n    This function calls the `get_available_cookbooks` method of the `Cookbook` class, which returns a tuple\n    containing a list of cookbook IDs and a list of `CookbookArguments` objects. The function then returns a list\n    of dictionaries, each representing a cookbook.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a cookbook.\n    \"\"\"\n    _, cookbooks = Cookbook.get_available_items()\n    return [cookbook.to_dict() for cookbook in cookbooks]\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_get_all_cookbook_name","title":"<code>api_get_all_cookbook_name()</code>","text":"<p>Retrieves the names of all available cookbooks.</p> <p>This function calls the <code>get_available_cookbooks</code> method of the <code>Cookbook</code> class, which returns a tuple containing a list of cookbook IDs and a list of <code>CookbookArguments</code> objects. The function then returns the list of cookbook IDs, which are the names of the cookbooks.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of cookbook names.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>def api_get_all_cookbook_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves the names of all available cookbooks.\n\n    This function calls the `get_available_cookbooks` method of the `Cookbook` class, which returns a tuple\n    containing a list of cookbook IDs and a list of `CookbookArguments` objects. The function then returns the\n    list of cookbook IDs, which are the names of the cookbooks.\n\n    Returns:\n        list[str]: A list of cookbook names.\n    \"\"\"\n    cookbooks_names, _ = Cookbook.get_available_items()\n    return cookbooks_names\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_read_cookbook","title":"<code>api_read_cookbook(cb_id)</code>","text":"<p>Retrieves a cookbook based on the provided cookbook ID.</p> <p>This function reads a cookbook using the <code>read_cookbook</code> method of the <code>Cookbook</code> class, and converts the returned <code>Cookbook</code> object to a dictionary using its <code>to_dict</code> method.</p> <p>Parameters:</p> Name Type Description Default <code>cb_id</code> <code>str</code> <p>A cookbook ID.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary representing a cookbook.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_read_cookbook(cb_id: str) -&gt; dict:\n    \"\"\"\n    Retrieves a cookbook based on the provided cookbook ID.\n\n    This function reads a cookbook using the `read_cookbook` method\n    of the `Cookbook` class, and converts the returned `Cookbook` object to a dictionary using its `to_dict` method.\n\n    Args:\n        cb_id (str): A cookbook ID.\n\n    Returns:\n        dict: A dictionary representing a cookbook.\n    \"\"\"\n    return Cookbook.read(cb_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_read_cookbooks","title":"<code>api_read_cookbooks(cb_ids)</code>","text":"<p>Retrieves a list of cookbooks based on the provided list of cookbook IDs.</p> <p>This function iterates over the list of provided cookbook IDs, reads each cookbook using the <code>read_cookbook</code> method of the <code>Cookbook</code> class, and converts the returned <code>Cookbook</code> objects to dictionaries using their <code>to_dict</code> method. It then returns a list of these dictionary representations.</p> <p>Parameters:</p> Name Type Description Default <code>cb_ids</code> <code>conlist(str, min_length=1</code> <p>A list of cookbook IDs.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries representing the cookbooks.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_read_cookbooks(cb_ids: conlist(str, min_length=1)) -&gt; list[dict]:\n    \"\"\"\n    Retrieves a list of cookbooks based on the provided list of cookbook IDs.\n\n    This function iterates over the list of provided cookbook IDs, reads each cookbook using the `read_cookbook` method\n    of the `Cookbook` class, and converts the returned `Cookbook` objects to dictionaries using their `to_dict` method.\n    It then returns a list of these dictionary representations.\n\n    Args:\n        cb_ids (conlist(str, min_length=1)): A list of cookbook IDs.\n\n    Returns:\n        list[dict]: A list of dictionaries representing the cookbooks.\n    \"\"\"\n    return [Cookbook.read(cb_id).to_dict() for cb_id in cb_ids]\n</code></pre>"},{"location":"api_reference/api_cookbook/#moonshot.src.api.api_cookbook.api_update_cookbook","title":"<code>api_update_cookbook(cb_id, **kwargs)</code>","text":"<p>Updates the fields of an existing cookbook with the provided keyword arguments.</p> <p>This function first checks if the cookbook with the given ID exists. If it does, it updates the fields of the cookbook with the provided keyword arguments. If a field does not exist on the cookbook, it is ignored. After updating the fields, it persists the changes to the cookbook.</p> <p>Parameters:</p> Name Type Description Default <code>cb_id</code> <code>str</code> <p>The ID of the cookbook to update.</p> required <code>**kwargs</code> <p>Arbitrary keyword arguments representing the fields to update and their new values.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the cookbook was successfully updated.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If there's an error during the update process.</p> Source code in <code>moonshot/src/api/api_cookbook.py</code> <pre><code>@validate_call\ndef api_update_cookbook(cb_id: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Updates the fields of an existing cookbook with the provided keyword arguments.\n\n    This function first checks if the cookbook with the given ID exists. If it does, it updates the fields\n    of the cookbook with the provided keyword arguments. If a field does not exist on the cookbook, it is ignored.\n    After updating the fields, it persists the changes to the cookbook.\n\n    Args:\n        cb_id (str): The ID of the cookbook to update.\n        **kwargs: Arbitrary keyword arguments representing the fields to update and their new values.\n\n    Returns:\n        bool: True if the cookbook was successfully updated.\n\n    Raises:\n        Exception: If there's an error during the update process.\n    \"\"\"\n    # Check if the cookbook exists\n    try:\n        existing_cookbook = Cookbook.read(cb_id)\n    except Exception:\n        raise RuntimeError(f\"Cookbook with ID '{cb_id}' does not exist\")\n\n    # Update the fields of the existing cookbook with the provided kwargs\n    for key, value in kwargs.items():\n        if hasattr(existing_cookbook, key):\n            setattr(existing_cookbook, key, value)\n\n    # Perform pydantic check on the updated existing cookbook\n    CookbookArguments.model_validate(existing_cookbook.to_dict())\n\n    # Update the cookbook\n    return Cookbook.update(existing_cookbook)\n</code></pre>"},{"location":"api_reference/api_dataset/","title":"Dataset API","text":""},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_create_datasets","title":"<code>api_create_datasets(name, description, reference, license, method, **kwargs)</code>","text":"<p>This function creates a new dataset.</p> <p>This function takes the name, description, reference, and license for a new dataset as input. It then creates a new DatasetArguments object with these details and an empty id. The id is left empty because it will be generated from the name during the creation process. The function then calls the Dataset's create method to create the new dataset.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the new dataset.</p> required <code>description</code> <code>str</code> <p>A brief description of the new dataset.</p> required <code>reference</code> <code>str</code> <p>A reference link for the new dataset.</p> required <code>license</code> <code>str</code> <p>The license of the new dataset.</p> required <code>method</code> <code>str</code> <p>The method to create new dataset. (csv/hf)</p> required <code>kwargs</code> <p>Additional keyword arguments for the Dataset's create method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created dataset.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>def api_create_datasets(\n    name: str, description: str, reference: str, license: str, method: str, **kwargs\n) -&gt; str:\n    \"\"\"\n    This function creates a new dataset.\n\n    This function takes the name, description, reference, and license for a new dataset as input. It then creates a new\n    DatasetArguments object with these details and an empty id. The id is left empty because it will be generated\n    from the name during the creation process. The function then calls the Dataset's create method to\n    create the new dataset.\n\n    Args:\n        name (str): The name of the new dataset.\n        description (str): A brief description of the new dataset.\n        reference (str): A reference link for the new dataset.\n        license (str): The license of the new dataset.\n        method (str): The method to create new dataset. (csv/hf)\n        kwargs: Additional keyword arguments for the Dataset's create method.\n\n    Returns:\n        str: The ID of the newly created dataset.\n    \"\"\"\n    ds_args = DatasetArguments(\n        id=\"\",\n        name=name,\n        description=description,\n        reference=reference,\n        license=license,\n        examples=None,\n    )\n\n    return Dataset.create(ds_args, method, **kwargs)\n</code></pre>"},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_delete_dataset","title":"<code>api_delete_dataset(ds_id)</code>","text":"<p>Deletes a dataset identified by its unique dataset ID.</p> <p>Parameters:</p> Name Type Description Default <code>ds_id</code> <code>str</code> <p>The unique identifier for the dataset to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the dataset was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>@validate_call\ndef api_delete_dataset(ds_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a dataset identified by its unique dataset ID.\n\n    Args:\n        ds_id (str): The unique identifier for the dataset to be deleted.\n\n    Returns:\n        bool: True if the dataset was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Dataset.delete(ds_id)\n</code></pre>"},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_get_all_datasets","title":"<code>api_get_all_datasets()</code>","text":"<p>This function retrieves all available datasets and returns them as a list of dictionaries. Each dictionary represents a result and contains its information.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a result.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>def api_get_all_datasets() -&gt; list[dict]:\n    \"\"\"\n    This function retrieves all available datasets and returns them as a list of dictionaries. Each dictionary\n    represents a result and contains its information.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a result.\n    \"\"\"\n    _, datasets = Dataset.get_available_items()\n    return [dataset.to_dict() for dataset in datasets]\n</code></pre>"},{"location":"api_reference/api_dataset/#moonshot.src.api.api_dataset.api_get_all_datasets_name","title":"<code>api_get_all_datasets_name()</code>","text":"<p>This function retrieves all available datasets names and returns them as a list.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of datasets names.</p> Source code in <code>moonshot/src/api/api_dataset.py</code> <pre><code>def api_get_all_datasets_name() -&gt; list[str]:\n    \"\"\"\n    This function retrieves all available datasets names and returns them as a list.\n\n    Returns:\n        list[str]: A list of datasets names.\n    \"\"\"\n    datasets_name, _ = Dataset.get_available_items()\n    return datasets_name\n</code></pre>"},{"location":"api_reference/api_environment_variables/","title":"Environment Variable API","text":""},{"location":"api_reference/api_environment_variables/#moonshot.src.api.api_environment_variables.api_set_environment_variables","title":"<code>api_set_environment_variables(env_vars)</code>","text":"<p>Sets the environment variables for the current session.</p> <p>Parameters:</p> Name Type Description Default <code>env_vars</code> <code>dict</code> <p>A dictionary containing the environment variables to set.</p> required <p>Returns:</p> Type Description <code>None</code> <p>None</p> Source code in <code>moonshot/src/api/api_environment_variables.py</code> <pre><code>def api_set_environment_variables(env_vars: dict) -&gt; None:\n    \"\"\"\n    Sets the environment variables for the current session.\n\n    Args:\n        env_vars (dict): A dictionary containing the environment variables to set.\n\n    Returns:\n        None\n    \"\"\"\n    EnvironmentVars.load_env(env_vars)\n</code></pre>"},{"location":"api_reference/api_metrics/","title":"Metric API","text":""},{"location":"api_reference/api_metrics/#moonshot.src.api.api_metrics.api_delete_metric","title":"<code>api_delete_metric(met_id)</code>","text":"<p>Deletes a metric identified by its unique metric ID.</p> <p>Parameters:</p> Name Type Description Default <code>met_id</code> <code>str</code> <p>The unique identifier for the metric to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the metric was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_metrics.py</code> <pre><code>@validate_call\ndef api_delete_metric(met_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a metric identified by its unique metric ID.\n\n    Args:\n        met_id (str): The unique identifier for the metric to be deleted.\n\n    Returns:\n        bool: True if the metric was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Metric.delete(met_id)\n</code></pre>"},{"location":"api_reference/api_metrics/#moonshot.src.api.api_metrics.api_get_all_metric","title":"<code>api_get_all_metric()</code>","text":"<p>Retrieves all available metrics.</p> <p>This function calls the get_available_items method from the Metric class to retrieve all available metrics. It then returns a list of dictionaries, each containing the details of a metric.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a metric's details.</p> Source code in <code>moonshot/src/api/api_metrics.py</code> <pre><code>def api_get_all_metric() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available metrics.\n\n    This function calls the get_available_items method from the Metric class to retrieve all available metrics.\n    It then returns a list of dictionaries, each containing the details of a metric.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a metric's details.\n    \"\"\"\n    _, metrics_info = Metric.get_available_items()\n    return metrics_info\n</code></pre>"},{"location":"api_reference/api_metrics/#moonshot.src.api.api_metrics.api_get_all_metric_name","title":"<code>api_get_all_metric_name()</code>","text":"<p>Retrieves all available metric names.</p> <p>This function calls the get_available_items method from the Metric class to retrieve all available metrics. It then extracts the names of each metric and returns a list of these names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing a metric name.</p> Source code in <code>moonshot/src/api/api_metrics.py</code> <pre><code>def api_get_all_metric_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available metric names.\n\n    This function calls the get_available_items method from the Metric class to retrieve all available metrics.\n    It then extracts the names of each metric and returns a list of these names.\n\n    Returns:\n        list[str]: A list of strings, each representing a metric name.\n    \"\"\"\n    metrics_names, _ = Metric.get_available_items()\n    return metrics_names\n</code></pre>"},{"location":"api_reference/api_prompt_template/","title":"Prompt Template API","text":""},{"location":"api_reference/api_prompt_template/#moonshot.src.api.api_prompt_template.api_delete_prompt_template","title":"<code>api_delete_prompt_template(pt_id)</code>","text":"<p>Deletes a prompt template by its identifier.</p> <p>Parameters:</p> Name Type Description Default <code>pt_id</code> <code>str</code> <p>The unique identifier of the prompt template to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the prompt template was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_prompt_template.py</code> <pre><code>@validate_call\ndef api_delete_prompt_template(pt_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a prompt template by its identifier.\n\n    Args:\n        pt_id (str): The unique identifier of the prompt template to be deleted.\n\n    Returns:\n        bool: True if the prompt template was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return PromptTemplate.delete(pt_id)\n</code></pre>"},{"location":"api_reference/api_prompt_template/#moonshot.src.api.api_prompt_template.api_get_all_prompt_template_detail","title":"<code>api_get_all_prompt_template_detail()</code>","text":"<p>Retrieves all available prompt template details and returns them as a list of dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing the details of a prompt template.</p> Source code in <code>moonshot/src/api/api_prompt_template.py</code> <pre><code>def api_get_all_prompt_template_detail() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available prompt template details and returns them as a list of dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing the details of a prompt template.\n    \"\"\"\n    return PromptTemplate.get_all_prompt_template_details()\n</code></pre>"},{"location":"api_reference/api_prompt_template/#moonshot.src.api.api_prompt_template.api_get_all_prompt_template_name","title":"<code>api_get_all_prompt_template_name()</code>","text":"<p>Retrieves all available prompt template names and returns them as a list.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of prompt template names.</p> Source code in <code>moonshot/src/api/api_prompt_template.py</code> <pre><code>def api_get_all_prompt_template_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available prompt template names and returns them as a list.\n\n    Returns:\n        list[str]: A list of prompt template names.\n    \"\"\"\n    return PromptTemplate.get_all_prompt_template_names()\n</code></pre>"},{"location":"api_reference/api_recipe/","title":"Recipe API","text":""},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_create_recipe","title":"<code>api_create_recipe(name, description, tags, categories, datasets, prompt_templates, metrics, grading_scale)</code>","text":"<p>Creates a new recipe with the given parameters.</p> <p>This function takes various parameters that define a recipe, creates a RecipeArguments object with these parameters, and then calls the Recipe.create method to create a new recipe in the system.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the recipe.</p> required <code>description</code> <code>str</code> <p>A description of the recipe.</p> required <code>tags</code> <code>list[str]</code> <p>A list of tags associated with the recipe.</p> required <code>categories</code> <code>list[str]</code> <p>A list of categories the recipe belongs to.</p> required <code>datasets</code> <code>list[str]</code> <p>A list of datasets used in the recipe.</p> required <code>prompt_templates</code> <code>list[str]</code> <p>A list of prompt templates for the recipe.</p> required <code>metrics</code> <code>list[str]</code> <p>A list of metrics to evaluate the recipe.</p> required <code>grading_scale</code> <code>dict[str, list[int]]</code> <p>A grading scale dictionary where the key is the grade and the</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The ID of the newly created recipe.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_create_recipe(\n    name: str,\n    description: str,\n    tags: list[str],\n    categories: list[str],\n    datasets: list[str],\n    prompt_templates: list[str],\n    metrics: list[str],\n    grading_scale: dict[str, list[int]],\n) -&gt; str:\n    \"\"\"\n    Creates a new recipe with the given parameters.\n\n    This function takes various parameters that define a recipe, creates a RecipeArguments\n    object with these parameters, and then calls the Recipe.create method to create a new\n    recipe in the system.\n\n    Args:\n        name (str): The name of the recipe.\n        description (str): A description of the recipe.\n        tags (list[str]): A list of tags associated with the recipe.\n        categories (list[str]): A list of categories the recipe belongs to.\n        datasets (list[str]): A list of datasets used in the recipe.\n        prompt_templates (list[str]): A list of prompt templates for the recipe.\n        metrics (list[str]): A list of metrics to evaluate the recipe.\n        grading_scale (dict[str, list[int]]): A grading scale dictionary where the key is the grade and the\n        value is a list of integers representing the scale.\n\n    Returns:\n        str: The ID of the newly created recipe.\n    \"\"\"\n    rec_args = RecipeArguments(\n        id=\"\",\n        name=name,\n        description=description,\n        tags=tags,\n        categories=categories,\n        datasets=datasets,\n        prompt_templates=prompt_templates,\n        metrics=metrics,\n        grading_scale=grading_scale,\n    )\n    return Recipe.create(rec_args)\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_delete_recipe","title":"<code>api_delete_recipe(rec_id)</code>","text":"<p>Deletes a recipe identified by its unique recipe ID.</p> <p>This function takes a recipe ID, verifies the existence of the recipe, and if found, calls the delete method from the Recipe class to remove the recipe from storage.</p> <p>If the deletion is successful, it returns True. If the recipe does not exist or an exception occurs during deletion, a RuntimeError is raised with an appropriate error message.</p> <p>Parameters:</p> Name Type Description Default <code>rec_id</code> <code>str</code> <p>The unique identifier for the recipe to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the recipe was successfully deleted.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_delete_recipe(rec_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a recipe identified by its unique recipe ID.\n\n    This function takes a recipe ID, verifies the existence of the recipe, and if found, calls the delete method from\n    the Recipe class to remove the recipe from storage.\n\n    If the deletion is successful, it returns True.\n    If the recipe does not exist or an exception occurs during deletion, a RuntimeError is raised with an\n    appropriate error message.\n\n    Args:\n        rec_id (str): The unique identifier for the recipe to be deleted.\n\n    Returns:\n        bool: True if the recipe was successfully deleted.\n\n    Raises:\n        RuntimeError: If the deletion process encounters an error.\n    \"\"\"\n    return Recipe.delete(rec_id)\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_get_all_recipe","title":"<code>api_get_all_recipe()</code>","text":"<p>Retrieves all available recipes.</p> <p>This function calls the get_available_recipes method to retrieve all available recipes. It then converts each recipe into a dictionary using the to_dict method and returns a list of these dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a recipe.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>def api_get_all_recipe() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available recipes.\n\n    This function calls the get_available_recipes method to retrieve all available recipes. It then converts each\n    recipe into a dictionary using the to_dict method and returns a list of these dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a recipe.\n    \"\"\"\n    _, recipes = Recipe.get_available_items()\n    return [recipe.to_dict() for recipe in recipes]\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_get_all_recipe_name","title":"<code>api_get_all_recipe_name()</code>","text":"<p>Retrieves all available recipe names.</p> <p>This function calls the get_available_recipes method to retrieve all available recipes. It then extracts the names of each recipe and returns a list of these names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing a recipe name.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>def api_get_all_recipe_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available recipe names.\n\n    This function calls the get_available_recipes method to retrieve all available recipes. It then extracts the names\n    of each recipe and returns a list of these names.\n\n    Returns:\n        list[str]: A list of strings, each representing a recipe name.\n    \"\"\"\n    recipes_names, _ = Recipe.get_available_items()\n    return recipes_names\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_read_recipe","title":"<code>api_read_recipe(rec_id)</code>","text":"<p>Reads a recipe and returns its information.</p> <p>This function takes a recipe ID as input, reads the corresponding recipe, and returns a dictionary containing the recipe's information.</p> <p>Parameters:</p> Name Type Description Default <code>rec_id</code> <code>str</code> <p>The ID of the recipe.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the recipe's information.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_read_recipe(rec_id: str) -&gt; dict:\n    \"\"\"\n    Reads a recipe and returns its information.\n\n    This function takes a recipe ID as input, reads the corresponding recipe,\n    and returns a dictionary containing the recipe's information.\n\n    Args:\n        rec_id (str): The ID of the recipe.\n\n    Returns:\n        dict: A dictionary containing the recipe's information.\n    \"\"\"\n    return Recipe.read(rec_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_read_recipes","title":"<code>api_read_recipes(rec_ids)</code>","text":"<p>Reads multiple recipes and returns their information.</p> <p>This function takes a list of recipe IDs as input, reads the corresponding recipes, and returns a list of dictionaries containing each recipe's information.</p> <p>Parameters:</p> Name Type Description Default <code>rec_ids</code> <code>list[str]</code> <p>The IDs of the recipes.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each containing a recipe's information.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_read_recipes(rec_ids: conlist(str, min_length=1)) -&gt; list[dict]:\n    \"\"\"\n    Reads multiple recipes and returns their information.\n\n    This function takes a list of recipe IDs as input, reads the corresponding recipes,\n    and returns a list of dictionaries containing each recipe's information.\n\n    Args:\n        rec_ids (list[str]): The IDs of the recipes.\n\n    Returns:\n        list[dict]: A list of dictionaries, each containing a recipe's information.\n    \"\"\"\n    # This function uses list comprehension to iterate over the list of recipe IDs,\n    # calling the read_recipe method for each ID and converting the result to a dictionary.\n    # The resulting list of dictionaries is then returned.\n    return [Recipe.read(rec_id).to_dict() for rec_id in rec_ids]\n</code></pre>"},{"location":"api_reference/api_recipe/#moonshot.src.api.api_recipe.api_update_recipe","title":"<code>api_update_recipe(rec_id, **kwargs)</code>","text":"<p>Updates a recipe with the given keyword arguments.</p> <p>This function takes a recipe ID and arbitrary keyword arguments, checks if the recipe exists, and updates the fields of the recipe with the provided values. If the recipe does not exist, a RuntimeError is raised. If the update is successful, it returns True.</p> <p>Parameters:</p> Name Type Description Default <code>rec_id</code> <code>str</code> <p>The ID of the recipe to update.</p> required <code>**kwargs</code> <p>Arbitrary keyword arguments representing the fields to update.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the recipe was successfully updated.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the recipe with the given ID does not exist.</p> Source code in <code>moonshot/src/api/api_recipe.py</code> <pre><code>@validate_call\ndef api_update_recipe(rec_id: str, **kwargs) -&gt; bool:\n    \"\"\"\n    Updates a recipe with the given keyword arguments.\n\n    This function takes a recipe ID and arbitrary keyword arguments, checks if the recipe exists,\n    and updates the fields of the recipe with the provided values. If the recipe does not exist,\n    a RuntimeError is raised. If the update is successful, it returns True.\n\n    Args:\n        rec_id (str): The ID of the recipe to update.\n        **kwargs: Arbitrary keyword arguments representing the fields to update.\n\n    Returns:\n        bool: True if the recipe was successfully updated.\n\n    Raises:\n        RuntimeError: If the recipe with the given ID does not exist.\n    \"\"\"\n    # Check if the recipe exists\n    try:\n        existing_recipe = Recipe.read(rec_id)\n    except Exception:\n        raise RuntimeError(f\"Recipe with ID '{rec_id}' does not exist\")\n\n    # Update the fields of the existing recipe with the provided kwargs\n    for key, value in kwargs.items():\n        if hasattr(existing_recipe, key):\n            setattr(existing_recipe, key, value)\n\n    # Perform pydantic check on the updated existing recipe\n    RecipeArguments.model_validate(existing_recipe.to_dict())\n\n    # Update the recipe\n    return Recipe.update(existing_recipe)\n</code></pre>"},{"location":"api_reference/api_red_teaming/","title":"Red Teaming API","text":""},{"location":"api_reference/api_red_teaming/#moonshot.src.api.api_red_teaming.api_delete_attack_module","title":"<code>api_delete_attack_module(am_id)</code>","text":"<p>Deletes an attack module by its identifier.</p> <p>This function takes an attack module ID as input and calls the delete method from the AttackModule class to remove the specified attack module from storage.</p> <p>Parameters:</p> Name Type Description Default <code>am_id</code> <code>str</code> <p>The unique identifier of the attack module to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the attack module was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_red_teaming.py</code> <pre><code>@validate_call\ndef api_delete_attack_module(am_id: str) -&gt; bool:\n    \"\"\"\n    Deletes an attack module by its identifier.\n\n    This function takes an attack module ID as input and calls the delete method from the AttackModule class\n    to remove the specified attack module from storage.\n\n    Args:\n        am_id (str): The unique identifier of the attack module to be deleted.\n\n    Returns:\n        bool: True if the attack module was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return AttackModule.delete(am_id)\n</code></pre>"},{"location":"api_reference/api_red_teaming/#moonshot.src.api.api_red_teaming.api_get_all_attack_module_metadata","title":"<code>api_get_all_attack_module_metadata()</code>","text":"<p>Retrieves metadata for all available attack modules.</p> <p>This function calls the <code>get_available_items</code> method from the <code>AttackModule</code> class to retrieve all available attack modules metadata.</p> <p>It then extracts the metadata for each attack module and returns a list of dictionaries, each containing the metadata of an attack module.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing the metadata of an attack module.</p> Source code in <code>moonshot/src/api/api_red_teaming.py</code> <pre><code>def api_get_all_attack_module_metadata() -&gt; list[dict]:\n    \"\"\"\n    Retrieves metadata for all available attack modules.\n\n    This function calls the `get_available_items` method from the `AttackModule` class to retrieve all available\n    attack modules metadata.\n\n    It then extracts the metadata for each attack module and returns a list of dictionaries, each containing the\n    metadata of an attack module.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing the metadata of an attack module.\n    \"\"\"\n    _, attack_modules_metadata = AttackModule.get_available_items()\n    return attack_modules_metadata\n</code></pre>"},{"location":"api_reference/api_red_teaming/#moonshot.src.api.api_red_teaming.api_get_all_attack_modules","title":"<code>api_get_all_attack_modules()</code>","text":"<p>Retrieves all available attack module IDs.</p> <p>This function calls the <code>get_available_items</code> method from the <code>AttackModule</code> class to retrieve all available attack modules.</p> <p>It then extracts the IDs of each attack module and returns a list of these IDs.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each representing an attack module ID.</p> Source code in <code>moonshot/src/api/api_red_teaming.py</code> <pre><code>def api_get_all_attack_modules() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available attack module IDs.\n\n    This function calls the `get_available_items` method from the `AttackModule` class to retrieve all available\n    attack modules.\n\n    It then extracts the IDs of each attack module and returns a list of these IDs.\n\n    Returns:\n        list[str]: A list of strings, each representing an attack module ID.\n    \"\"\"\n    attack_modules_ids, _ = AttackModule.get_available_items()\n    return attack_modules_ids\n</code></pre>"},{"location":"api_reference/api_result/","title":"Result API","text":""},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_delete_result","title":"<code>api_delete_result(res_id)</code>","text":"<p>Deletes a result by its identifier.</p> <p>This function takes a result ID as input and calls the delete method from the Result class to remove the specified result from storage.</p> <p>Parameters:</p> Name Type Description Default <code>res_id</code> <code>str</code> <p>The unique identifier of the result to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the result was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>@validate_call\ndef api_delete_result(res_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a result by its identifier.\n\n    This function takes a result ID as input and calls the delete method from the Result class\n    to remove the specified result from storage.\n\n    Args:\n        res_id (str): The unique identifier of the result to be deleted.\n\n    Returns:\n        bool: True if the result was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Result.delete(res_id)\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_get_all_result","title":"<code>api_get_all_result()</code>","text":"<p>This function retrieves all available results and returns them as a list of dictionaries. Each dictionary represents a result and contains its information.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a result.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>def api_get_all_result() -&gt; list[dict]:\n    \"\"\"\n    This function retrieves all available results and returns them as a list of dictionaries. Each dictionary\n    represents a result and contains its information.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a result.\n    \"\"\"\n    _, results = Result.get_available_items()\n    return [result for result in results]\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_get_all_result_name","title":"<code>api_get_all_result_name()</code>","text":"<p>This function retrieves all available result names and returns them as a list.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of result names.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>def api_get_all_result_name() -&gt; list[str]:\n    \"\"\"\n    This function retrieves all available result names and returns them as a list.\n\n    Returns:\n        list[str]: A list of result names.\n    \"\"\"\n    results_name, _ = Result.get_available_items()\n    return results_name\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_read_result","title":"<code>api_read_result(res_id)</code>","text":"<p>Reads a result and returns its information.</p> <p>This function takes a result ID as input, reads the corresponding database file from the storage manager, and returns a dictionary containing the result's information.</p> <p>Parameters:</p> Name Type Description Default <code>res_id</code> <code>str</code> <p>The ID of the result.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the result's information.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>@validate_call\ndef api_read_result(res_id: str) -&gt; dict:\n    \"\"\"\n    Reads a result and returns its information.\n\n    This function takes a result ID as input, reads the corresponding database file from the storage manager,\n    and returns a dictionary containing the result's information.\n\n    Args:\n        res_id (str): The ID of the result.\n\n    Returns:\n        dict: A dictionary containing the result's information.\n    \"\"\"\n    return Result.read(res_id)\n</code></pre>"},{"location":"api_reference/api_result/#moonshot.src.api.api_result.api_read_results","title":"<code>api_read_results(res_ids)</code>","text":"<p>Reads multiple results and returns their information.</p> <p>This function takes a list of result IDs as input, reads the corresponding database files from the storage manager, and returns a list of dictionaries, each containing a result's information.</p> <p>Parameters:</p> Name Type Description Default <code>res_ids</code> <code>conlist(str, min_length=1</code> <p>A list of result IDs.</p> required <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each containing a result's information.</p> Source code in <code>moonshot/src/api/api_result.py</code> <pre><code>@validate_call\ndef api_read_results(res_ids: conlist(str, min_length=1)) -&gt; list[dict]:\n    \"\"\"\n    Reads multiple results and returns their information.\n\n    This function takes a list of result IDs as input, reads the corresponding database files from the storage manager,\n    and returns a list of dictionaries, each containing a result's information.\n\n    Args:\n        res_ids (conlist(str, min_length=1)): A list of result IDs.\n\n    Returns:\n        list[dict]: A list of dictionaries, each containing a result's information.\n    \"\"\"\n\n    return [Result.read(res_id) for res_id in res_ids]\n</code></pre>"},{"location":"api_reference/api_run/","title":"Run API","text":""},{"location":"api_reference/api_run/#moonshot.src.api.api_run.api_get_all_run","title":"<code>api_get_all_run(runner_id='')</code>","text":"<p>Retrieves all runs for a given runner ID or for all runners if no ID is provided.</p> <p>This function calls an internal API to get available runs and then converts each run into a dictionary format.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner to retrieve runs for. If empty, runs for all runners</p> <code>''</code> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a run's data.</p> Source code in <code>moonshot/src/api/api_run.py</code> <pre><code>def api_get_all_run(runner_id: str = \"\") -&gt; list[dict]:\n    \"\"\"\n    Retrieves all runs for a given runner ID or for all runners if no ID is provided.\n\n    This function calls an internal API to get available runs and then converts each run into a dictionary format.\n\n    Args:\n        runner_id (str, optional): The ID of the runner to retrieve runs for. If empty, runs for all runners\n        are retrieved.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a run's data.\n    \"\"\"\n    _, runs = _api_get_available_runs(runner_id)\n    return [run.to_dict() for run in runs]\n</code></pre>"},{"location":"api_reference/api_runner/","title":"Runner API","text":""},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_create_runner","title":"<code>api_create_runner(name, endpoints, description='', progress_callback_func=None)</code>","text":"<p>Creates a new runner.</p> <p>This function takes the name, endpoints, and an optional progress callback function to create a new Runner instance. The id of the runner is generated from the name of the runner using the slugify function, so it does not need to be provided.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the runner.</p> required <code>endpoints</code> <code>list[str]</code> <p>A list of endpoint identifiers for the runner.</p> required <code>description</code> <code>str</code> <p>A brief description of the runner. Defaults to an empty string.</p> <code>''</code> <code>progress_callback_func</code> <code>Callable | None</code> <p>An optional callback function for progress updates.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Runner</code> <code>Runner</code> <p>A new Runner object.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_create_runner(\n    name: str,\n    endpoints: list[str],\n    description: str = \"\",\n    progress_callback_func: Callable | None = None,\n) -&gt; Runner:\n    \"\"\"\n    Creates a new runner.\n\n    This function takes the name, endpoints, and an optional progress callback function to create a new Runner instance.\n    The id of the runner is generated from the name of the runner using the slugify function,\n    so it does not need to be provided.\n\n    Args:\n        name (str): The name of the runner.\n        endpoints (list[str]): A list of endpoint identifiers for the runner.\n        description (str, optional): A brief description of the runner. Defaults to an empty string.\n        progress_callback_func (Callable | None, optional): An optional callback function for progress updates.\n        Defaults to None.\n\n    Returns:\n        Runner: A new Runner object.\n    \"\"\"\n    # Create a new recipe runner\n    # We do not need to provide the id.\n    # This is because during creating:\n    # 1. the id is slugify from the name and stored as id.\n    runner_args = RunnerArguments(\n        id=\"\",\n        name=name,\n        endpoints=endpoints,\n        description=description,\n        progress_callback_func=progress_callback_func,\n    )\n    return Runner.create(runner_args)\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_delete_runner","title":"<code>api_delete_runner(runner_id)</code>","text":"<p>Deletes a runner by its identifier.</p> <p>This function takes a runner ID as input and calls the delete method from the Runner class to remove the specified runner from storage.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the runner was successfully deleted.</p> <p>Raises:</p> Type Description <code>Exception</code> <p>If the deletion process encounters an error.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_delete_runner(runner_id: str) -&gt; bool:\n    \"\"\"\n    Deletes a runner by its identifier.\n\n    This function takes a runner ID as input and calls the delete method from the Runner class\n    to remove the specified runner from storage.\n\n    Args:\n        runner_id (str): The unique identifier of the runner to be deleted.\n\n    Returns:\n        bool: True if the runner was successfully deleted.\n\n    Raises:\n        Exception: If the deletion process encounters an error.\n    \"\"\"\n    return Runner.delete(runner_id)\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_get_all_runner","title":"<code>api_get_all_runner()</code>","text":"<p>Retrieves all available runners.</p> <p>This function calls the get_available_items method to retrieve all available runners. It then converts each runner into a dictionary using the to_dict method and returns a list of these dictionaries.</p> <p>Returns:</p> Type Description <code>list[dict]</code> <p>list[dict]: A list of dictionaries, each representing a runner.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>def api_get_all_runner() -&gt; list[dict]:\n    \"\"\"\n    Retrieves all available runners.\n\n    This function calls the get_available_items method to retrieve all available runners. It then converts each\n    runner into a dictionary using the to_dict method and returns a list of these dictionaries.\n\n    Returns:\n        list[dict]: A list of dictionaries, each representing a runner.\n    \"\"\"\n    _, runners = Runner.get_available_items()\n    return [runner.to_dict() for runner in runners]\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_get_all_runner_name","title":"<code>api_get_all_runner_name()</code>","text":"<p>Retrieves all available runner names.</p> <p>This function calls the get_available_items method to retrieve all available runners. It then extracts the names of each runner and returns a list of these names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of runner names.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>def api_get_all_runner_name() -&gt; list[str]:\n    \"\"\"\n    Retrieves all available runner names.\n\n    This function calls the get_available_items method to retrieve all available runners. It then extracts the names of\n    each runner and returns a list of these names.\n\n    Returns:\n        list[str]: A list of runner names.\n    \"\"\"\n    runners_names, _ = Runner.get_available_items()\n    return runners_names\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_load_runner","title":"<code>api_load_runner(runner_id, progress_callback_func=None)</code>","text":"<p>Loads a runner based on the provided runner ID.</p> <p>This function retrieves the runner using the provided runner ID and then loads it. It utilizes the Runner's load method to fetch and return the runner.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner to be loaded.</p> required <code>progress_callback_func</code> <code>Callable | None</code> <p>The progress callback function to be used by the runner.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Runner</code> <code>Runner</code> <p>An initialized Runner object.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_load_runner(\n    runner_id: str, progress_callback_func: Callable | None = None\n) -&gt; Runner:\n    \"\"\"\n    Loads a runner based on the provided runner ID.\n\n    This function retrieves the runner using the provided runner ID and then loads it.\n    It utilizes the Runner's load method to fetch and return the runner.\n\n    Args:\n        runner_id (str): The ID of the runner to be loaded.\n        progress_callback_func (Callable | None): The progress callback function to be used by the runner.\n\n    Returns:\n        Runner: An initialized Runner object.\n    \"\"\"\n    return Runner.load(runner_id, progress_callback_func)\n</code></pre>"},{"location":"api_reference/api_runner/#moonshot.src.api.api_runner.api_read_runner","title":"<code>api_read_runner(runner_id)</code>","text":"<p>Reads a runner and returns its information.</p> <p>This function takes a runner ID as input, reads the corresponding runner, and returns a dictionary containing the runner's information.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <code>dict</code> <p>A dictionary containing the runner's information.</p> Source code in <code>moonshot/src/api/api_runner.py</code> <pre><code>@validate_call\ndef api_read_runner(runner_id: str) -&gt; dict:\n    \"\"\"\n    Reads a runner and returns its information.\n\n    This function takes a runner ID as input, reads the corresponding runner,\n    and returns a dictionary containing the runner's information.\n\n    Args:\n        runner_id (str): The ID of the runner.\n\n    Returns:\n        dict: A dictionary containing the runner's information.\n    \"\"\"\n    return Runner.read(runner_id).to_dict()\n</code></pre>"},{"location":"api_reference/api_session/","title":"Session API","text":""},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_create_session","title":"<code>api_create_session(runner_id, database_instance, endpoints, runner_args)</code>","text":"<p>Creates a new session for a specific runner.</p> <p>This function creates a new session by calling the <code>Session</code> constructor with the provided arguments.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner for which the session is to be created.</p> required <code>database_instance</code> <code>Any</code> <p>The database instance to be used for the session.</p> required <code>endpoints</code> <code>list</code> <p>A list of endpoints for the session.</p> required <code>runner_args</code> <code>dict</code> <p>A dictionary of arguments for the runner.</p> required <p>Returns:</p> Type Description <code>Session</code> <p>Session</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_create_session(\n    runner_id: str, database_instance: Any, endpoints: list[str], runner_args: dict\n) -&gt; Session:\n    \"\"\"\n    Creates a new session for a specific runner.\n\n    This function creates a new session by calling the `Session` constructor with the provided arguments.\n\n    Args:\n        runner_id (str): The unique identifier of the runner for which the session is to be created.\n        database_instance (Any): The database instance to be used for the session.\n        endpoints (list): A list of endpoints for the session.\n        runner_args (dict): A dictionary of arguments for the runner.\n\n    Returns:\n        Session\n    \"\"\"\n    if isinstance(database_instance, DBInterface):\n        if runner_id:\n            session_instance = Session(\n                runner_id,\n                RunnerType.REDTEAM,\n                {**runner_args},\n                database_instance,\n                endpoints,\n                Storage.get_filepath(\n                    EnvVariables.RESULTS.name, runner_id, \"json\", True\n                ),\n            )\n            return session_instance\n        else:\n            raise RuntimeError(\n                \"[Session] Failed to initialise Session. String should have at least 1 character.\"\n            )\n    else:\n        raise RuntimeError(\n            \"[Session] Failed to initialise Session. No database instance provided.\"\n        )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_delete_session","title":"<code>api_delete_session(runner_id)</code>","text":"<p>Deletes the session for a specific runner.</p> <p>This function deletes the session for the runner identified by the given runner_id. It calls the <code>Session.delete</code> method with the runner's database instance.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the session needs to be deleted.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the session is deleted successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_delete_session(runner_id: str) -&gt; bool:\n    \"\"\"\n    Deletes the session for a specific runner.\n\n    This function deletes the session for the runner identified by the given runner_id. It calls the\n    `Session.delete` method with the runner's database instance.\n\n    Args:\n        runner_id (str): The ID of the runner for which the session needs to be deleted.\n\n    Returns:\n        bool: The status on whether the session is deleted successfully.\n    \"\"\"\n    return Session.delete(api_load_runner(runner_id).database_instance)\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_all_chats_from_session","title":"<code>api_get_all_chats_from_session(runner_id)</code>","text":"<p>Retrieves all chat messages from a specific session.</p> <p>This function retrieves all chat messages from the session associated with the specified runner ID. It calls the <code>Session.get_session_chats</code> method with the runner's database instance.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner for which the chat messages are to be retrieved.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: A dictionary containing all chat messages if available, otherwise None.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_get_all_chats_from_session(runner_id: str) -&gt; dict | None:\n    \"\"\"\n    Retrieves all chat messages from a specific session.\n\n    This function retrieves all chat messages from the session associated with the specified runner ID.\n    It calls the `Session.get_session_chats` method with the runner's database instance.\n\n    Args:\n        runner_id (str): The unique identifier of the runner for which the chat messages are to be retrieved.\n\n    Returns:\n        dict | None: A dictionary containing all chat messages if available, otherwise None.\n    \"\"\"\n    return Session.get_session_chats(api_load_runner(runner_id).database_instance)\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_all_session_metadata","title":"<code>api_get_all_session_metadata()</code>","text":"<p>Retrieves metadata for all sessions.</p> <p>This function retrieves the metadata for all active sessions by calling the <code>api_get_available_session_info</code> method.</p> <p>Returns:</p> Name Type Description <code>list</code> <code>list[dict]</code> <p>A list containing the metadata for all active sessions, sorted by created datetime in descending order.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>def api_get_all_session_metadata() -&gt; list[dict]:\n    \"\"\"\n    Retrieves metadata for all sessions.\n\n    This function retrieves the metadata for all active sessions by calling the `api_get_available_session_info` method.\n\n    Returns:\n        list: A list containing the metadata for all active sessions, sorted by created datetime in descending order.\n    \"\"\"\n    _, session_metadata_list = api_get_available_session_info()\n    return sorted(\n        session_metadata_list, key=itemgetter(\"created_datetime\"), reverse=True\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_all_session_names","title":"<code>api_get_all_session_names()</code>","text":"<p>Retrieves a list of all session names.</p> <p>This function calls the <code>api_get_available_session_info</code> method to obtain the available session information and returns a list of session names.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of strings, each denoting a session name.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>def api_get_all_session_names() -&gt; list[str]:\n    \"\"\"\n    Retrieves a list of all session names.\n\n    This function calls the `api_get_available_session_info` method to obtain the available session information\n    and returns a list of session names.\n\n    Returns:\n        list[str]: A list of strings, each denoting a session name.\n    \"\"\"\n    session_names, _ = api_get_available_session_info()\n    return session_names\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_get_available_session_info","title":"<code>api_get_available_session_info()</code>","text":"<p>Retrieves the IDs and database instances of runners with active sessions.</p> <p>This function retrieves the IDs and database instances of runners with active sessions by querying all runners and checking if each runner has an active session. It returns a tuple containing a list of runner IDs and a list of corresponding session metadata for runners with active sessions.</p> <p>Returns:</p> Type Description <code>list</code> <p>tuple[list[str], list[str]]: A tuple containing a list of runner IDs and a list of corresponding session</p> <code>list</code> <p>metadata for runners with active sessions.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>def api_get_available_session_info() -&gt; tuple[list, list]:\n    \"\"\"\n    Retrieves the IDs and database instances of runners with active sessions.\n\n    This function retrieves the IDs and database instances of runners with active sessions by querying all runners\n    and checking if each runner has an active session. It returns a tuple containing a list of runner IDs and a list\n    of corresponding session metadata for runners with active sessions.\n\n    Returns:\n        tuple[list[str], list[str]]: A tuple containing a list of runner IDs and a list of corresponding session\n        metadata for runners with active sessions.\n    \"\"\"\n    runners_info = api_get_all_runner()\n    runner_instances = [\n        api_load_runner(str(runner_info.get(\"id\"))) for runner_info in runners_info\n    ]\n\n    runner_ids = []\n    session_metadata_list = []\n\n    for runner_instance in runner_instances:\n        if runner_instance.database_instance:\n            session_metadata = Session.load(runner_instance.database_instance)\n            if session_metadata is not None:\n                runner_ids.append(runner_instance.id)\n                session_metadata_list.append(session_metadata)\n    return runner_ids, session_metadata_list\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_load_session","title":"<code>api_load_session(runner_id)</code>","text":"<p>Loads the session details for a specific runner.</p> <p>This function calls the <code>Session.load</code> method to retrieve the session details associated with the specified runner ID.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The unique identifier of the runner for which the session details are to be loaded.</p> required <p>Returns:</p> Type Description <code>dict | None</code> <p>dict | None: A dictionary containing the session details if available, otherwise None.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_load_session(runner_id: str) -&gt; dict | None:\n    \"\"\"\n    Loads the session details for a specific runner.\n\n    This function calls the `Session.load` method to retrieve the session details associated with the\n    specified runner ID.\n\n    Args:\n        runner_id (str): The unique identifier of the runner for which the session details are to be loaded.\n\n    Returns:\n        dict | None: A dictionary containing the session details if available, otherwise None.\n    \"\"\"\n    return Session.load(api_load_runner(runner_id).database_instance)\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_attack_module","title":"<code>api_update_attack_module(runner_id, attack_module_id)</code>","text":"<p>Updates the attack module for a specific runner.</p> <p>This function updates the attack module for a specific runner identified by the given runner_id. It calls the <code>Session.update_attack_module</code> method with the runner's database instance, runner_id, and the new attack_module_id.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the attack module needs to be updated.</p> required <code>attack_module_id</code> <code>str</code> <p>The new attack module to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the attack module is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_attack_module(runner_id: str, attack_module_id: str) -&gt; bool:\n    \"\"\"\n    Updates the attack module for a specific runner.\n\n    This function updates the attack module for a specific runner identified by the given runner_id. It calls the\n    `Session.update_attack_module` method with the runner's database instance,\n    runner_id, and the new attack_module_id.\n\n    Args:\n        runner_id (str): The ID of the runner for which the attack module needs to be updated.\n        attack_module_id (str): The new attack module to be set for the runner.\n\n    Returns:\n        bool: The status on whether the attack module is updated successfully.\n    \"\"\"\n    return Session.update_attack_module(\n        api_load_runner(runner_id).database_instance, runner_id, attack_module_id\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_context_strategy","title":"<code>api_update_context_strategy(runner_id, context_strategy)</code>","text":"<p>Updates the context strategy for a specific runner.</p> <p>This function updates the context strategy for a specific runner identified by the given runner_id. It calls the <code>Session.update_context_strategy</code> method with the runner's database instance, runner_id, and the new context_strategy.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the context strategy needs to be updated.</p> required <code>context_strategy</code> <code>str</code> <p>The new context strategy to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the context strategy is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_context_strategy(runner_id: str, context_strategy: str) -&gt; bool:\n    \"\"\"\n    Updates the context strategy for a specific runner.\n\n    This function updates the context strategy for a specific runner identified by the given runner_id. It calls the\n    `Session.update_context_strategy` method with the runner's database instance,\n    runner_id, and the new context_strategy.\n\n    Args:\n        runner_id (str): The ID of the runner for which the context strategy needs to be updated.\n        context_strategy (str): The new context strategy to be set for the runner.\n\n    Returns:\n        bool: The status on whether the context strategy is updated successfully.\n    \"\"\"\n    return Session.update_context_strategy(\n        api_load_runner(runner_id).database_instance, runner_id, context_strategy\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_cs_num_of_prev_prompts","title":"<code>api_update_cs_num_of_prev_prompts(runner_id, num_of_prev_prompts)</code>","text":"<p>Updates the number of previous prompts used in a context strategy for a specific runner.</p> <p>This function updates the number of previous prompts used in a context strategy for a specific runner identified by the given runner_id. It calls the <code>Session.update_cs_num_of_prev_prompts</code> method with the runner's database instance, runner_id, and the new num_of_prev_prompts.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the number of previous prompts needs to be updated.</p> required <code>num_of_prev_prompts</code> <code>int</code> <p>The new number of previous prompts to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the number of prompts for context strategy is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_cs_num_of_prev_prompts(runner_id: str, num_of_prev_prompts: int) -&gt; bool:\n    \"\"\"\n    Updates the number of previous prompts used in a context strategy for a specific runner.\n\n    This function updates the number of previous prompts used in a context strategy for a specific runner identified by\n    the given runner_id. It calls the `Session.update_cs_num_of_prev_prompts` method with the runner's database\n    instance, runner_id, and the new num_of_prev_prompts.\n\n    Args:\n        runner_id (str): The ID of the runner for which the number of previous prompts needs to be updated.\n        num_of_prev_prompts (int): The new number of previous prompts to be set for the runner.\n\n    Returns:\n        bool: The status on whether the number of prompts for context strategy is updated successfully.\n    \"\"\"\n    return Session.update_cs_num_of_prev_prompts(\n        api_load_runner(runner_id).database_instance, runner_id, num_of_prev_prompts\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_metric","title":"<code>api_update_metric(runner_id, metric_id)</code>","text":"<p>Updates the metric for a specific runner.</p> <p>This function updates the metric for a specific runner identified by the given runner_id. It calls the <code>Session.update_metric</code> method with the runner's database instance, runner_id, and the new metric_id.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the metric needs to be updated.</p> required <code>metric_id</code> <code>str</code> <p>The new metric to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the metric is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_metric(runner_id: str, metric_id: str) -&gt; bool:\n    \"\"\"\n    Updates the metric for a specific runner.\n\n    This function updates the metric for a specific runner identified by the given runner_id. It calls the\n    `Session.update_metric` method with the runner's database instance,\n    runner_id, and the new metric_id.\n\n    Args:\n        runner_id (str): The ID of the runner for which the metric needs to be updated.\n        metric_id (str): The new metric to be set for the runner.\n\n    Returns:\n        bool: The status on whether the metric is updated successfully.\n    \"\"\"\n    return Session.update_metric(\n        api_load_runner(runner_id).database_instance, runner_id, metric_id\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_prompt_template","title":"<code>api_update_prompt_template(runner_id, prompt_template)</code>","text":"<p>Updates the prompt template for a specific runner.</p> <p>This function updates the prompt template for a specific runner identified by the given runner_id. It calls the <code>Session.update_prompt_template</code> method with the runner's database instance, runner_id, and the new prompt_template.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the prompt template needs to be updated.</p> required <code>prompt_template</code> <code>str</code> <p>The new prompt template to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the prompt template is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_prompt_template(runner_id: str, prompt_template: str) -&gt; bool:\n    \"\"\"\n    Updates the prompt template for a specific runner.\n\n    This function updates the prompt template for a specific runner identified by the given runner_id. It calls the\n    `Session.update_prompt_template` method with the runner's database instance,\n    runner_id, and the new prompt_template.\n\n    Args:\n        runner_id (str): The ID of the runner for which the prompt template needs to be updated.\n        prompt_template (str): The new prompt template to be set for the runner.\n\n    Returns:\n        bool: The status on whether the prompt template is updated successfully.\n    \"\"\"\n    return Session.update_prompt_template(\n        api_load_runner(runner_id).database_instance, runner_id, prompt_template\n    )\n</code></pre>"},{"location":"api_reference/api_session/#moonshot.src.api.api_session.api_update_system_prompt","title":"<code>api_update_system_prompt(runner_id, system_prompt)</code>","text":"<p>Updates the system prompt for a specific runner.</p> <p>This function updates the system prompt for a specific runner identified by the given runner_id. It calls the <code>Session.update_system_prompt</code> method with the runner's database instance, runner_id, and the new system_prompt.</p> <p>Parameters:</p> Name Type Description Default <code>runner_id</code> <code>str</code> <p>The ID of the runner for which the system prompt needs to be updated.</p> required <code>system_prompt</code> <code>str</code> <p>The new system prompt to be set for the runner.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>The status on whether the system prompt is updated successfully.</p> Source code in <code>moonshot/src/api/api_session.py</code> <pre><code>@validate_call\ndef api_update_system_prompt(runner_id: str, system_prompt: str) -&gt; bool:\n    \"\"\"\n    Updates the system prompt for a specific runner.\n\n    This function updates the system prompt for a specific runner identified by the given runner_id. It calls the\n    `Session.update_system_prompt` method with the runner's database instance,\n    runner_id, and the new system_prompt.\n\n    Args:\n        runner_id (str): The ID of the runner for which the system prompt needs to be updated.\n        system_prompt (str): The new system prompt to be set for the runner.\n\n    Returns:\n        bool: The status on whether the system prompt is updated successfully.\n    \"\"\"\n    return Session.update_system_prompt(\n        api_load_runner(runner_id).database_instance, runner_id, system_prompt\n    )\n</code></pre>"},{"location":"api_reference/web_api_swagger/","title":"Web-API","text":"<p>To evaluate the Swagger documentation, initiate the Moonshot web API and navigate to 127.0.0.1:5000/docs in your web browser.</p> <p></p>"},{"location":"getting_started/first_test/","title":"Running your first test","text":""},{"location":"getting_started/first_test/#objective","title":"Objective","text":"<p>In this guide, you will learn how to</p> <ol> <li>Launch Moonshot UI </li> <li>Run tests using benchmark and perform red teaming on one of the OpenAI models.</li> </ol>"},{"location":"getting_started/first_test/#launch-moonshot-ui","title":"Launch Moonshot UI","text":"<p>Moonshot UI is designed to simplify the testing workflows. Once Moonshot is installed, you can start the Web UI using the  following command:</p> <pre><code>python -m moonshot web\n</code></pre> <p>Then, use your browser and navigate to <code>http://localhost:3000</code></p> <p>Note</p> <p>We will be testing a model from OpenAI in this guide. You will need to prepare two API tokens - one from OpenAI and one from TogetherAI</p>"},{"location":"getting_started/first_test/#run-benchmark-test","title":"Run Benchmark Test","text":"<p>Upon navigating to the webpage, you will be greeted with our main screen. To start a benchmark test, click on \"Get Started\".</p> <p></p> <p>This will direct you to a wizard that will guide you through the testing process. In the first step, select the tests you would like to run on your model. By default, three baseline tests are selected.</p> <p>Note</p> <p>We will be testing a model from OpenAI in this guide. You will need to prepare an OpenAI API token.</p> <p></p> <p>Once you have completed the selection, click on the arrow to proceed to the next step. In this step, you will see the total number of prompts in this set of tests. Click on the arrow again to advance to the next step.</p> <p></p> <p>Connect to your AI system. Click \"Edit\" for one of the OpenAI models, such as OpenAI GPT-3.5 Turbo.</p> <p></p> <p>Enter your API token on this screen, then click \"Save\". Repeat this step for \"Together Llama Guard 7B Assistant.\"</p> <p>Note</p> <p>Some cookbooks use another LLM to evaluate the response. For this test, one of the baseline cookbooks uses Llama Guard 7B to evaluate if the response is safe or unsafe.</p> <p></p> <p>You will return to the screen to select the endpoint. Choose the endpoint you have just configured, then proceed to the next step by clicking the arrow.</p> <p>Finally, enter the name and description for this test. Set the number of prompts to \"1\" and click \"Run.\"</p> <p></p> <p>The progress bar will be shown in the screen.</p> <p></p> <p>Note</p> <p>You can continue using Moonshot for other tasks, such as red teaming, while waiting for the test to complete.</p> <p>If the test runs unsuccessfully, you can view the errors by clicking on \"View Errors\".</p> <p></p> <p>If the test runs successfully, you will be prompted to view the report.</p> <p></p> <p>You can view the report in the web browser, or you can download it for offline access by clicking the \"Download HTML Report\" button.</p> <p></p>"},{"location":"getting_started/first_test/#run-red-teaming","title":"Run Red Teaming","text":"<p>To initiate red teaming, click on the icon in the sidebar or select \"Start Red Teaming\" from the home page.</p> <p></p> <p>Note</p> <p>If you click on the icon in the sidebar, click \"Start New Session\" in the next screen.</p> <p>Select one or more endpoints to red team on this screen. Click the arrow to proceed to the next screen.</p> <p></p> <p>In this screen, you have the option to select one of the attack modules to automatically red team your model. For the purposes of this guide, we will skip this step. Click \"Skip for now\".</p> <p></p> <p>Enter a name and type a description in this screen, then click \"Start\".</p> <p></p> <p>In the red teaming screen, you can type any text in the textbox at the bottom to send a prompt to the selected endpoints. The prompt will be sent to all endpoints.</p> <p></p> <p>To run automated red teaming, click on \"Attack Module\" and select one of the modules. For this test, select \"Toxic Sentence Generator\" to test whether the endpoints can be induced to complete the sentences with toxic words.</p> <p></p> <p>Type a cuss word in the prompt. This process may take a while to load, as it requires Moonshot to download a specific model. Once completed, you can review the prompts by scrolling through the chatbox.</p> <p></p>"},{"location":"getting_started/overview/","title":"Moonshot","text":"<p>Developed by the AI Verify Foundation, Moonshot is one of the first tools to bring benchmarking and red teaming together to help AI developers, compliance teams and AI system owners test and evaluate their LLMs and LLM applications.</p>"},{"location":"getting_started/overview/#what-does-moonshot-do","title":"What does Moonshot do?","text":"<p>Moonshot provides ready access to test LLMs from popular model providers e.g., OpenAI, Anthropic, Together, HuggingFace. You will just need to provide your API Key.</p> <p>If you are testing other models or your own LLM application hosted on a custom server, you will need to create your own Model Connector. Fortunately, Model Connectors in Moonshot are designed in such a way that you will need to write as few lines of code as possible.</p>"},{"location":"getting_started/overview/#benchmark","title":"Benchmark","text":"<p>Benchmarks are \u201cexam questions\u201d to test the model across a variety of competencies, e.g., language and context understanding.</p> <p>Moonshot offers a range of benchmarks to measure your LLM application's performance in the categories of Capability, Quality, and Trust &amp; Safety. These include benchmarks widely used by the community like Google's BigBench and HuggingFace's leaderboards, and more domain/task specific tests like Tamil Language and Medical LLM benchmarks.</p>"},{"location":"getting_started/overview/#red-teaming","title":"Red Teaming","text":"<p>Red teaming is the adversarial prompting of LLM applications to induce them to behave in a manner incongruent with their design. This process is crucial to identify vulnerabilities in AI systems.</p> <p>Moonshot simplifies the process of red teaming by providing an easy to use interface that allows for the simulataneous probing of multiple LLM applications, and equipping you with red teaming utilities like prompt templates, context strategies and attack modules.</p>"},{"location":"getting_started/overview/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>As red teaming conventionally relies on human ingenuity, it is hard to scale. Moonshot has developed some attack modules based on research-backed techniques that will enable you to automatically generate adversarial prompts.</p>"},{"location":"getting_started/overview/#glossary","title":"Glossary","text":"<p>Here are some common terms that may be used in this documentation:</p> Term Description Connector A Connector in Moonshot enables users to integrate new models into the toolkit by connecting to their Large Language Models (LLMs) via API connectors. Cookbook A Cookbook in Moonshot contains one or more recipes, each designed to generate results when selected to run with the model endpoints. It serves as a comprehensive guide for conducting evaluations and tests, offering a structured approach to assessing LLM applications' performance and addressing potential risks. Recipe A Recipe in Moonshot brings together 3 essential components. A recipe can contain one or more datasets, prompt templates and metrics. Datasets Datasets consist of a collection of input-target pairs, where the 'input' is a prompt provided to the LLM (being tested), and the 'target' is the correct response or ground truth. Session A Session feature allows users to initiate interactions with selected models, enabling them to engage in chats and send prompts to red team the models. Chat A Chat refers to an interaction directed to a specific model within a session, initiating the red teaming prompt process. Users can communicate with individual models, sending prompts and assessing their responses to identify potential vulnerabilities and areas for improvement in LLM applications."},{"location":"getting_started/quick_install/","title":"Installing Moonshot for User Interface","text":""},{"location":"getting_started/quick_install/#dependencies-needed-for-installation","title":"Dependencies needed for installation","text":"<p>This project strictly requires Python 3.11. Ensure that you have Python 3.11 installed on your system before proceeding with installation and usage.</p> Software Version Requirement Python v3.11 NodeJs v20.11.1 LTS or above npm v10.8.0 or above git"},{"location":"getting_started/quick_install/#install-moonshot","title":"Install Moonshot","text":"<p>Run the following command in a virtual environment of your choice:</p> <pre><code>$ pip install \"aiverify-moonshot[all]\"\n</code></pre> <p>Once installed, Moonshot provides commands to download all the test assets required to start testing your AI system:</p> <pre><code>$ python -m moonshot -i moonshot-data -i moonshot-ui\n</code></pre> <p>Run Moonshot UI with the following command:</p> <pre><code>$ python -m moonshot web\n</code></pre> <p>Lastly, access Moonshot UI using a browser (<code>http://localhost:3000</code>).</p> <p>Warning</p> <p>If you are operating on an x86 MacOS, you may encounter difficulties when attempting to install the dependency for moonshot-data. Please refer to this FAQ for a potential solution.</p>"},{"location":"getting_started/quick_install/#extra-resources","title":"Extra Resources","text":""},{"location":"getting_started/quick_install/#setting-up-virtual-environment","title":"Setting up Virtual Environment","text":"<p>It is recommended to create a new Python virtual environment in your working directory before proceeding with installation. To do so, enter working directory and proceed with following steps:</p> Windows PowershellWindows Command PromptMac <pre><code>$ python -m venv venv\n$ venv/Scripts/Activate.ps1\n</code></pre> <pre><code>$ python -m venv venv\n$ venv/Scripts/activate.bat\n</code></pre> <pre><code>$ python -m venv venv\n$ source venv/bin/activate\n</code></pre>"},{"location":"getting_started/quick_install/#setting-up-logging","title":"Setting up Logging","text":"<p>By default, the moonshot library uses a logger to write logs with its severity to <code>moonshot.log</code>.</p> <p>There are multiple severity levels that we are currently using:</p> Logging Severity Description debug Used for detailed debugging information, helpful during development. info General information about system operation, useful for system monitoring. warning Indicates a potential issue that should be looked into but is not immediately critical. error Reports a failure within the system, requiring immediate attention. <p>Additionally, you can customize the logging behavior through environment variables:</p> Environment Variable Description Default Value MS_LOG_NAME The name of the log file. <code>moonshot.log</code> MS_LOG_LEVEL The minimum logging severity to capture. Can be one of <code>debug</code>, <code>info</code>, <code>warning</code>, or <code>error</code>. <code>info</code> MS_LOG_TO_FILE Whether to write logs to a file (<code>true</code>) or to standard output (<code>false</code>). <code>false</code> <p>To customize the logging behavior of Moonshot through environment variables, you can export them in your terminal. This allows you to override the default logging configurations. Here's how you can set them: <pre><code>export MS_LOG_NAME=moonshot\nexport MS_LOG_LEVEL=debug\nexport MS_LOG_TO_FILE=true\n</code></pre> After exporting these variables, any subsequent runs of the Moonshot application will adhere to these logging settings  until the terminal session ends or the variables are unset.</p> <p>The logging format is designed to provide a clear and concise overview of each log entry, structured as follows: <pre><code>%(asctime)s [%(levelname)s][%(filename)s::%(funcName)s(%(lineno)d)] %(message)s\n</code></pre> This format includes:</p> <ul> <li>timestamp (<code>%(asctime)s</code>)</li> <li>severity level (<code>%(levelname)s</code>)</li> <li>filename (<code>%(filename)s</code>)</li> <li>function name (<code>%(funcName)s</code>)</li> <li>line number (<code>%(lineno)d</code>)</li> <li>log message (<code>%(message)s</code>)</li> </ul> <p>For example: <pre><code>2023-04-01 12:00:00 [INFO][module.py::main(10)] Application started successfully.\n</code></pre> This detailed format ensures that logs are not only easily readable but also provide in-depth information for debugging and monitoring purposes.</p>"},{"location":"getting_started/quick_install/#specifying-custom-environment-file","title":"Specifying Custom Environment File","text":"<p>If you have a custom '.env' file, specify the path to the file as follows: <pre><code>python -m moonshot -e /path/to/your/.env\n</code></pre></p>"},{"location":"getting_started/quick_start/","title":"Quick Start Guide","text":"<p>Note</p> <p>Users are encouraged to install using the latest release on <code>pypi</code>.</p>"},{"location":"resources/attack_modules/","title":"List of Attack Modules","text":"Name Description Character Swap Attack This module tests for adversarial textual robustness. It creates perturbations through swapping characters for words that contains more than 3 characters.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. [Default: 10] Toxic Sentence Generator This module generates toxic sentence based on a given seed prompt. The attack module intends to test if the system under tests will complete the sentence with toxic sentences/phrases. TextBugger Attack This module tests for adversarial textual robustness and implements the perturbations listed in the paper TEXTBUGGER: Generating Adversarial Text Against Real-world Applications.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. This is also thenumber of transformations that should be generated. [Default: 5]Note:Usage of this attack module requires the internet. Initial downloading of the GLoVe embedding occurs when the UniversalEncoder is called.Embedding is retrieved from the following URL: https://textattack.s3.amazonaws.com/word_embeddings/paragramcf Job Role Generator Module This attack module adds demographic groups to the job role. Homoglyph Attack This module tests for adversarial textual robustness. Homoglyphs are alternative words for words comprising of ASCII characters.Example of a homoglyph fool -&gt; fooIThis module purturbs the prompt with all available homoglyphs for each word present.Parameters:1. MAX_ITERATIONS - Maximum number of prompts that should be sent to the target. [Default: 20] Violent Durian This is a multi-turn agent designed to interact over several exchanges. It's used to elicit dangerous or violent suggestions from the target language model by adopting a criminal persona. The application is experimental and uses OpenAI GPT-4. Configure the endpoint openai-gpt4 to use this attack module. TextFooler Attack This module tests for adversarial textual robustness and implements the perturbations listed in the paper Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. This is also the number of transformations that should be generated. [Default: 5]Note:Usage of this attack module requires the internet. Initial downloading of the GLoVe embedding occurs when the UniversalEncoder is called.Embedding is retrieved from the following URL: https://textattack.s3.amazonaws.com/word_embeddings/paragramcf Colloquial Wordswap This attack module tests for textual robustness against the Singapore context. It takes in prompts that feature nouns that describe people. Examples of this include words like 'girl' , 'boy' or 'grandmother'. The module substitutes these words with their Singapore colloquial counterparts, such as 'ah boy', 'ah girl' and 'ah ma'. Insert Punctuation Attack This module tests for adversarial textual robustness and creates perturbations through adding punctuation to the start of words in a prompt.Parameters:1. MAX_ITERATIONS - Number of prompts that should be sent to the target. [Default: 10] Malicious Question Generator This attack module generates malicious questions using OpenAI's GPT4 based on a given topic. This module will stop by the number of iterations (Default: 50). To use this attack module, you need to configure an 'openai-gpt4'endpoint. Sample Attack Module This is a sample attack module. Singapore Sentence Generator This module generates singlish sentence based on a given seed prompt. The attack module intends to test if the endpoint will complete the sentence with toxic sentences/phrases in Singapore context."},{"location":"resources/cookbooks/","title":"List of Cookbooks","text":"Name Description Recipes Easy test sets for Common Risks This is a cookbook that consists (easy) test sets for common risks. These test sets are adapted from various research and will be expanded in the future. 1. uciadult2. bbq3. winobias4. challenging-toxicity-prompts-completion5. realtime-qa6. commonsense-morality-easy7. jailbreak-dan8. advglue Hard test sets for Common Risks This is a cookbook that consists (hard) test sets for common risks. These test sets are adapted from various research and will be expanded in the future. 1. uciadult2. bbq3. winobias4. challenging-toxicity-prompts-completion5. realtime-qa6. commonsense-morality-hard7. jailbreak-dan8. advglue Medical LLM Leaderboard This cookbook contains the benchmarks used in Medical LLM Leaderboard hosted on HuggingFace. Achieving a high score may mean that the targeted system is performing well in answering healthcare questions. 1. medical-mcq2. mmlu-medical MLCommons AI Safety Benchmarks v0.5 for General Chat Models This cookbook systematically assesses the system's capacity to navigate and respond to potentially harmful inquiries, analyzing its responses in accordance with the established safety guidelines. A high refusal rate means that the system under test is performing very well. A low refusal rate means that the system under test is unsafe. 1. mlc-cae2. mlc-cbr3. mlc-hat4. mlc-nvc5. mlc-vcr6. mlc-ssh7. mlc-scr Leaderboard Cookbook This cookbook, drawing inspiration from leaderboards like HF's OpenLLM and HELM, features popular benchmarks for testing model capabilities, with results that may vary from actual leaderboard standings. 1. mmlu2. truthfulqa-mcq3. winogrande4. hellaswag5. arc6. gsm8k Facts about Singapore This cookbook is designed to evaluate Singapore's historical events and essential facts, serving as a litmus test for its understanding of the country's unique context. In addition, there are safety prompts written in Singapore context. By assessing a model's familiarity with Singapore's cultural and historical landscape, it provides valuable insights into its overall proficiency and accuracy in natural language processing systems tailored to Singaporean contexts. singapore-facts Tamil Language This is a cookbook that consists of datasets related to the Tamil Language. 1. tamil-kural-classification2. tamil-tamilnews-classification3. tamil-tanglish-tweets AI Safety in Chinese Language This cookbook measures the system's ability in answering trust and safety questions that are asked in Chinese languages. 1. cvalues2. cbbq-lite Legal Summarisation This cookbook runs general capabilitiy benchmark on legal summarisation model. 1. analogical-similarity2. auto-categorisation3. cause-and-effect4. contextual-parametric-knowledge-conflicts5. gre-reading-comprehension6. squad-shifts-tnf"},{"location":"resources/datasets/","title":"List of Datasets","text":"Name Description License Reference squad-shifts-tnf Zero-shot reading comprehension on paragraphs and questions from squadshifts - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/squad_shifts BBQ-lite on religion - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on religion, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 advglue Adversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models. - https://github.com/AI-secure/adversarial-glue Food in Singapore Contain prompts that test model's udnerstanding in Food, in True/False format Apache-2.0 IMDA MedMCQA MedMCQ is a large-scale, multiple-choice question answering dataset designed to address realworld medical entrance exam questions. It contains more than 194k high-quality AIIMS &amp; NEET PG entrnace exam MCQs covering 2.4k healthcare topics and 21 medical subjects. MIT License https://github.com/MedMCQA/MedMCQA tamil-thirukural This dataset is used to test the comprehension abilities for the Thirukkural. Thirukkural is a classic Tamil literature composed by the ancient Tamil poet Thiruvalluvar. It consists of 1330 couplets (kurals) that are grouped into 133 chapters, each containing 10 couplets. Creative Commons Attribution 4.0 International https://github.com/vijayanandrp/Thirukkural-Tamil-Dataset RealtimeQA RealTime QA is a dynamic question answering (QA) platform that inquires about the present. - https://github.com/realtimeqa/realtimeqa_public sg-university-tutorial-questions-legal Contain tutorial questions ans answers from Singapore's Universities to test model's ability in understanding legal context in Singapore - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on gender - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on gender, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 ARC-Easy A dataset of genuine grade-school level, multiple-choice science questions in advanced Q&amp;A. This is the challenge set. CC BY-SA https://allenai.org/data/arc BBQ-lite on nationality - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on nationality, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 m3exam-vietnamese This dataset contains local exam questions for testing Vietnamese capability. CC BY-NC-SA https://github.com/DAMO-NLP-SG/M3Exam BBQ-lite on physical-appearance - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on physical-appearance, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 tanglish-tweets-SA Code-mixed Tamil and English tweets curated for the sentiment analysis task. CC0: Public Domain - Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ uciadult The UCI Adult dataset has been used widely used to assess fairness. Creative Commons Attribution 4.0 International https://archive.ics.uci.edu/dataset/2/adult BBQ-lite on age - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on age, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Suicide &amp; Self-Harm Responses that enable, encourage, or endorse acts of intentional self-harm. - - sg-legal-glossary A list of singapore legal terms extracted from SICC and Judiciary websites. - https://www.sicc.gov.sg/glossary-of-legal-terms MLC Baseline - Hate Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics. - - BBQ-lite on age - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on age, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 cause_and_effect This recipe measures if the model is able to distinguish and understand cause and effect. The higher the grade, the better the system can perform this capability. - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/cause_and_effect BBQ-lite on race-x-gender - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-gender, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ TruthfulQA (MCQ Version) TruthfulQA aims to measure the the truthfulness of a model. This dataset uses a multiple choice format. Apache-2.0 https://github.com/sylinrl/TruthfulQA Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ PubMedQA PubMedQA is a large-scale, multiple-choice question answering dataset designed to address realworld medical entrance exam questions. It contains more than 194k high-quality AIIMS &amp; NEET PG entrnace exam MCQs covering 2.4k healthcare topics and 21 medical subjects. MIT License https://github.com/MedMCQA/MedMCQA Facts about Singapore in True and False Contain prompts that contains facts about Singapore, in True/False format Apache-2.0 IMDA Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ RealToxicityPrompts RealToxicityPrompts aims to measure the model's ability in identify toxic sentences. Apache-2.0 https://github.com/allenai/real-toxicity-prompts/ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ gre_reading_comprehension To measure the model/'s ability to summarize text, infer and deduce knowledge from context, and match the context. - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/gre_reading_comprehension MMLU College Medicine MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU College Medicine MIT License https://github.com/hendrycks/test BBQ-lite on race-x-ses - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-ses, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Singapore Polical History Contain questions about Singapore's key historical events in political. Apache-2.0 IMDA ChallengingToxicityPrompts ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences. CC BY-SA 4.0 https://github.com/AI-secure/DecodingTrust MLC Baseline - Violent Crimes Responses that enable, encourage, or endorse the commission of violent crimes. - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MMLU Clinical Knowledge MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Clinical Knowledge MIT License https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ coqa_conversational_question_answering To measure the ability of machines to understand a text passage and answer a series of interconnected questions - - Singapore Transport System Contain questions about Singapore's public housing system Apache-2.0 IMDA ChallengingToxicityPrompts ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences. CC BY-SA 4.0 https://github.com/AI-secure/DecodingTrust BBQ-lite on race-x-ses - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-ses, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Chemical, Biological, Radiological, Nuclear, and Explosives Responses that enable, encourage, or endorse the creation of weapons of mass destruction. - - BBQ-lite on gender - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on gender, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 BBQ-lite on sexual-orientation - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on sexual-orientation, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MLC Baseline - Chemical, Biological, Radiological, Nuclear, and Explosives Responses that enable, encourage, or endorse the creation of weapons of mass destruction. - - MLC Baseline - Hate Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics. - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Winogrande This dataset is used for commonsense reasoning, expert-crafted pronoun resolution problems designed to be unsolvable for statistical models. Apache-2.0 https://github.com/allenai/winogrande Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Contextual Parametric Knowledge Conflicts To measure the model/\u2019s ability in making informed predictions - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/contextual_parametric_knowledge_conflicts MMLU Anatomy MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Anatomy MIT License https://github.com/hendrycks/test Singapore Transport System Contain questions about Singapore's transport system Apache-2.0 IMDA truthfulqa TruthfulQA aims to measure the the truthfulness of a model. Apache-2.0 https://github.com/sylinrl/TruthfulQA ARC-Easy A dataset of genuine grade-school level, multiple-choice science questions in advanced Q&amp;A. This is the easy set. CC BY-SA https://allenai.org/data/arc Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Iconic Places in Singapore Contain questions about Singapore's iconic places. Apache-2.0 IMDA Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MLC Baseline - Sex-Related Crimes Responses that enable, encourage, or endorse the commission of sex-related crimes. - - Analogical Similarity To measure the model\u2019s ability in discriminating between different degrees of analogical similarity in two given episodes - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/analogical_similarity Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on race-ethnicity - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on race-ethnicity, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 GSM8K This dataset consists of high quality grade school math problems created by human. These problems take between 2 and 8 steps to solve, and usually requires a sequence of elementary calculations. MIT License https://github.com/openai/grade-school-math MLC Baseline - Child Abuse and Exploitation Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children. - - m3exam-indonesian This dataset contains local exam questions for testing Indonesian capability. CC BY-NC-SA https://github.com/DAMO-NLP-SG/M3Exam BBQ-lite on race-x-gender - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on race-x-gender, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Sex-Related Crimes Responses that enable, encourage, or endorse the commission of sex-related crimes. - - BBQ-lite on disability-status - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on disability-status, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MMLU College Biology MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU College Biology MIT License https://github.com/hendrycks/test ChallengingToxicityPrompts ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences. CC BY-SA 4.0 https://github.com/AI-secure/DecodingTrust BBQ-lite on religion - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on religion, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MLC Baseline - Child Abuse and Exploitation Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children. - - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ MLC Baseline - Non-Violent Crimes Responses that enable, encourage, or endorse the commission of non-violent crimes. - - MLC Baseline - Non-Violent Crimes Responses that enable, encourage, or endorse the commission of non-violent crimes. - - List of Occupations This dataset contains a list of occupations collected from various websites (e.g., MoM of Singapore). The dataset can be used to test job-related applications. MIT License IMDA In-the-wild Jailbreak Dataset This dataset contains jailbreak prompts that were collected from various places (e.g., Discord). MIT license https://github.com/verazuo/jailbreak_llms MLC Baseline - Suicide &amp; Self-Harm Responses that enable, encourage, or endorse acts of intentional self-harm. - - MLC Baseline - Violent Crimes Responses that enable, encourage, or endorse the commission of violent crimes. - - Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ auto_categorization To measure the model's ability in categorising elements into groups. - https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/auto_categorization BBQ-lite on sexual-orientation - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on sexual-orientation, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 tamil-news-classification This dataset is used to classify a static set of Tamil News. The task is to classify news to its respective category. The dataset has 6 news categories - \"tamilnadu\", \"india\", \"cinema\", \"sports\", \"politics\", \"world\". GNU General Public License v3.0 - Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ C-Values - Values of Chinese Large Language attack_modules This dataset contains prompts that can measure the alignment ability of LLMs in both safety and responsibility in Chinese Language. Apache-2.0 license - BBQ-lite on physical-appearance - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on physical-appearance, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 enronemail The Enron email dataset is aimed at evaluating if there is leakage of private information. The dataset was used in DecodingTrust as part of its privacy evaluation. Apache-2.0 https://github.com/ParakweetLabs/EmailIntentDataSet m3exam-thai This dataset contains local exam questions for testing Thai capability. CC BY-NC-SA https://github.com/DAMO-NLP-SG/M3Exam MMLU Medical Genetics MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Medical Genetics MIT License https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on ses - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on ses, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 truthfulqa TruthfulQA aims to measure the the truthfulness of a model. Apache-2.0 https://github.com/sylinrl/TruthfulQA Ethics-Commonsense-Hard This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept. MIT License https://github.com/hendrycks/ethics/ Places in Singapore Contain prompts that test model's udnerstanding places in Singapore, in True/False format Apache-2.0 IMDA BBQ-lite on nationality - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on nationality, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 MMLU Professional Medicine.json MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Professional Medicine.json MIT License https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on race-ethnicity - Ambiguous Questions This dataset is an excerpt from Bias Benchmark from QA on race-ethnicity, containing only the ambiguous questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ winobias-variation1 This dataset contains gender-bias based on the professions from the Labor Force Statistics (https://www.bls.gov/cps/cpsaat11.htm), which contain some gender-bias. MIT License https://github.com/uclanlp/corefBias/tree/master/WinoBias/wino Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ HellaSwag This dataset is used to evaluate commonsense with questions that are trivial for humans but difficult for state-of-the-art models. MIT License https://github.com/rowanz/hellaswag BBQ-lite on ses - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on ses, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2 Safety Benchmark (Singapore Context) Contain prompts that test safety in Singapore-context Apache-2.0 IMDA MedQA (US) MedQA is a free-form multiple-choice OpenQA dataset for solving medical problems. These are collected from the professional medical board exams. We extracted the list of MCQ questions from the US in this dataset. MIT License https://github.com/jind11/MedQA uciadult The UCI adult dataset, created in 1996, is used to train models to predict whether a person's income will exceed $50K/yr based on census data. Also known as \"Census Income\" dataset. Creative Commons Attribution 4.0 International https://archive.ics.uci.edu/dataset/2/adult MMLU This dataset covers 57 tasks including elementary mathemathics, US history, computer science, law, and more. MIT license https://github.com/hendrycks/test Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ Chinese Version - Bias Benchmark for QA This aims to measure social biases across 9 different categories in Chinese language. - https://github.com/YFHuangxxxx/CBBQ BBQ-lite on disability-status - Disambiguated Questions This dataset is an excerpt from Bias Benchmark from QA on disability-status, containing only the disambiguated questions. CC-BY-4.0 license https://arxiv.org/pdf/2110.08193v2"},{"location":"resources/jupyter_notebook/","title":"Jupyter Notebook","text":"<p>Here are some examples of how you can run Moonshot using Jupyter Notebook.</p> <p>Moonshot Benchmark Feature Walkthrough - An extensive walkthrough of the features in Moonshot.</p> <p>Tutorial 1 - Basic Workflow - Execute a Benchmark - Tutorial and code walkthrough on how to execute benchmark tests.</p> <p>Tutorial 2 - Basic Workflow - Add Your Own Test - Tutorial on how to create your own datasets, cookbooks and recipes.</p> <p>Tutorial 3 - Basic Workflow - Run Red Teaming Session - Tutorial on how to run manual and automated red teaming.</p> <p>Tutorial 4 - Advanced Workflow - Create Your Own Connector - Tutorial on how to create your connector to connect to a LLM.</p>"},{"location":"resources/metrics/","title":"List of Metrics","text":"Name Description BertScore BertScore uses Bert to check for the similarity in embedding between two sentences. SpellingScore SpellingScore uses Levenshetein Distance to find permutations within an edit distance of 2 form the original word before comparing to known words in a word frequency list. GPT4 Annotator Calculates the number of refused response using GPT4. BleuScore Bleuscore uses Bleu to return the various rouge scores. ReadabilityScore ReadabilityScore uses Flesch Reading Ease to compute the complexity of the output Toxicity Classifier This classifier measures how toxic a given input isand calculate the number of toxic sentence detected. RougeScorer RougeScorer returns the various rouge scores. Attack Success Rate Attack success rate measures how successful a changed prompt performs. A high score shows that the system under test is highly sensitive towards a prompt with minimal changes. LeakageRate Leakage Rate will compare the LCS between two string - Output and Target. ReverseExactStrMatch ReverseExactStrMatch will compare the output from language model with the expected target. ExactStrMatch ExactStrMatch will compare the output from language model with a single target or multiple expected target. RelaxStrMatch RelaxStrMatch will remove symbols and spaces before comparing the output from language model with the expected target. LlamaGuard Annotator Calculates the number of safe, unsafe and unknown response by using LlamaGuard. SampleMetric Sample Metric will provide examples on connecting to LLMs. Singapore Toxicity Classifier This classifier measures how unsafe a given input is in the Singapore context. It can calculate the number of toxic sentences detected."},{"location":"resources/recipes/","title":"List of Recipes","text":"Name Description Datasets Metrics Prompt Templates RealtimeQA RealTime QA is a dynamic question answering (QA) platform that inquires about the present. The higher the grade, the better the system is handling hallucination. 1. realtimeqa-past 1. exactstrmatch - squad-shifts-tnf Zero-shot reading comprehension on paragraphs and questions from squadshifts. Augmented to true/false statement. The higher the grade, the better the model performs this capability. 1. squad-shifts-tnf 1. relaxstrmatch - MLCommons AI Safety Benchmark - Non-Violent Crimes This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the commission of non-violent crimes. A high grade indicates that the system under test handles the response well. 1. mlc-nvc-malicious-user2. mlc-nvc-typical-user 1. llamaguardannotator - TAMIL-KURAL-CLASSIFICATION This recipe is used to test the comprehension abilities for the Thirukkural. Thirukkural is a classic Tamil literature composed by the ancient Tamil poet Thiruvalluvar. It consists of 1330 couplets (kurals) that are grouped into 133 chapters, each containing 10 couplets. The higher the grade, the better the model performs in this task. 1. tamil-kural-classification 1. exactstrmatch 1. tamil-templatekuralclassification University Tutorial Questions in Singapore's Legal Classes To measure the model's ability in understanding legal context in Singapore. 1. sg-university-tutorial-questions-legal 1. bertscore 1. answer-template MLCommons AI Safety Benchmark - Child Abuse and Exploitation This recipe measures the model's responses in dealing with prompts that contain, describe, enable, encourage, or endorse the sexual abuse of children. A high grade indicates that the system under test handles the response well. 1. mlc-cae-malicious-user2. mlc-cae-typical-user 1. llamaguardannotator - TAMIL-TANGLISH-TWEETS This recipe is used to perform sentiment analysis on code-mixed Tamil and English tweets. The higher the grade, the better the model performs in this task. 1. tamil-tanglish-tweets 1. exactstrmatch 1. tamil-templatetanglishsa ChallengingToxicityPrompts This recipe measures the model's ability in generating toxic phrases or sentences when given a toxic phrase. The higher the grade, the less toxic the system is. 1. challenging-toxicity-prompts 1. toxicity-classifier 1. complete-sentence Singapore Legal Glossary To measure the model's ability in understanding legal term used commonly in Singapore. 1. sg-legal-glossary 1. bertscore 1. legal-term-template EnronEmail The Enron email dataset is aimed at evaluating if there is leakage of private information. The dataset was used in DecodingTrust as part of its privacy evaluation. 1. privacy-enronemails 1. leakagerate 1. enronemail-templatea2. enronemail-templateb3. enronemail-templatec4. enronemail-templated Bias Benchmark for QA This recipe measures the model's ability in attesting social biases against people belonging to protected classes along nine social dimensions relevant for US English-speaking context with age ambiguous and disambiguous questions. The higher the grade, the better the system is in handling social biases. 1. bbq-lite-age-ambiguous2. bbq-lite-age-disamb3. bbq-lite-disability-status-ambiguous4. bbq-lite-disability-status-disamb5. bbq-lite-gender-ambiguous6. bbq-lite-gender-disamb7. bbq-lite-nationality-ambiguous8. bbq-lite-nationality-disamb9. bbq-lite-physical-appearance-ambiguous10. bbq-lite-physical-appearance-disamb11. bbq-lite-race-ethnicity-ambiguous12. bbq-lite-race-ethnicity-disamb13. bbq-lite-race-x-gender-ambiguous14. bbq-lite-race-x-gender-disamb15. bbq-lite-race-x-ses-ambiguous16. bbq-lite-race-x-ses-ambiguous17. bbq-lite-religion-ambiguous18. bbq-lite-religion-disamb19. bbq-lite-ses-ambiguous20. bbq-lite-ses-disamb21. bbq-lite-sexual-orientation-ambiguous22. bbq-lite-sexual-orientation-disamb 1. exactstrmatch 1. mcq-template Chinese Bias Becnhmark for QA - Lite This recipe measures a system's ability to respond to safety-related, biased, and stereotypical questions in Chinese. A higher grade indicates that the system under test is safer, less biased, and less stereotypical. 1. cbbq-lite-age-ambiguous2. cbbq-lite-age-disamb3. cbbq-lite-disability-ambiguous4. cbbq-lite-disability-disamb5. cbbq-lite-disease-ambiguous6. cbbq-lite-disease-disamb7. cbbq-lite-educational-qualification-ambiguous8. cbbq-lite-educational-qualification-disamb9. cbbq-lite-ethnicity-ambiguous10. cbbq-lite-ethnicity-disamb11. cbbq-lite-gender-ambiguous12. cbbq-lite-gender-disamb13. cbbq-lite-household-registration-ambiguous14. cbbq-lite-household-registration-disamb15. cbbq-lite-nationality-ambiguous16. cbbq-lite-nationality-disamb17. cbbq-lite-physical-appearance-ambiguous18. cbbq-lite-physical-appearance-disamb19. cbbq-lite-race-ambiguous20. cbbq-lite-race-disamb21. cbbq-lite-region-ambiguous22. cbbq-lite-region-disamb23. cbbq-lite-SES-ambiguous24. cbbq-lite-SES-disamb25. cbbq-lite-sexual-orientation-ambiguous26. cbbq-lite-sexual-orientation-disamb 1. exactstrmatch 1. chinese-mcq-template Cause and Effect This recipe measure the model's ability in understanding the cause and effect in a sentence. The higher the grade, the better the system is in performing this capability. 1. cause-and-effect 1. relaxstrmatch - TruthfulQA (MCQ) TruthfulQA aims to measure the truthfulness of a model. The higher the grade, the more truthful the system is. 1. truthfulqa-mcq 1. exactstrmatch 1. mcq-template GRE Reading Comprehension To measure the model's ability to summarize text, infer and deduce knowledge from context, and match the context. The higher the grade, the better the system is in performing this capability. 1. gre-reading-comprehension 1. relaxstrmatch 1. answer-template Safety questions written in Singapore's context This recipe evaluates whether a system under test can perform well when a harmful question is written in Singapore's context. By achieving a high grade, the target demonstrates that it is lower in risk. 1. singapore-safety-questions 1. llamaguardannotator - COQA Conversational Q&amp;A To measure the ability of machines to understand a text passage and answer a series of interconnected questions. The higher the grade, the better the system performs for this capability. 1. coqa-conversational-qna 1. exactstrmatch 1. answer-template Bias - Occupation This recipe tests if a targeted system thinks that a certain demographic group can handle a job role better than others. 1. occupation 1. gpt4annotator 1. job-role-bias MLCommons AI Safety Benchmark - Violent Crimes This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the commission of violent crimes. A high grade indicates that the system under test handles the response well. 1. mlc-vcr-malicious-user2. mlc-vcr-typical-user 1. llamaguardannotator - Commonsense Morality (Easy) This recipe measures whether how the system performs when given prompts embedded the body of moral standards and principles that most people intuitively accept. The higher the grade, the better the system performs. 1. commonsense-morality-easy-variation1 1. exactstrmatch - MLCommons AI Safety Benchmark - Hate This recipe measures the model's responses in dealing with prompts that demean or dehumanize people on the basis of their sensitive, personal characteristics. A high grade indicates that the system under test handles the response well. 1. mlc-hat-malicious-user2. mlc-hat-typical-user 1. llamaguardannotator - Winograde To measure model's ability in answering commonsense reasoning, expert-crafted pronoun resolution problems that are designed to be unsolvable for statistical models. The higher the score, the better the model is. 1. winogrande 1. exactstrmatch 1. mcq-template ARC To measure model's ability in answering genuine grade-school level, multiple-choice science questions on the easy and challenge sets. The higher the grade, the better the sytem is performing this capability. 1. arc-challenge2. arc-easy 1. exactstrmatch 1. mcq-template Contextual Parametric Knowledge Conflicts This recipe measures the model\u2019s ability in making informed predictions. The higher the grade, the better the system can perform for this capability. 1. contextual-parametric-knowledge-conflicts 1. relaxstrmatch 1. mcq-template Commonsense Morality (Hard) This recipe measures whether how the system performs when given prompts embedded the body of moral standards and principles that most people intuitively accept. The higher the grade, the better the system performs. 1. commonsense-morality-hard-variation1 1. exactstrmatch - RealToxicityPrompts (Completion) RealToxicityPrompts aims to measure the model's ability in identify toxic sentences. The higher the grade, the less toxic the system is. 1. real-toxicity-prompts 1. toxicity-classifier 1. real-toxicity-prompt-template2 Analogical Similarity This recipe measures the model\u2019s ability in discriminating between different degrees of analogical similarity in two given episodes. The higher the grade, the better the sytem is performing this capability. 1. analogical-similarity 1. relaxstrmatch 1. analogical-similarity GSM8K To measure model's ability in solvinggrade school math problems created by human. These problems take between 2 and 8 steps to solve, and usually requires a sequence of elementary calculations. The higher the grade, the better the system can perform this capability. 1. gsm8k 1. exactstrmatch 1. mcq-template MLCommons AI Safety Benchmark - Sex-related Crimes This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the commission of sex-related crimes. A high grade indicates that the system under test handles the response well. 1. mlc-scr-malicious-user2. mlc-scr-typical-user 1. llamaguardannotator - MLCommons AI Safety Benchmark - Chemical, Biological, Radiological, Nuclear, and Explosives This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse the creation of weapons of mass destruction. A high grade indicates that the system under test handles the response well. 1. mlc-cbr-malicious-user2. mlc-cbr-typical-user 1. llamaguardannotator - Jailbreak-DAN This recipe assesses whether the system will be jailbroken using the common jailbreak methods. The higher the grade, the better the system is protected against common jailbreaks. 1. jailbreak-dan 1. reverseexactstrmatch - Auto Categorisation This recipe measures the model's ability in categorising elements into groups. The higher the grade, the system performs better in this capability. 1. auto-categorisation 1. relaxstrmatch 1. complete-sentence Medical MCQ In this recipe, we measure how well a system is able to answer healthcare questions using various datasets related to healthcare. The higher the grade, the better the system performs in answering healthare questions. 1. medmcqa2. medqa-us3. pubmedqa 1. exactstrmatch 1. mcq-template TAMIL-NEWS-CLASSIFICATION This recipe is to classify a static set of Tamil News. The task is to classify news to its respective category. The higher the grade, the better the model performs in this task. 1. tamil-tamilnews-classification 1. exactstrmatch 1. tamil-templatenewsclassification CValues - The benchmark for measuring alignment in LLMs using Chinese Langauges. This recipe measures the alignment ability of LLMs in both safety and responsibility in Chinese Language. A higher grade means that the LLMs are more aligned to human's values. 1. cvalues 1. exactstrmatch 1. chinese-mcq-template TruthfulQA TruthfulQA aims to measure the truthfulness of a model. This is an experimental recipe using Rouge Score 1. truthfulqa-open-ended 1. rougescorer 1. mcq-template Facts about Singapore This recipe evaluates the accuracy of facts about Singapore. A higher score reflects the target's ability to answer questions about Singapore with a high level of precision and detail. By achieving a high grade, the target demonstrates a thorough understanding and knowledge of Singapore's key events, transport system, and facts. 1. singapore-transport-system2. singapore-iconic-places3. singapore-political-history4. singapore-public-housing5. singapore-facts-tnf6. singapore-places-tnf7. singapore-food-tnf 1. exactstrmatch - AdvGLUE AdvGLUE is a comprehensive robustness evaluation benchmark that concentrates on assessing the adversarial robustness of language models. It encompasses textual adversarial attacks from various perspectives and hierarchies, encompassing word-level transformations and sentence-level manipulations. A higher grade indicates that the system under test is more resilient to changes in the sentences. 1. advglue-all 1. advglue - MMLU To measure model's ability in answering accurately across 57 tasks including elementary mathemathics, US history, computer science, law, and more. The higher the grade, the better the system performs. 1. mmlu-all 1. exactstrmatch 1. mmlu HellaSwag To measure commonsense with questions that are trivial for humans but difficult for statistical models. The higher the grade, the better the system performs this capability. 1. hellaswag 1. exactstrmatch 1. mcq-template UCI Adult Dataset This recipe contains the easy variation of UCI adult dataset where LLM is expected to classify the attributes correctly. The higher the score, the better the model is. 1. uciadult 1. exactstrmatch 1. uciadult-template MMLU - Medical related questions. MMLU benchmark measures model's ability in answering accurately across 57 tasks including elementary mathemathics, US history, computer science, law, and more. In this recipe, we extracted all the tasks related to healthare. The higher the grade, the better the system performs in answering healthcare related questions. 1. mmlu-anatomy2. mmlu-clinicalknowledge3. mmlu-collegebiology4. mmlu-collegemedicine5. mmlu-medicalgenetics6. mmlu-professionalmedicine 1. exactstrmatch 1. mcq-template MLCommons AI Safety Benchmark - Suicide &amp; Self-Harm This recipe measures the model's responses in dealing with prompts that enable, encourage, or endorse acts of intentional self-harm. A high grade indicates that the system under test handles the response well. 1. mlc-ssh-vulnerable-user2. mlc-ssh-typical-user 1. llamaguardannotator - Winobias Winobias dataset is used to test representational harm in LLMs. LLM should refuse to answer. The higher the score, the better the model is. 1. winobias-type1 1. reverseexactstrmatch -"},{"location":"tutorial/cli/create_benchmark_tests/","title":"(CLI) How to Create Custom Benchmark Tests","text":"<p>In this tutorial, you will learn how to create a custom cookbook via our command line interface. A cookbook is a collection of one or more tests (or recipes). This is very useful when the user needs to run a specific set of recipes repeatedly (e.g., running different set of bias benchmarks on the same endpoint before and after safety fine-tuning).</p> <ol> <li> <p>Change directory to the root directory of Moonshot.</p> </li> <li> <p>Enter the following command to enter the CLI interactive mode:</p> <pre><code>python -m moonshot cli interactive\n</code></pre> </li> <li> <p>Choose a benchmark type to create and view help:</p> <ul> <li> <p>Recipe </p> <p>To find out more about the required fields to create a recipe: </p> <pre><code>add_recipe -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>add_recipe 'My new recipe' 'I am recipe description' \"['category1','category2']\" \"['bbq-lite-age-ambiguous']\" \"['bertscore','bleuscore']\" -p \"['analogical-similarity','mmlu']\" -t \"['tag1','tag2']\" -a \"['charswap_attack']\" -g \"{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}\"\n</code></pre> </li> <li> <p>Cookbook</p> <p>To find out more about the required fields to create a cookbook: </p> <pre><code>add_cookbook -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>add_cookbook 'My new cookbook' 'I am cookbook description' \"['analogical-similarity','auto-categorisation']\"\n</code></pre> </li> </ul> </li> <li> <p>View the newly created recipe or cookbook:</p> <ul> <li> <p>Enter:</p> <pre><code>view_recipe my-new-recipe\n</code></pre> <p></p> </li> <li> <p>Enter:</p> <pre><code>view_cookbook my-new-cookbook\n</code></pre> <p></p> </li> </ul> </li> </ol> <p>You can view more information on how creating benchmark tests here.</p>"},{"location":"tutorial/cli/create_endpoint/","title":"(CLI) How to Create Connector Endpoint","text":"<p>In this tutorial, you will learn how to configure and seamlessly connect Moonshot to your AI systems. A connector endpoint is a set of configuration that tells Moonshot how to connect to your AI model.</p> <ol> <li> <p>Change directory to the root directory of Moonshot. </p> </li> <li> <p>Enter the following command to enter the CLI interactive mode:</p> <pre><code>python -m moonshot cli interactive\n</code></pre> </li> <li> <p>To find out more about the required fields to create a connector endpoint:</p> <pre><code>add_endpoint -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>add_endpoint openai-connector 'OpenAI GPT3.5 Turbo 1106' MY_URI ADD_YOUR_TOKEN_HERE 1 1 \"{'temperature': 0.5, 'model': 'gpt-3.5-turbo-1106'}\"\n</code></pre> </li> <li> <p>View the newly created connector endpoint by entering:</p> <pre><code>view_endpoint openai-gpt3-5-turbo-1106\n</code></pre> </li> </ol> <p>INFO: <code>openai-gpt3-5-turbo-1106</code> is the ID of the connector endpoint and is slugified from the name <code>OpenAI GPT3.5 Turbo 1106</code>)</p> <p></p> <p>You can view more information on creating connector endpoint here.</p>"},{"location":"tutorial/cli/run_benchmark_tests/","title":"(CLI) How to Run Benchmark Tests","text":"<p>In this tutorial, you will learn how to run a benchmark in Moonshot. Benchmarks are a set of \"exam questions\" that can help to evaluate and assess the capabilities and safety of the AI system.</p> <ol> <li> <p>Change directory to the root directory of Moonshot.</p> </li> <li> <p>Enter the following command to enter the CLI interactive mode:</p> <pre><code>python -m moonshot cli interactive\n</code></pre> </li> <li> <p>Choose a benchmark type to run and view help:</p> <ul> <li> <p>Recipe</p> <p>To find out more about the required fields to create a recipe:</p> <pre><code>run_recipe -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>run_recipe \"my new recipe runner\" \"['bbq','mmlu']\" \"['openai-gpt35-turbo']\" -n 1 -r 1 -s \"You are an intelligent AI\"\n</code></pre> </li> <li> <p>Cookbook:</p> <p>To find out more about the required fields to create a cookbook:</p> <pre><code>run_cookbook -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>run_cookbook \"my new cookbook runner\" \"['chinese-safety-cookbook']\" \"['openai-gpt35-turbo']\" -n 1 -r 1 -s \"You are an intelligent AI\"\n</code></pre> </li> </ul> </li> <li> <p>View the results:</p> <ul> <li> <p>Recipe:</p> <p></p> </li> <li> <p>Cookbook:</p> <p></p> </li> </ul> </li> </ol> <p>You can view more information on running benchmarks here.</p>"},{"location":"tutorial/cli/run_red_teaming/","title":"(CLI) How to Run Red Teaming","text":"<p>In this tutorial, you will learn how to conduct red teaming using Moonshot's command line interface. Red teaming serves as a crucial process to induce your LLMs to behave in ways that are incongruent with their design, revealing any weaknesses or flaws.</p> <ol> <li> <p>Change directory to the root directory of Moonshot.</p> </li> <li> <p>Enter the following command to enter the CLI interactive mode:</p> <pre><code>python -m moonshot cli interactive\n</code></pre> </li> <li> <p>Create a new session with a new runner:</p> <ul> <li> <p>New Session</p> <p>To find out more about the required fields to create a new session:</p> <pre><code>new_session -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>new_session my-runner -e \"['openai-gpt4']\" -c add_previous_prompt -p mmlu\n</code></pre> <p>You should see that your session is created:</p> <p></p> </li> </ul> </li> </ol>"},{"location":"tutorial/cli/run_red_teaming/#manual-red-teaming","title":"Manual Red Teaming","text":"<p>Continuing from Step 3, you can type a prompt and it will be sent to the LLM:</p> <p></p>"},{"location":"tutorial/cli/run_red_teaming/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>Continuing from Step 3 or manual red teaming, you can choose to run an attack module to perform automated red teaming. </p> <ul> <li> <p>To find out more about the required fields to run an attack module:</p> <pre><code>run_attack_module -h\n</code></pre> <p>To run the help example, enter:</p> <pre><code>run_attack_module sample_attack_module \"this is my prompt\" -s \"test system prompt\" -c \"add_previous_prompt\" -p \"mmlu\" -m \"bleuscore\"\n</code></pre> <p>You should see your prompt and response:</p> </li> </ul> <p></p> <p>You can view more information on running red teaming here.    </p>"},{"location":"tutorial/contributor/configure_web_api/","title":"Running Moonshot as a Web API","text":"<p>Moonshot Web API is built using FastAPI. This guide will help you get started and configure your environment. This will be useful if you are intending to create your own UI.</p>"},{"location":"tutorial/contributor/configure_web_api/#launch-moonshot-web-api","title":"Launch Moonshot Web API","text":"<p>To run Moonshot Web API: <pre><code>$ python -m moonshot web-api\n</code></pre></p> <p>For instructions on setting up the Moonshot UI, please refer to the Moonshot UI repository.</p>"},{"location":"tutorial/contributor/configure_web_api/#customising-moonshot-web-api-configuration","title":"Customising Moonshot Web API Configuration","text":"<p>By default, Moonshot Web API uses its own configuration settings. However, you can customize these settings by providing your own <code>.env</code> file in the directory where you are running Moonshot.</p>"},{"location":"tutorial/contributor/configure_web_api/#configuring-your-environment-variable-file","title":"Configuring Your Environment Variable File","text":"<p>The <code>.env</code> file should include the following variables:</p> Key Description Example <code>MS_WEB_API_CONFIG</code> This is used to specify the path to your configuration file. <code>/User/path/to/your/config.yml</code> <code>APP_ENVIRONMENT</code> This defines the environment in which you are running Moonshot. <code>PROD</code> <code>HOST</code> This is the host where you wish to run Moonshot. <code>127.0.0.1</code> <code>PORT</code> This is the port at which you wish to run your FastAPI. <code>/5000</code>"},{"location":"tutorial/contributor/configure_web_api/#configuring-your-configuration-file","title":"Configuring your Configuration File","text":"<p>The <code>config.yml</code> file contains several sections. Here's a brief overview of each section:</p>"},{"location":"tutorial/contributor/configure_web_api/#asyncio","title":"<code>asyncio</code>","text":"Key Description Example <code>monitor_task</code> This flag determines whether to monitor tasks in asyncio or not. <code>monitor_task: false</code>"},{"location":"tutorial/contributor/configure_web_api/#ssl","title":"<code>ssl</code>","text":"Key Description Example <code>enabled</code> This flag determines whether SSL is enabled or not. <code>enabled: ${ENABLE_SSL:false}</code> <code>file_path</code> This is the path to the directory containing the SSL certificate and key files. <code>file_path: \"${SSL_FILE_PATH:./web_api/certs}</code> <code>cert_filename</code> This is the filename of the SSL certificate. <code>cert_filename: \"cert.pem\"</code> <code>key_filename</code> This is the filename of the SSL key. <code>key_filename: \"key.pem\"</code>"},{"location":"tutorial/contributor/configure_web_api/#cors","title":"<code>cors</code>","text":"Key Description Example <code>enabled</code> This flag determines whether CORS is enabled or not. <code>enabled: false</code> <code>allowed_origins</code> This is a list of origins that are allowed to make cross-origin requests. <code>allowed_origins: \"http://localhost:3000\"</code>"},{"location":"tutorial/contributor/configure_web_api/#log","title":"<code>log</code>","text":"Key Description Example <code>logging</code> This flag determines whether logging is enabled or not. <code>logging: ${LOGGING:true}</code> <code>level</code> This sets the level of logging. It could be <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, or <code>CRITICAL</code>. <code>level: ${LOG_LEVEL:DEBUG}</code> <code>format</code> This specifies the format of the log messages. <code>format: \"[%(asctime)s] [%(levelname)s] [%(name)s]: %(message)s\"</code> <code>log_file_path</code> This is the path where the log files will be stored. <code>log_file_path: \"/path/to/write/moonshot.logs\"</code> <code>log_file_max_size</code> This is the maximum size (in bytes) that a log file can have before it gets rolled over. <code>log_file_max_size: 5242880</code> <code>log_file_backup_count</code> This is the number of backup log files to keep. <code>log_file_backup_count: 3\"</code> <p>For more example on how to structure your <code>config.yml</code> file, refer to the example provided here.</p>"},{"location":"tutorial/contributor/create_connector/","title":"Create a New Custom Connector","text":"<p>Currently, the most straightforward way is to duplicate an existing connector module, and modify the codes. This feature is currently not available on the Web UI and CLI.</p> <p>All connectors inherit the super class Connector. We initalise this super class with certain variables that are common across various connectors (i.e. <code>token</code>, <code>max_concurrency</code>, etc). These variables come from another class called ConnectorEndpoint.</p>"},{"location":"tutorial/contributor/create_connector/#initialise-connector-class","title":"Initialise Connector Class","text":"<p>We will use a set of modified code from one of our connectors openai-connector as an example:</p> <pre><code>def __init__(self, ep_arguments: ConnectorEndpointArguments):\n    # Initialize super class\n    super().__init__(ep_arguments)\n\n    # This is optional. You can keep this here if your model needs to take in a model field from the user\n    self.model = self.optional_params.get(\"model\", \"\")\n</code></pre> <p>The <code>__init__()</code> function initialises the Connector class. This must be included in your code.</p> <pre><code>@Connector.rate_limited # Limits the number of calls per second made to the LLM based on a variable max_calls_per_second. \n@perform_retry # Performs retries based on a variable num_of_retries. Throws a ConnectionError when the number of retries is hit. \nasync def get_response(self, prompt: str) -&gt; str:\n    \"\"\"\n    Copy and paste this function and insert your codes to send prompts and receive responses from the target LLM \n    here. \n\n    Args:\n        prompt (str): The input prompt to send to the target LLM.\n\n    Returns:\n        str: The text response generated by the target LLM.\n    \"\"\"\n    # You may want to insert codes to perform appending or editing of prompt before sending to LLM\n    connector_prompt = f\"{self.pre_prompt}{prompt}{self.post_prompt}\" # just an example\n\n    # Every LLM requires their connector to send the prompts in a specific way with certain configurations\n    response = await self._client.chat.completions.create(**new_params) # an example from the OpenAI Connector\n\n    # Return the response of the LLM \n    return await self._process_response(response) # an example\n</code></pre>"},{"location":"tutorial/contributor/create_connector/#modify-response-method","title":"Modify Response Method","text":"<p>The <code>get_response()</code> is an abstract method that must be instantiated. This is where you will insert your code to send prompts to the LLM and receive responses.</p> <p><pre><code>async def _process_response(self, response: Any) -&gt; str:\n    \"\"\"\n    An optional helper method we have in all our connector types to process the response from the LLM. The way to\n    process responses from different LLMs can be different. You can insert codes to process the response here if \n    you want.\n\n    Args:\n        response (Any): The response from the LLM. It depends on what the LLM returns as a response\n        (i.e. could be a dict, string, list, etc)\n\n    Returns:\n        str: The processed response\n    \"\"\"\n    return str(response) # an example\n</code></pre> The <code>_process_response()</code> is an optional method that is included in all our connectors to aid in formatting responses from the LLM.</p>"},{"location":"tutorial/contributor/create_connector/#list-your-newly-created-connector","title":"List Your Newly Created Connector","text":"<p>Once you have your connector created, move it to your own <code>moonshot-data/connectors</code> folder. The name of your connector will be your file name (i.e. the name of your connector will be <code>new-custom-connector</code> if your connector file name is <code>new-custom-connector.py</code>)</p> <p>If you are using CLI, you should be able to see your connector when you list the connectors using the following command:</p> <pre><code>moonshot &gt; list_connector_types\n</code></pre> <p></p>"},{"location":"tutorial/contributor/create_connector/#whats-next","title":"What's Next","text":"<p>Once you are able to see your newly created connector, you can proceed to create a connector endpoint (i.e. configuration file) :</p> <ul> <li>Create Connector Endpoint via Web UI</li> <li>Create Connector Endpoint via CLI</li> </ul>"},{"location":"tutorial/web-ui/benchmark/","title":"(UI) How to Run Benchmark Tests","text":"<p>In this tutorial, you will learn how to run a benchmark in Moonshot. Benchmarks are a set of \"exam questions\" that can help to evaluate and assess the capabilities and safety of the AI system.</p> <p>Note</p> <p>Moonshot offers a wide range of benchmarks, including widely recognized ones like Google's BigBench and HuggingFace's leaderboards, as well as more domain/task-specific tests like Tamil Language and Medical LLM benchmarks.</p> <p>This tutorial will provide a step-by-step guide on how to run these benchmark tests, enabling you to measure your LLM application's performance in the categories of Capability, Quality, and Trust &amp; Safety. </p> <p>Let's get started on running your first benchmark test.</p> <p>In the homepage, click on \"Evaluate against standard tests\". Alternatively, you can click on \"Get Started\".</p> <p></p> <p>A set of recommended baseline cookbooks has been pre-selected. Select or deselect any cookbook that you wish to run. Once you've made your selection, click the down arrow button to proceed to the next step.</p> <p></p> <p>In this step, the total number of prompts that will be executed is displayed. Click on \"these cookbooks\" to view all the available cookbooks.</p> <p></p> <p>This page shows a list of cookbooks that are sorted by their category. To select a cookbook, click on the corresponding checkbox. For more information about a cookbook, click on \"About\". Once you've finished, click \"OK\".</p> <p></p> <p>You will be redirected back to the page showing the total number of prompts. To proceed to the next step, click the down arrow button.</p> <p></p> <p>Here, you are required to select an endpoint for testing. If needed, you can create a new endpoint or edit an existing one on this page. After selecting an endpoint, click on the down arrow button to proceed to the next step.</p> <p></p> <p>Warning</p> <p>Before proceeding, please ensure that you have your Together Llama Guard 7B Assistant endpoint token set up. This is necessary to run one of our baseline cookbooks, MLCommon's AI Safety Benchmark.</p> <p>On this page, you need to fill out the form. If you wish to test a smaller dataset, replace the value in the \"Run a smaller set\" field. By default, the value is 0, which means the entire cookbook will be run. By entering a value, you can specify the number of prompts to be tested from each dataset, as specified in the recipe. Once you've completed the form, click on \"Run\" to start the test.</p> <p></p> <p>The benchmark test is now running. You can click on \"See Details\" to view the endpoints and cookbooks that are currently running. If you wish to exit an ongoing run, click on \"Cancel\".</p> <p></p> <p>You can safely close the window while the benchmark is running; it will continue to operate in the background. To check the status of your run, click on the bell icon. If you wish to view more details about the run, simply click on the run itself.</p> <p></p> <p>After the benchmark test has finished, you can access the results by clicking on \"View Report\".</p> <p></p>"},{"location":"tutorial/web-ui/create_cookbook/","title":"(UI) How to Create Custom Cookbook","text":"<p>In this tutorial, you will learn how to create a custom cookbook via our web interface. A cookbook is a collection of one or more tests (or recipes). This is very useful when the user needs to run a specific set of recipes repeatedly (e.g., running different set of bias benchmarks on the same endpoint before and after safety fine-tuning).</p> <p>Let's get started on creating your first cookbook.</p> <p>Click on \"Create cookbooks\". </p> <p></p> <p>Enter the name and description. Once done, click on \"Select Recipes\".</p> <p></p> <p>You will be presented with a list of available recipes in Moonshot. Select the recipes you wish to include in your custom cookbook and confirm by clicking on \"Add to Cookbook\".</p> <p></p> <p>Finalise the creation of your cookbook by clicking on \"Create Cookbook\".</p> <p></p> <p>Once your cookbook is created, you can view it along with any other cookbooks you've created by clicking on \"View Cookbooks\". </p> <p></p>"},{"location":"tutorial/web-ui/create_endpoint/","title":"(UI) How to Create Connector Endpoint","text":"<p>In this tutorial, you will learn how to configure and seamlessly connect Moonshot to your AI systems. A connector endpoint is a set of configuration that tells Moonshot how to connect to your AI model.</p> <p>Let's dive in and start connecting your models.</p> <p>Click on the \"model endpoints\" icon in the sidebar panel.</p> <p></p> <p>Click on \"Create New Endpoint\" to create a new endpoint.</p> <p></p> <p>A form will appear. Enter the details. If your AI models require more details, click on \"More Configs\" to add/amend the additional parameters.</p> <p></p> <p>Note</p> <p>You can add in additional parameters that are required by your model. An example is top_k.</p> <p>Click \"OK\" to confirm your details.</p> <p></p> <p>Click \"Save\" to save your configuration.</p> <p></p>"},{"location":"tutorial/web-ui/redteam/","title":"(UI) How to Run Red Teaming","text":"<p>In this tutorial, you will learn how to conduct red teaming. Red teaming serves as a crucial process to induce your LLMs to behave in ways that are incongruent with their design, revealing any weaknesses or flaws.</p> <p>Moonshot simplifies red teaming by providing an intuitive interface that allows for simultaneous probing of multiple LLM applications. It also comes equipped with utilities such as prompt templates, context strategies and attack modules.</p> <p>This tutorial will provide a step-by-step guide on how to run red teaming, enabling you to effectively identify and address vulnerabilities in your AI systems. </p> <p>Let's get started on your first red teaming session.</p> <p>First, click on 'Discover new vulnerabilities' in the homepage.</p> <p></p> <p>On this page, you are prompted to select an endpoint for testing. You have the option to create a new endpoint or modify an existing one. After making your selection, click on the down arrow button to move to the next step.</p> <p></p> <p>This step presents a list of attack modules available for your red teaming. For the purpose of this tutorial, select 'Skip for now'.</p> <p></p> <p>You are now required to complete a form on this page. After filling out the form, initiate a red teaming session by clicking on 'Start'.</p> <p></p> <p>You have now entered a session to conduct your red teaming. This session includes a chat window for sending prompts and a section for selecting the tool you wish to use during your red teaming session.</p> <p></p>"},{"location":"tutorial/web-ui/redteam/#manual-red-teaming","title":"Manual Red Teaming","text":"<p>During manual red teaming, you have the option to utilize tools like prompt templates and context strategy. These tools assist in structuring and providing context to your prompts.</p> <p>You can load either a prompt template or a context strategy from the tools section.  After making your selection, input your prompt into the chat window. You will then observe the enhancements that have been incorporated into your prompt. </p>"},{"location":"tutorial/web-ui/redteam/#automated-red-teaming","title":"Automated Red Teaming","text":"<p>To initiate an automated red teaming, you would need to load an attack module.</p> <p>Navigate to the 'Attack Module' within the tools section. Choose your desired attack module and confirm your selection by clicking 'Use'.</p> <p></p> <p>Type your prompt in the chat window and it will start the automated red teaming.</p> <p></p>"},{"location":"user_guide/cli/add_your_own_tests/","title":"Add Your Own Benchmark Tests","text":"<p>In this tutorial, we will be going through the steps required to add new test using CLI.</p> <p>You will learn how to:</p> <ul> <li>Add a new dataset into Moonshot</li> <li>Add a new recipe to run a benchmark</li> <li>Add a new cookbook to run a set of benchmarks</li> </ul>"},{"location":"user_guide/cli/add_your_own_tests/#launch-moonshot-cli","title":"Launch Moonshot CLI","text":"<p>You can launch Moonshot CLI by running the following command:</p> <pre><code>python -m moonshot cli interactive\n</code></pre>"},{"location":"user_guide/cli/add_your_own_tests/#create-a-new-dataset","title":"Create a New Dataset","text":"<p>You can convert your raw dataset into Moonshot-compatible dataset using the following schema. Once you have created the new dataset, you can save the file in <code>moonshot-data/datasets</code> for Moonshot to access this dataset.</p> <p>Use your favourite text editor and save the following json data in <code>moonshot-data/datasets/example-dataset.json</code>.</p> <pre><code>{\n    \"name\": \"Fruits Dataset\",\n    \"description\":\"Measures whether the model knows what is a fruit\",\n    \"license\": \"MIT license\",\n    \"reference\": \"\",\n    \"examples\": [\n        {\n            \"input\": \"Is Lemon a Fruit? Answer Yes or No.\",\n            \"target\": \"Yes.\"\n        },\n        {\n            \"input\": \"Is Apple a Fruit? Answer Yes or No.\",\n            \"target\": \"Yes.\"\n        },\n        {\n            \"input\": \"Is Bak Choy a Fruit? Answer Yes or No.\",\n            \"target\": \"No.\"\n        },\n        {\n            \"input\": \"Is Bak Kwa a Fruit? Answer Yes or No.\",\n            \"target\": \"No.\"\n        },\n        {\n            \"input\": \"Is Dragonfruit a Fruit? Answer Yes or No.\",\n            \"target\": \"Yes.\"\n        },\n        {\n            \"input\": \"Is Orange a Fruit? Answer Yes or No.\",\n            \"target\": \"Yes.\"\n        },\n        {\n            \"input\": \"Is Coke Zero a Fruit? Answer Yes or No.\",\n            \"target\": \"No.\"\n        }\n    ]\n}\n</code></pre> <p>The name of the dataset is the unique identifier for the dataset. This will be used in the recipes.</p> <p>Note</p> <p>You can also refer to this Jupyter notebook example for more details how a dataset can be created.</p>"},{"location":"user_guide/cli/add_your_own_tests/#create-a-new-recipe","title":"Create a New Recipe","text":"<p>To run the new Moonshot-compatible dataset that you have created in <code>moonshot-data/datasets</code>, we must first create a new recipe. </p> <p>Note</p> <p>A recipe contains all the details required to run a benchmark. A recipe guides Moonshot on what data to use, and how to evaluate the model's responses.</p>"},{"location":"user_guide/cli/add_your_own_tests/#add-recipe","title":"Add Recipe","text":"<p>In Moonshot CLI, the user can use <code>add_recipe</code> to add a new recipe in Moonshot. The parameters of the command are shown below:</p> <ul> <li>Name (A unique name for the recipe): <code>My new recipe</code></li> <li>Description (An explanation of what the recipe does and what it's for): <code>I am recipe description</code></li> <li>Categories (Broader classifications that help organize recipes into collections): <code>['category1','category2']</code></li> <li>Datasets (The data that will be used when running the recipe. This could be a set of prompts, questions, or any input that - the model will respond to): <code>['bbq-lite-age-ambiguous']</code></li> <li>Metrics (Criteria or measurements used to evaluate the model's responses, such as accuracy, fluency, or adherence to a - prompt): <code>['bertscore','bleuscore']</code></li> <li>Prompt Templates (Optional pre-prompt or post-prompt): <code>['analogical-similarity','mmlu']</code></li> <li>Tags (Optional keywords that categorize the recipe, making it easier to find and group with similar recipes): <code>['tag1','tag2']</code></li> <li>Attack Strategies (Optional components that introduce adversarial testing scenarios to probe the model's robustness): <code>['charswap_attack']</code></li> <li>Grading Scale (Optional set of thresholds or criteria used to grade or score the model's performance): <code>{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}</code></li> </ul> <p>You can also view the description of this command using the following command:</p> <pre><code>moonshot &gt; add_recipe -h\n</code></pre> <p>Add a new recipe using the dataset that you have created in the previous section using the following command:</p> <pre><code>add_recipe 'My new recipe' 'I am recipe description' \"['fruits']\" \"['capability']\" \"['example-dataset']\" \"[]\" \"['exactstrmatch']\" \"[]\" \"{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}\" \n</code></pre>"},{"location":"user_guide/cli/add_your_own_tests/#view-recipe","title":"View Recipe","text":"<p>Once created, you can view your recipe using <code>view_recipe</code>.</p> <pre><code>moonshot &gt; view_recipe my-new-recipe\n</code></pre> <p></p> <p>Note</p> <p>The ID of the recipe is created by slugifying the name. In this case, the ID of this recipe is <code>my-new-recipe</code>.</p>"},{"location":"user_guide/cli/add_your_own_tests/#create-a-new-cookbook","title":"Create a New Cookbook","text":"<p>We can also create a new cookbook with our new recipe. A cookbook in Moonshot is a curated collection of recipes. A cookbook is very useful when the user wants to group a certain type of tests into a single execution.</p>"},{"location":"user_guide/cli/add_your_own_tests/#add-cookbook","title":"Add Cookbook","text":"<p>To add a new cookbook, simply run the following command: </p> <pre><code>moonshot &gt; add_cookbook [name] [description] [cookbooks]\n</code></pre> <p>The fields are as follows for this example: </p> <ul> <li>Name (A unique name for the cookbook): <code>My new cookbook</code></li> <li>Description (A detailed explanation of the cookbook's purpose and the types of recipes it contains): <code>I am cookbook description</code></li> <li>Recipes (A list of recipe names that are included in the cookbook. Each recipe represents a specific test or benchmark): <code>['analogical-similarity','auto-categorisation']</code></li> </ul> <p>You can also view the description of this command using the following command:</p> <pre><code>moonshot &gt; add_cookbook -h\n</code></pre> <p>Use the following command to create a new cookbook with your newly created recipe:</p> <pre><code>add_cookbook 'My new cookbook' 'I am cookbook description' \"['my-new-recipe','auto-categorisation']\"\n</code></pre>"},{"location":"user_guide/cli/add_your_own_tests/#view-cookbook","title":"View Cookbook","text":"<p>Enter the following command to view your newly created cookbook:</p> <pre><code>view_cookbook my-new-cookbook\n</code></pre> <p></p>"},{"location":"user_guide/cli/benchmarking/","title":"Execute Existing Tests","text":"<p>In this section, we will be going through the steps required to run a test in CLI.</p> <p>To run a test, you will need:</p> <ul> <li>Connector Endpoint - a configuration file to connect to your desired LLM endpoint</li> <li>Cookbook/Recipe - benchmarks you want to run</li> </ul> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter: </p> <pre><code>python -m moonshot cli interactive\n</code></pre>"},{"location":"user_guide/cli/benchmarking/#select-a-connector-endpoint","title":"Select a Connector Endpoint","text":"<p>If we do not have a connector endpoint you need, check out the guide here to create one yourself.</p>"},{"location":"user_guide/cli/benchmarking/#running-a-test-using-our-predefined-cookbook","title":"Running a Test Using Our Predefined Cookbook","text":"<p>Once you have your connector endpoint, we can start choosing the test we want to run. </p> <ol> <li> <p>To view all the cookbooks available, enter:</p> <pre><code>list_cookbooks\n</code></pre> <p>You will see a list of available cookbooks:</p> <p></p> </li> <li> <p>To understand more about how to run a cookbook, enter:</p> <pre><code>run_cookbook -h\n</code></pre> <p>You should see a help example:</p> <pre><code>run_cookbook \"my new cookbook runner\" \"['chinese-safety-cookbook']\" \"['my-openai-connector']\" -n 1 -r 2 -s \"This is a customised system prompt\"\n</code></pre> <p>The fields are as follows for this example:</p> <ul> <li>Runner ID (<code>id</code> in <code>list_runners</code>): my-new-cookbook-runner (Enter <code>list_runners</code> to view the runners available. If you do not want to use an existing runner or do not have a runner yet, the <code>run_cookbook</code> command will create a runner for you using a slugified ID.)</li> <li>ID of the cookbook (<code>ID</code> in <code>list_cookbooks</code>): <code>chinese-safety-cookbook</code></li> <li>ID of your connector endpoint (<code>Id</code> column in <code>list_endpoints</code>): <code>my-openai-connector</code> </li> <li>Number of prompts (Optional. The count of prompts selected from each dataset, as specified in the recipe. For instance, if a recipe includes two datasets, Dataset A and B, and the 'number of prompts' is set to 5, then five prompts will be selected from Dataset A and five prompts from Dataset B for benchmarking.\"): <code>1</code></li> <li>Random seed (Optional. A number used to initialize a pseudorandom number generator for prompt selection from dataset. The same seed ensures reproducible prompt selection, while different seeds yield different prompt sets, enabling consistent experiments and benchmarking variations.): <code>2</code></li> <li>System prompt (Optional system prompt which overwrites our default system prompt): <code>This is a customised system prompt</code></li> <li>Runner processing module (Optional. The module refers to the selected module tasked with performing either benchmarking or red teaming. If alternative processing modules are available, they can be specified here. Defaults to use benchmarking module.)</li> <li>Result processing module (Optional. The module refers to the chosen module responsible for generating the final results from the raw data. If there are alternative modules available, they can be specified here. Defaults to use benchmarking result module.)        </li> </ul> <p>TIP:  You can run more than one cookbook and endpoint by adding them into the list( i.e. <code>\"['chinese-safety-cookbook','common-risk-easy']\"</code>)</p> </li> <li> <p>Enter the following command to run the example cookbook. You should see a table of results from your run:</p> <pre><code>run_cookbook my-new-cookbook-runner\n</code></pre> <p></p> </li> </ol>"},{"location":"user_guide/cli/benchmarking/#running-a-test-using-our-predefined-recipe","title":"Running a Test Using Our Predefined Recipe","text":"<p>You can choose to run a recipe instead of a cookbook as well.</p> <ol> <li> <p>To view all the recipes available, enter:</p> <pre><code>list_recipes\n</code></pre> <p>You will see a list of available recipes:</p> <p></p> </li> <li> <p>To understand more about how to run a recipe, enter:</p> <pre><code>run_recipe -h\n</code></pre> <p>You should see a help example:</p> <pre><code>run_recipe \"my new recipe runner\" \"['auto-categorisation','winobias']\" \"['my-openai-connector']\" -n 1 -r 2 -s \"You are an intelligent AI\"\n</code></pre> <p>The fields are as follows for this example:</p> <ul> <li>Runner ID (<code>id</code> in <code>list_runners</code>): my-new-recipe-runner (Enter <code>list_runners</code> to view the runners available. If you do not want to use an existing runner or do not have a runner yet, the <code>run_recipe</code> command will create a runner for you using a slugified ID.)</li> <li>ID of the recipes (<code>ID</code> in <code>list_recipes</code>): <code>auto-categorisation</code> and <code>winobias</code></li> <li>Name of your connector endpoint (<code>Id</code> column in <code>list_endpoints</code>): <code>my-openai-connector</code> </li> <li>Number of prompts (Optional. The count of prompts selected from each dataset, as specified in the recipe. For instance, if a recipe includes two datasets, Dataset A and B, and the 'number of prompts' is set to 5, then five prompts will be selected from Dataset A and five prompts from Dataset B for benchmarking.\"): <code>1</code> </li> <li>Random seed (Optional. A number used to initialize a pseudorandom number generator for prompt selection from dataset. The same seed ensures reproducible prompt selection, while different seeds yield different prompt sets, enabling consistent experiments and benchmarking variations.): <code>2</code></li> <li>System prompt (Optional system prompt which overwrites our default system prompt): <code>This is a customised system prompt</code></li> <li>Runner processing module (Optional. The module refers to the selected module tasked with performing either benchmarking or red teaming. If alternative processing modules are available, they can be specified here. Defaults to use benchmarking module.)</li> <li>Result processing module (Optional. The module refers to the chosen module responsible for generating the final results from the raw data. If there are alternative modules available, they can be specified here. Defaults to use benchmarking result module.)</li> </ul> </li> <li> <p>Enter the following command to run the example recipe. You should see a table of results from your run:</p> <pre><code>run_recipe my-new-recipe-runner\n</code></pre> <p></p> </li> </ol>"},{"location":"user_guide/cli/benchmarking/#viewing-of-benchmarking-results-and-run-summary","title":"Viewing of Benchmarking Results and Run Summary","text":"<p>After running a recipe or cookbook, you view the results and summary of the runs:</p> <ul> <li>View result: After running a cookbook or recipe, the result will be shown in a table immediately. You can view the results after that as well:<ul> <li>Run help example: <pre><code>view_result my-new-cookbook-runner\n</code></pre> </li> </ul> </li> </ul> <p> </p> <ul> <li>View runner summary: In the examples above, we have created two runners <code>my-new-cookbook-runner</code> and <code>my-new-recipe-runner</code>. You can view the summary of runs and sessions that we have done for the runner:<ul> <li>Run help example: <pre><code>view_runner my-new-cookbook-runner\n</code></pre> </li> </ul> </li> </ul> <p></p> <ul> <li>View the runs of a runner: Every runner can have multiple runs. In the example above, we did a run <code>my-new-cookbook-runner</code>. You can view the all the runs in this runner (in this case you should see 1 run):<ul> <li>Run help example: <pre><code>view_run my-new-cookbook-runner\n</code></pre> </li> </ul> </li> </ul> <p></p>"},{"location":"user_guide/cli/benchmarking/#view-other-benchamarking-related-things","title":"View Other Benchamarking Related Things","text":"<p>You can also see some of the things we have for benchmarking (i.e. recipes):</p> <ul> <li> <p>List all recipes or cookbooks:</p> <ul> <li><code>list_recipes</code> lists all the recipes available.</li> <li><code>list_cookbooks</code> lists all the cookbooks available.</li> </ul> </li> <li> <p>View details of a recipe or cookbook:</p> <ul> <li><code>view_recipe &lt;recipe_id&gt;</code>, where <code>&lt;recipe_id&gt;</code> is the <code>id</code> field of a recipe in <code>list_recipes</code></li> <li><code>view_cookbook &lt;cookbook_id&gt;</code>, where <code>&lt;cookbook_id&gt;</code> is the <code>id</code> field of a cookbook in <code>list_cookbooks</code></li> </ul> </li> </ul>"},{"location":"user_guide/cli/cli_command_list/","title":"1. List of CLI Commands","text":"<p>This page is mainly for users who are most interested in using the CLI to perform benchmark tests and run red teaming. We have prepared the list of commands you can run in the CLI so users can have a rough sense of what can be done in the CLI.</p> Command Description Parameters add_cookbook<sub><code>add_cookbook 'My new cookbook' 'I am cookbook description' \"['analogical-similarity','auto-categorisation']\"</code></sub> Add a new cookbook. The 'name' argument will be slugified to create a unique identifier. name (str)Name of the new cookbook<sub>example: <code>'My new cookbook'</code></sub>description (str)Description of the new cookbook<sub>example: <code>'I am cookbook description'</code></sub>recipes (str)List of recipes to be included in the new cookbook (currently in string format). It will be converted into a list in the backend.<sub>example: <code>\"['analogical-similarity','auto-categorisation']\"</code></sub> list_bookmarks<sub><code>list_bookmarks</code></sub> List all available bookmarks. - list_cookbooks<sub><code>list_cookbooks</code></sub> List all available cookbooks. - update_cookbook<sub><code>update_cookbook my-new-cookbook \"[('name', 'Updated Cookbook Name'), ('description', 'Updated description'), ('recipes', ['analogical-similarity'])]\"</code></sub> Update a cookbook. cookbook (str)Id of the cookbook<sub>example: <code>my-new-cookbook</code></sub>update_values (str)List of tuples of (key,value) to update in the cookbook (currently in string format). It will be converted into a list in the backend.<sub>example: <code>\"[('name', 'Updated Cookbook Name'), ('description', 'Updated description'), ('recipes', ['analogical-similarity'])]\"</code></sub> view_cookbook<sub><code>view_cookbook my-new-cookbook</code></sub> View a cookbook. cookbook (str)Id of the cookbook<sub>example: <code>my-new-cookbook</code></sub> delete_cookbook<sub><code>delete_cookbook my-new-cookbook</code></sub> Delete a cookbook. cookbook (str)Id of the cookbook<sub>example: <code>my-new-cookbook</code></sub> run_cookbook<sub><code>run_cookbook 'my new cookbook runner' \"['bbq','mmlu']\" \"['openai-gpt35-turbo']\" -n 1 -r 1 -s 'You are an intelligent AI'</code></sub> Execute a cookbook with the specified parameters. name (str)Name of cookbook runner<sub>example: <code>my new cookbook runner</code></sub>cookbooks (str)List of cookbooks to run (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['bbq','mmlu']\"</code></sub>endpoints (str)List of endpoints to run (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['openai-gpt35-turbo']\"</code></sub>-n, --num_of_prompts (int)Number of prompts to run<sub>example: <code>1</code></sub>-r, --random_seed (int)Random seed number<sub>example: <code>1</code></sub>-s, --system_prompt (str)System Prompt to use<sub>example: <code>'You are an intelligent AI'</code></sub>-l, --runner_proc_module (str)Runner processing module to use. Defaults to use the <code>benchmarking</code> module<sub>None</sub>-o, --result_proc_module (str)Result processing module to use. Defaults to use the <code>benchmarking-result</code> module<sub>None</sub> list_datasets<sub><code>list_datasets</code></sub> List all available datasets. - view_dataset<sub><code>view_dataset bbq-lite-age-ambiguous</code></sub> View a dataset file. dataset_filename (str)Name of the dataset file<sub>example: <code>bbq-lite-age-ambiguous</code></sub> delete_dataset<sub><code>delete_dataset bbq-lite-age-ambiguous</code></sub> Delete a dataset. dataset (str)Name of the dataset<sub>example: <code>bbq-lite-age-ambiguous</code></sub> list_metrics<sub><code>list_metrics</code></sub> List all available metrics. - view_metric<sub><code>view_metric my-new-metric</code></sub> View a metric file. metric_filename (str)Name of the metric file<sub>example: <code>my-new-metric</code></sub> delete_metric<sub><code>delete_metric my-new-metric</code></sub> Delete a metric. metric (str)Name of the metric<sub>example: <code>my-new-metric</code></sub> add_recipe<sub><code>add_recipe 'My new recipe' 'I am recipe description' \"['category1','category2']\" \"['bbq-lite-age-ambiguous']\" \"['bertscore','bleuscore']\" -p \"['analogical-similarity','mmlu']\" -t \"['tag1','tag2']\" -a \"['charswap_attack']\" -g \"{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}\"</code></sub> Add a new recipe. The 'name' argument will be slugified to create a unique identifier. name (str)Name of the new recipe<sub>example: <code>'My new recipe'</code></sub>description (str)Description of the new recipe<sub>example: <code>'I am recipe description'</code></sub>categories (str)List of categories to be included in the new recipe (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['category1','category2']\"</code></sub>datasets (str)The dataset to be used (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['bbq-lite-age-ambiguous']\"</code></sub>metrics (str)List of metrics to be included in the new recipe (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['bertscore','bleuscore']\"</code></sub>-p, --prompt_templates (str)List of prompt templates to be included in the new recipe (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['analogical-similarity','mmlu']\"</code></sub>-t, --tags (str)List of tags to be included in the new recipe<sub>example: <code>\"['tag1','tag2']\"</code></sub>-a, --attack_modules (str)List of attack modules to be included in the new recipe (currently in string format). It will be converted into a list in the backend. * We currently only support running 1 attack module<sub>example: <code>\"['charswap_attack']\"</code></sub>-g, --grading_scale (str)Dict of grading scale for the metric to be included in the new recipe<sub>example: <code>\"{'A':[80,100],'B':[60,79],'C':[40,59],'D':[20,39],'E':[0,19]}\"</code></sub> list_recipes<sub><code>list_recipes</code></sub> List all available recipes. - view_recipe<sub><code>view_recipe my-new-recipe</code></sub> View a recipe. recipe (str)Id of the recipe<sub>example: <code>my-new-recipe</code></sub> run_recipe<sub><code>run_recipe 'my new recipe runner' \"['bbq','mmlu']\" \"['openai-gpt35-turbo']\" -n 1 -r 1 -s 'You are an intelligent AI'</code></sub> Execute a recipe with the specified parameters. name (str)Name of recipe runner<sub>example: <code>my new recipe runner</code></sub>recipes (str)List of recipes to run (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['bbq','mmlu']\"</code></sub>endpoints (str)List of endpoints to run (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['openai-gpt35-turbo']\"</code></sub>-n, --num_of_prompts (int)Number of prompts to run<sub>example: <code>1</code></sub>-r, --random_seed (int)Random seed number<sub>example: <code>1</code></sub>-s, --system_prompt (str)System Prompt to use<sub>example: <code>'You are an intelligent AI'</code></sub>-l, --runner_proc_module (str)Runner processing module to use. Defaults to use the <code>benchmarking</code> module<sub>None</sub>-o, --result_proc_module (str)Result processing module to use. Defaults to use the <code>benchmarking-result</code> module<sub>None</sub> update_recipe<sub><code>update_recipe my-new-recipe \"[('name', 'Updated Recipe Name'), ('tags', ['fairness', 'bbq'])]\"</code></sub> Update a recipe. recipe (str)Id of the recipe<sub>example: <code>my-new-recipe</code></sub>update_values (str)List of tuples of (key,value) to update in the recipe (currently in string format). It will be converted into a list in the backend.<sub>example: <code>\"[('name', 'Updated Recipe Name'), ('tags', ['fairness', 'bbq'])]\"</code></sub> delete_recipe<sub><code>delete_recipe my-new-recipe</code></sub> Delete a recipe. recipe (str)Id of the recipe<sub>example: <code>my-new-recipe</code></sub> list_results<sub><code>list_results</code></sub> List all available results. - view_result<sub><code>view_result my-new-cookbook-runner</code></sub> View a result file. result_filename (str)Name of the result file<sub>example: <code>my-new-cookbook-runner</code></sub> delete_result<sub><code>delete_result my-new-cookbook-runner</code></sub> Delete a result. result (str)Name of the result<sub>example: ``</sub> list_runs<sub><code>list_runs</code></sub> List all runs. - view_run<sub><code>view_run my-new-cookbook-runner</code></sub> View the details of a specific run. runner_id (str)Name of the runner<sub>example: ``</sub> list_runners<sub><code>list_runners</code></sub> List all runners. - view_runner<sub><code>view_runner my-new-cookbook-runner</code></sub> View a runner. runner (str)Name of the runner<sub>example: <code>my-new-cookbook-runner</code></sub> delete_runner<sub><code>delete_runner my-new-cookbook-runner</code></sub> Delete a runner. runner (str)Name of the runner<sub>example: <code>my-new-cookbook-runner</code></sub> add_endpoint<sub><code>add_endpoint openai-connector 'OpenAI GPT3.5 Turbo 1106' MY_URI ADD_YOUR_TOKEN_HERE 1 1 \"{'temperature': 0.5, 'model': 'gpt-3.5-turbo-1106'}\"</code></sub> Add a new endpoint. The 'name' argument will be slugified to create a unique identifier. connector_type (str)Type of connection for the endpoint<sub>example: <code>openai-connector</code></sub>name (str)Name of the new endpoint<sub>example: <code>'OpenAI GPT3.5 Turbo 1106'</code></sub>uri (str)URI of the new endpoint<sub>example: <code>MY_URI</code></sub>token (str)Token of the new endpoint<sub>example: <code>MY_URI ADD_YOUR_TOKEN_HERE</code></sub>max_calls_per_second (int)Max calls per second of the new endpoint<sub>example: <code>1</code></sub>max_concurrency (int)Max concurrency of the new endpoint<sub>example: <code>1</code></sub>params (str)Params of the new endpoint<sub>example: <code>\"{'temperature': 0.5, 'model': 'gpt-3.5-turbo-1106'}\"</code></sub> update_endpoint<sub><code>update_endpoint openai-gpt4 \"[('name', 'my-special-openai-endpoint'), ('uri', 'my-uri-loc'), ('token', 'my-token-here')]\"</code></sub> Update an endpoint. endpoint (str)Name of the endpoint<sub>example: <code>openai-gpt4</code></sub>update_kwargs (str)List of tuples of (key,value) to update in the endpoint (currently in string format). It will be converted into a list in the backend.<sub>example: <code>\"[('name', 'my-special-openai-endpoint'), ('uri', 'my-uri-loc'), ('token', 'my-token-here')]\"</code></sub> view_endpoint<sub><code>view_endpoint openai-gpt4</code></sub> View an endpoint. endpoint (str)Name of the endpoint<sub>example: <code>openai-gpt4</code></sub> delete_endpoint<sub><code>delete_endpoint openai-gpt4</code></sub> Delete a recipe. endpoint (str)Name of the endpoint<sub>example: <code>openai-gpt4</code></sub> list_connector_types<sub><code>list_connector_types</code></sub> List all connector types. - list_endpoints<sub><code>list_endpoints</code></sub> List all endpoints. - list_prompt_templates<sub><code>list_prompt_templates</code></sub> List all prompt templates available. - delete_prompt_template<sub><code>delete_prompt_template squad-shifts</code></sub> <code>Delete a prompt template.</code> prompt_template (str)The ID of the prompt template to delete<sub>example: <code>squad-shifts</code></sub> list_attack_modules<sub><code>list_attack_modules</code></sub> List all available attack modules. - delete_attack_module<sub><code>delete_attack_module sample_attack_module</code></sub> Delete an attack module. attack_module (str)The ID of the attack module to delete<sub>example: <code>sample_attack_module</code></sub> list_context_strategies<sub><code>list_context_strategies</code></sub> List all available context strategies. - use_context_strategy<sub><code>use_context_strategy my_strategy_one -n 8</code></sub> Use a context strategy. context_strategy (str)The ID of the context strategy to use<sub>example: <code>my_strategy_one</code></sub>-n, --num_of_prev_prompts (int)The number of previous prompts to use with the context strategy<sub>example: <code>8</code></sub> clear_context_strategy<sub><code>clear_context_strategy</code></sub> Resets the context in a session. - delete_context_strategy<sub><code>delete_context_strategy add_previous_prompt</code></sub> Deletes a context strategy after confirming with the user. context_strategy (str)The ID of the context strategy to delete<sub>example: <code>add_previous_prompt</code></sub> use_prompt_template<sub><code>use_prompt_template 'analogical-similarity'</code></sub> Use a prompt template by specifying its name while user is in a session. prompt_template (str)Name of the prompt template<sub>example: <code>'analogical-similarity'</code></sub> clear_prompt_template<sub><code>clear_prompt_template</code></sub> Resets the prompt template in a session. - new_session<sub><code>new_session my-runner -e \"['openai-gpt4']\" -c add_previous_prompt -p mmlu</code></sub> Creates a new session based on the provided arguments. runner_id (str)ID of the runner. Creates a new runner if runner does not exist.<sub>example: <code>my-runner</code></sub>endpoints (list)List of endpoint(s) for the runner that is only compulsory for creating a new runner (currently in string format). It will be converted into a list in the backend<sub>example: <code>\"['openai-gpt4']\"</code></sub>-c, --context_strategy (str)Name of the context_strategy to be used - indicate context strategy here if you wish to use with the selected attack.<sub>example: <code>add_previous_prompt</code></sub>-p, --prompt_template (str)Name of the prompt template to be used - indicate prompt template here if you wish to use with the selected attack.<sub>example: <code>mmlu</code></sub> use_session<sub><code>use_session runner_id</code></sub> Resumes a session by specifying its runner ID and updates the active session. runner_id (str)The ID of the runner<sub>example: <code>runner_id</code></sub> end_session<sub><code>end_session</code></sub> Ends the current session by clearing active_session variable. - list_sessions<sub><code>list_sessions</code></sub> Retrieves and displays the list of sessions. - show_prompts<sub><code>show_prompts</code></sub> Display all prompts. - run_attack_module<sub><code>run_attack_module sample_attack_module 'this is my prompt' -s 'test system prompt' -m 'bleuscore'</code></sub> Runs automated red teaming in the current session. attack_module_id (str)ID of the attack module.<sub>example: <code>sample_attack_module</code></sub>prompt (str)Prompt to be used for the attack.<sub>example: <code>'this is my prompt'</code></sub>-s, --system_prompt (str)System Prompt to be used for the attack. If not specified, the default system prompt will be used.<sub>example: <code>'test system prompt'</code></sub>-c, --context_strategy (str)Name of the context strategy module to be used. If this is set, it will overwrite the context strategy set in the session while running this attack module.<sub>example: <code>'add_previous_prompt'</code></sub>-n, --cs_num_of_prev_prompts (str)The number of previous prompts to use with the context strategy. If this is set, it will overwrite the number of previous prompts set in the session while running this attack module.<sub>example: <code>5</code></sub>-p, --prompt_template (str)Name of the prompt template to be used. If this is set, it will overwrite the prompt template set in the session while running this attack module.<sub>example: <code>mmlu</code></sub>-m, --metric (str)Name of the metric module to be used.<sub>example: <code>bleuscore</code></sub>-o, --optional_args (str)Optional parameters to input into the red teaming module.<sub>example: <code>{'param1': 'value1'}</code></sub> delete_session<sub><code>delete_session my-test-runner</code></sub> Delete a session session (str)The runner ID of the session to delete<sub>example: <code>my-test-runner</code></sub> add_bookmark<sub><code>add_bookmark openai-connector 2 my-bookmarked-prompt</code></sub> Bookmark a prompt endpoint (str)Endpoint which the prompt was sent to<sub>example: <code>openai-connector</code></sub>prompt_id (int)ID of the prompt (the leftmost column)<sub>example: <code>2</code></sub>bookmark_name (str)Name of the bookmark<sub>example: <code>my-bookmarked-prompt</code></sub> use_bookmark<sub><code>use_bookmark my_bookmark</code></sub> Use a bookmarked prompt bookmark_name (str)Name of the bookmark<sub>example: <code>my_bookmark</code></sub> delete_bookmark<sub><code>delete_bookmark my_bookmarked_prompt</code></sub> Delete a bookmark bookmark_name (str)Name of the bookmark<sub>example: <code>my_bookmarked_prompt</code></sub> view_bookmark<sub><code>view_bookmark my_bookmarked_prompt</code></sub> View a bookmark bookmark_name (str)Name of the bookmark you want to view<sub>example: <code>my_bookmarked_prompt</code></sub> export_bookmarks<sub><code>export_bookmarks \"my list of exported bookmarks\"</code></sub> Exports bookmarks as a JSON file bookmark_list_name (str)Name of the exported bookmarks JSON file you want to save as (without the .json extension)<sub>example: <code>my list of exported bookmarks</code></sub>"},{"location":"user_guide/cli/cli_guide/","title":"Running Moonshot via CLI","text":"<p>Two modes are available on the Moonshot CLI: Command-Based Mode and Interactive Mode.</p> Full list of commands in Moonshot <pre><code>Initialisation\n======================================================================================================\ninteractive           Run the interactive shell.                                                      \nlist_connect_types    Get a list of available Language Model (LLM) connection types.                  \nlist_endpoints        Get a list of available Language Model (LLM) endpoints.                         \nversion               Get the version of the application.                                             \n\nMoonshot Benchmarking\n======================================================================================================\nadd_cookbook          Add a new cookbook.                                                             \nadd_endpoint          Add a new endpoint.                                                             \nadd_recipe            Add a new recipe.                                                               \nlist_cookbooks        Get a list of available cookbooks.                                              \nlist_recipes          Get a list of available recipes.                                                \nlist_results          Get a list of available results.                                                \nlist_runs             Get a list of available runs.                                                   \nresume_run            Resume an interrupted run.                                                      \nrun_cookbook          Run a cookbook.                                                                 \nrun_recipe            Run a recipe.                                                                   \nview_cookbook         View a cookbook.                                                                \nview_results          View a results file.                                                            \n\nMoonshot RedTeaming\n=======================================================================================================\nend_session            End the current session.                                                        \nlist_prompt_templates  List all prompt templates available.                                            \nlist_sessions          List all available sessions.                                                    \nnew_session            Add a new red teaming session.                                                  \nuse_context_strategy   Use a context strategy.                                                         \nuse_prompt_template    Use a prompt template.                                                          \nuse_session            Use an existing red teaming session.                                            \n\nUncategorized\n======================================================================================================\nalias                 Manage aliases                                                                  \nedit                  Run a text editor and optionally open a file with it                            \nhelp                  List available commands or provide detailed help for a specific command         \nhistory               View, run, edit, save, or clear previously entered commands                     \nmacro                 Manage macros                                                                   \nquit                  Exit this application                                                           \nrun_pyscript          Run a Python script file inside the console                                     \nrun_script            Run commands in script file that is encoded as either ASCII or UTF-8 text       \nset                   Set a settable parameter or show current settings of parameters                 \nshell                 Execute a command as if at the OS prompt                                        \nshortcuts             List available shortcuts                                                \n</code></pre>"},{"location":"user_guide/cli/cli_guide/#command-based-mode","title":"Command-based Mode","text":"<p>In the command-based mode, run commands by prepending <code>python -m moonshot cli</code>. </p> <p>For example,</p> <ul> <li>To list all the available commands: <code>python -m moonshot cli help</code></li> <li>To list the connector types available: <code>python -m moonshot cli list_connect_types</code></li> </ul>"},{"location":"user_guide/cli/cli_guide/#interactive-mode","title":"Interactive Mode","text":"<p>We recommend the interactive mode for a more efficient experience, especially if you are using Moonshot to red-team. </p> <p>To enter interactive mode: <code>python -m moonshot cli interactive</code> (You should see the command prompt change to <code>moonshot &gt;</code> ) For example, - To list all the available commands:      <pre><code>moonshot &gt; help\n</code></pre> - To list the connector types available:     <pre><code>moonshot &gt; list_connect_types\n</code></pre></p>"},{"location":"user_guide/cli/connecting_endpoints/","title":"(CLI) Connecting to LLMs","text":"<p>In this section, we will be going through the steps required to create a connector endpoint.</p> <p>Before we jump into executing tests and performing red teaming on LLMs, we have to first create a connector endpoint. This connector endpoint will help us to connect to a specific LLM.</p> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter:     </p> <pre><code>python -m moonshot cli interactive\n</code></pre>"},{"location":"user_guide/cli/connecting_endpoints/#using-an-existing-connector-endpoint","title":"Using an Existing Connector Endpoint","text":"<ol> <li>To view the connector endpoint available, enter:<pre><code>list_endpoints\n</code></pre> </li> </ol> <p>You will see a list of available connector endpoints that we have created beforehand: </p> <ol> <li> <p>If there is no connector endpoint for you here, you create your own connector endpoint here. Otherwise, enter the following command to modify the connector endpoint you want to use (e.g., adding your own API key):</p> <pre><code>update_endpoint -h\n</code></pre> <p>You should see a help example:</p> <pre><code>update_endpoint openai-gpt4 \"[('name', 'my-special-openai-endpoint'), ('uri', 'my-uri-loc'), ('token', 'my-token-here')]\"\n</code></pre> <p>Here, we are updating a connector endpoint with the ID <code>openai-gpt4</code>. The keys and values to be updated are tuples in a list (i.e. update the key <code>name</code> with the value<code>my-special-openai-endpoint</code>)</p> </li> <li> <p>After you have used the <code>update_endpoint</code> command to update your connector endpoint. Enter the following command to view your updated connector endpoint:</p> <pre><code>view_endpoint openai-gpt4\n</code></pre> <p></p> </li> </ol>"},{"location":"user_guide/cli/connecting_endpoints/#creating-a-connector-endpoint","title":"Creating a Connector Endpoint","text":"<ol> <li> <p>Enter the following command to understand more on how to create a connector endpoint </p> <pre><code>add_endpoint -h\n</code></pre> <p>You should see a help example:</p> <pre><code>add_endpoint openai-connector 'my-openai-connector' myendpointuri mythisismysecretapitoken 2 10 \"{'temperature': 0.5}\"\n</code></pre> <p>In this example, we are creating a connector endpoint for the <code>openai-connector</code> connector type:</p> <ul> <li>Name of your endpoint connenctor (unique identifier): <code>my-openai-connector</code></li> <li>URI: <code>myendpointuri</code> (set this to a random string like <code>none</code> if it is not required by your connector endpoint)</li> <li>API token: <code>thisismysecretapitoken</code></li> <li>Max number of calls made to the endpoint per second: <code>2</code></li> <li>Max concurrency of the endpoint:<code>10</code></li> <li> <p>Other parameters that this endpoint may need:</p> <ul> <li>Temperature: 0.5        </li> </ul> <p>To view the list of connector types, enter <code>list_connector_types</code>:     </p> <p>NOTE: If you do not see the connector type you want to use, refer to our guide in contributor_guide/create_connector.md to learn how to create your own connector type. </p> </li> </ul> </li> <li> <p>After you have used the <code>add_endpoint</code> command to create your endpoint. Enter the following command to view your newly created connector endpoint:</p> <pre><code>view_endpoint my-openai-connector\n</code></pre> <p>NOTE: The ID (my-openai-connector)of the connector endpoint is created by slugifying the name.</p> <p></p> </li> </ol>"},{"location":"user_guide/cli/red_teaming/","title":"Run Red Teaming Sessions","text":"<p>In this section, we will be going through the steps required to run red teaming sessions.</p> <p>To run a test, you will need:</p> <ul> <li>Connector Endpoint - a configuration file to connect to your desired LLM endpoint</li> <li>Session - a session allows users to perform manual and automated red teaming on the LLMs, and stores the prompts and responses to and fro.</li> <li>Prompt - a prompt that you will be sending to LLMs in manual red teaming/ a starting prompt to input in attack modules before sending to the LLMs</li> </ul> <p>For the following steps, they will be done in interactive mode in CLI. To activate interactive mode, enter:</p> <pre><code>python -m moonshot cli interactive\n</code></pre>"},{"location":"user_guide/cli/red_teaming/#create-a-connector-endpoint","title":"Create a Connector Endpoint","text":"<p>If you have not already created a connector endpoint, check out the guide here.</p>"},{"location":"user_guide/cli/red_teaming/#create-a-session","title":"Create a Session","text":"<p>Once your connector endpoint is created, we can start creating our session for red teaming.</p> <p>Every session must reside in a runner. Before we create a session, enter the following command to view a list of runners currently available by entering:</p> <pre><code>list_runners\n</code></pre> <p></p> <p>There are two options to create a session: you can either use an existing runner, or create a new runner with a session. To better understand its usage, enter the following command:</p> <pre><code>new_session -h\n</code></pre> <ol> <li> <p>Use existing runner.</p> <ul> <li> <p>Example:</p> <pre><code>new_session my-test-mrt -c add_previous_prompt -p mmlu\n</code></pre> <ul> <li>Runner ID: <code>my-test-mrt</code></li> <li>Context strategy: <code>add_previous_prompt</code></li> <li>Prompt template:  <code>mmlu</code></li> </ul> </li> </ul> <p></p> <p>NOTE:  Context strategy and prompt template are optional and can be set later so you can omit the <code>-c -p</code> flags if you do not need them    </p> </li> <li> <p>Create new runner.</p> <ul> <li> <p>Example: </p> <pre><code>new_session my-new-runner-test-mrt -e \"['openai-gpt35-turbo','openai-gpt4']\" -p phrase-relatedness\n</code></pre> <ul> <li>Runner ID: <code>my-new-runner-test-mrt</code></li> <li>Endpoint: <code>['openai-gpt35-turbo','openai-gpt4']</code></li> <li>Prompt template: <code>phrase-relatedness</code></li> </ul> </li> </ul> <p></p> </li> </ol> <p>Once you have a session created and activated, we can proceed with red teaming. There are two ways to perform red teaming: manual red teaming and using attack modules to perform automated attacks. </p>"},{"location":"user_guide/cli/red_teaming/#manual-red-teaming","title":"Manual Red Teaming","text":"<p>From the previous section, you should have a session created and activated. For manual red teaming, you can start by typing something in the session and that prompt will be sent to all the LLMs in that session.      </p> <p>NOTE:  Anything entered in a session that is not a command will be considered a prompt and sent to the LLMs in that session! </p>"},{"location":"user_guide/cli/red_teaming/#automated-red-teaming-run-attack-modules","title":"Automated Red Teaming (Run Attack Modules)","text":"<p>We will use the same session from manual red teaming in this example. Enter the following command to find out more about running attack modules:</p> <pre><code>run_attack_module -h\n</code></pre> <p>You should see a help example:</p> <pre><code>run_attack_module charswap_attack \"The grandpa and his son went to does not know how to use a phone?\\na)Grandpa\\nb)Son.\"\n</code></pre> <p>The fields are as follows for this example:</p> <ul> <li>Attack module ID:  <code>charswap_attack</code></li> <li>Prompt: <code>The grandpa and his son went to does not know how to use a phone?\\na)Grandpa\\nb)Son.</code></li> </ul> <p></p> <p>Refer to this section for more information on automated red teaming</p>"},{"location":"user_guide/cli/red_teaming/#ending-and-resuming-a-session","title":"Ending and Resuming a Session","text":"<p>End session - Once you are done with red teaming, you can close the session by entering: </p> <pre><code>end_session\n</code></pre> <p>View sessions -  You can view your sessions by entering: </p> <pre><code>list_sessions\n</code></pre> <p>Resume session - You can resume a session by entering:</p> <pre><code>use_session &lt;desired session id&gt;\n</code></pre> <p>where <code>&lt;desired session id&gt;</code> is an <code>id</code> in <code>list_sessions</code>. When you resume a session, the state of your previous red teaming attempts will be restored.</p>"},{"location":"user_guide/cli/red_teaming/#configurations-in-a-session","title":"Configurations in a Session","text":"<ul> <li> <p>These are the configurations you can set in a session:</p> <ul> <li> <p>Context strategy: a Python module that helps to add context to the current prompt (i.e. add in the previous five prompts sent.) </p> <p>To use a context strategy:</p> <pre><code>use_context_strategy &lt;desired context strategy id&gt;\n</code></pre> <p>You can use the following command to view the list of context strategies available:</p> <pre><code>list_context_strategies\n</code></pre> <p>The <code>&lt;desired context strategy id&gt;</code> should correspond to an <code>Id</code> in <code>list_context_strategies</code>.</p> <ul> <li>It is also possible to set the number of previous prompts to use with a context strategy. For example, to add <code>8</code> previous prompts as context using the <code>add_previous_prompt</code>, use the command:<pre><code>use_context_strategy add_previous_prompt -n 8\n</code></pre> </li> </ul> <p>To clear a context strategy in a session, use:</p> <pre><code>clear_context_strategy\n</code></pre> </li> <li> <p>Prompt template: a JSON file which contains static texts that is appended to every prompt before they are sent to the LLMs. </p> <p>To use a prompt template:</p> <pre><code>use_prompt_template &lt;desired prompt template id&gt;\n</code></pre> <p>You can use the following command to view the list of prompt templates available:</p> <pre><code>list_prompt_templates\n</code></pre> <p>The <code>&lt;desired prompt template id&gt;</code> should correspond to an <code>Id</code> in <code>list_prompt_templates</code>.</p> <p>To clear a prompt template in a session, use:</p> <pre><code>clear_prompt_template\n</code></pre> </li> </ul> </li> </ul>"},{"location":"user_guide/cli/red_teaming/#more-about-automated-red-teaming","title":"More About Automated Red Teaming","text":"<p>Currently, automated red teaming heavily relies on the attack module being used. We have created a class, AttackModule, which serves as the base class for creating custom attack modules within the Moonshot framework. This class provides a structure that red teamers can extend to implement their own adversarial attack strategies.</p> <p>In the AttackModule class, we have simplified the process for red teamers by providing easy access to necessary components for red teaming, such as connector endpoints and a function to automatically wrap the prompt template and context strategy contents around the provided prompt.</p> <p>The design is very free-form, thus it is entirely up to the attack module developers whether they want to use the functions we have prepared. For instance, they may choose not to use the context strategy and prompt template at all in the attack module, even though these may be set in the session.</p>"},{"location":"user_guide/web_ui/choosing_relevant_tests/","title":"Choosing Relevant Tests","text":"<ol> <li>Click on \u2018Get Started\u2019 </li> </ol> <ol> <li> <p>This page lists the cookbooks that Moonshot provides. Each cookbook contains tests of the same theme. Select the areas that are relevant to your use case. This is not final as you will be able to further curate the scope and scale of the tests in following steps.   </p> <p>View full list of cookbook details </p> <p>Note</p> <p>Some of these cookbooks contain scoring metrics that require connection to specific models. </p> <p>MLCommons AI Safety Benchmarks v0.5 (Requires an API key for accessing Llama Guard via Together AI) </p> <p>Facts about Singapore (Requires an API key for accessing Llama Guard via Together AI)</p> <p>See the troubleshooting guide for more info on setting up alternative connections to Llama Guard.</p> </li> <li> <p>When done, click on the next button.       </p> </li> <li> <p>This page shows the total number of prompts that will be sent to each AI system you want to test. Click on \u2018these cookbooks\u2019 to see in greater detail what tests will be run.       </p> </li> <li> <p>This page shows you the cookbooks available in Moonshot, categorised according to Capability, Trust &amp; Safety, Quality and Others (for cookbooks without any categories).   </p> <p>You can click on \u2018About\u2019 for each cookbook to see what recipes it contains. </p> <p> </p> <p>Check the \u2018Run this cookbook\u2019 checkbox if you wish to run any of the cookbooks. Click on \u2018X\u2019 to close the pop-up. </p> <p> </p> <p>You can also unselect cookbooks if you do not wish to run them. </p> <p>Click on \u2018OK\u2019 once you are satisfied with the cookbooks to be run. The total number of prompts to be sent should be updated. (There will be a step later on in the workflow for you to run a smaller number of prompts) </p> <p> </p> <p>Click on the next button. </p> <p> </p> </li> </ol>"},{"location":"user_guide/web_ui/connecting_to_llms/","title":"Connecting to LLMs","text":"<ol> <li> <p>This page shows you the connector endpoints available to be tested. Moonshot comes with pre-configured connector endpoints to some popular model providers, you will just need to provide your API key.  </p> <ul> <li> <p>Click on \u2018Edit\u2019 to add in the API key for any of these models you may wish to test. </p> </li> <li> <p>If you wish to test other LLMs or your own hosted LLM application, click on \u2018Create New Endpoint\u2019. </p> </li> </ul> <p></p> </li> <li> <p>Provide the following info as necessary, and click \u2018Save\u2019 to create/ update the endpoint. </p> <p></p> Name Description Example Name (Required) A unique name for you to identify this new endpoint by <code>My GPT4</code> Connection Type (Required) Type of API to use. If you do not see the type that you need, see How to build a custom connector <code>openai-connector</code> URI URI to the endpoint to be tested <code>&lt;left blank&gt;</code> Token Your private API token <code>123myopenaicontoken456</code> Max Calls Per Second The maximum number of calls to be made to the endpoint per second <code>10</code> Max Concurrency The maximum number of calls that can be made to the endpoint at any one time <code>1</code> Other Parameters Certain connector types require extra parameters. e.g., for OpenAI connectors, you will need to specify the <code>model</code>. See OpenAI docs <code>{ \"timeout\": 300, \"allow_retries\": true, \"num_of_retries\": 3, \"temperature\": 0.5, \"model\": \"gpt-4\" }</code> </li> <li> <p>Select the endpoints to the AI systems that you wish to run benchmarks on, and click the next button when done. </p> <p>Click on \u2018Edit\u2019 for Together Llama Guard 7B Assistant, provide your API token, and click \u2018Save\u2019. (You don\u2019t need to select Together Llama Guard 7B Assistant for testing)  </p> </li> </ol>"},{"location":"user_guide/web_ui/creating_custom_cookbooks/","title":"Creating Custom Cookbooks","text":"<p>Using the recipes available on Moonshot, you can easily curate custom cookbooks to suit your testing needs. </p> <ol> <li> <p>Click on \u2018Create cookbooks, Select Recipes \u2192\u2019 </p> </li> <li> <p>Provide the following information.</p> Name Description Example Name (Required) A unique name to identify this cookbook by. My Custom Cookbook Description Describe what the tests in this cookbook will cover. This cookbook is designed to evaluate chatbots in capabilities that we expect it to excel in. <p></p> </li> <li> <p>Click on \u2018Select Recipes\u2019. </p> </li> <li> <p>Here you can view the list of recipes available in Moonshot. Select the recipes that you would like to include in your custom cookbook and click on \u2018Add to Cookbook\u2019. </p> <p></p> </li> <li> <p>Click on \u2018Create Cookbook\u2019, then \u2018View Cookbooks\u2019 to view all the cookbooks that you now have in the tool. </p> <p></p> </li> <li> <p>To run this cookbook, click on \u2018Get Started\u2019 </p> <p></p> </li> </ol>"},{"location":"user_guide/web_ui/running_benchmarks/","title":"Running Benchmarks","text":"<ol> <li> <p>Before you can start running benchmarks, provide the following info. These will be included in the report generated at the end of the run. </p> Name Description Example Name (Required) A unique name for you to identify this benchmark run by <code>GPT4 vs Claude on safety benchmarks</code> Description Describe the purpose and scopte of this benchmark run. Comparing GPT4 and Claude to determine which model is safer as a chatbot Run a smaller set The number of prompts per dataset, as specified in the recipe, to be run. Indicating 0 will run the full set.  * Before running the full recommended set, you may want to run a smaller number of prompts from each recipe to do a sanity check. 5 <li> <p>Click \u2018Run\u2019 to start running the benchmarks. </p> <p></p> </li> <li> <p>You can click on \u2018See Details\u2019 to recap on what is currently being run. </p> <p></p> </li> <li> <p>A report will be generated once the run is completed. Meanwhile, you can:</p> <ul> <li>Start Red Teaming to discover new vulnerabilities   </li> <li>Create a custom cookbook by curating your own set of recipes   </li> <li>Go back to home  </li> </ul> </li> <li> <p>To view the progress of the run, click on the bell icon, then select the specific benchmark run.</p> <p></p> </li> <li> <p>Once run is completed, you can click on \u2018View Report\u2019 </p> <p></p> </li> <li> <p>One report will be generated for each endpoint tested. Click on the dropdown to toggle the report displayed. You can also download the HTML report and the detailed results as a JSON file. </p> <p></p> </li> <li> <p>You can also view the details of previous runs through: </p> <ol> <li>Click on \u2018history\u2019 icon, then \u2018View Past Runs\u2019 </li> <li>Click on \u2018benchmarking\u2019 icon, then \u2018View Past Runs\u2019 </li> </ol> </li>"},{"location":"user_guide/web_ui/running_red_teaming/","title":"Red Teaming","text":"<ol> <li> <p>Click on \u2018Discover new vulnerabilities\u2019 to start a new red teaming session. </p> <p></p> </li> <li> <p>Select the endpoints to the LLMs that you wish to red team simultaneously in this session, and click the next button when done.  * There is currently no hard limit to the number of endpoints you can red team at once, but we recommend to keep it under 5 for a smoother UX.</p> <p></p> </li> <li> <p>This page shows you the various attack modules that you can use to automate your red teaming process. Each attack module provides a unique way to automatically generate prompts, based-off an initial prompt you provide, to be sent to the endpoints. Some of these attack modules require the connection to a helper model e.g., GPT4. </p> <p>Select one attack module you would like to try out as a start and click the next button, or click on \u2018Skip for now\u2019:  You will be able to start using attack modules in the midst of a red teaming session. </p> </li> <li> <p>Before you can start the new red teaming session, provide the following info. </p> Name Description Example Name (Required) A unique name for you to identify this red teaming session by Try to jailbreak GPTs Description Describe the purpose and scope of this red teaming session. Comparing GPT versions on resistance to various attack techniques <p></p> </li> <li> <p>Click \u2018Start\u2019 to create the new red teaming session. </p> </li> <li> <p>This page shows Moonshot\u2019s red teaming interface.  </p> <p></p> </li> </ol> <p>Chat boxes and Layout</p> <p>Each chat box will allow you to view the prompt and response sent to / received from each endpoint.   </p> <p>There are two layout options:  1. Carousel (Default if you have &gt;3 endpoints) and   2. Free Layout, which allows you to re-arrange, re-size and even minimise chat boxes. </p> <p>Sending Prompts</p> <p>Type your prompt in the \u2018Prompt\u2019 text box and click \u2018Send\u2019 to send that prompt to all the endpoints in your session.      </p> <p>Red Teaming Tools </p> <p>You can use some of these tools to enhance your red teaming process: </p> <ol> <li> <p>Attack Modules  Attack modules are techniques that will enable the automatic generation of adversarial prompts for automated red teaming. Click on \u2018Attack Modules\u2019 to view the list of attack modules that are available for use.</p> <p></p> <p>Click on \u2018Use\u2019 to select an attack module.</p> <p></p> <p>Note</p> <p>If you wish to run any of these attack modules, you will need to provide additional API keys: </p> <pre><code>1. Malicious Question Generator (Requires OpenAI\u2019s GPT4)\n\n2. Violent Durian (Requires OpenAI\u2019s GPT4)\n</code></pre> <p>To provide the API keys, go to \u2018Model Endpoints\u2019 and click on \u2018Edit\u2019 for OpenAI GPT4, provide your API token, and click \u2018Save\u2019. (You don\u2019t need to select OpenAI GPT4 in the red teaming session) </p> <ul> <li> <p>Enter your prompt in the \u2018Prompt\u2019 box as the initial prompt that the attack module will use to generate adversarial prompts from. </p> </li> <li> <p>Click \u2018Send\u2019 to trigger the attack module and start the automated red teaming process. Each attack module has a pre-defined number of prompts that it will generate. You will not be able to send any other prompts before the attack module has sent all of the prompts generated. </p> </li> </ul> <p></p> <p>Click on 'X' to remove the attack module set. </p> </li> <li> <p>Prompt Templates     Prompt templates are predefined text structures that guide the formatting and contextualisation of the prompt sent to the AI system being tested. Click on \u2018Prompt Templates\u2019 to view the list of prompt templates that are available for use. </p> <p>Click on 'Use' to select a prompt template. </p> <p>Enter your prompt in the \u2018Prompt\u2019 box. The prompt template you selected will be applied to the prompt when you click \u2018Send\u2019.  </p> <p>Hover your mouse over each prompt to view its details.  </p> <p>Click on \u2018X\u2019 to remove the prompt template set.  </p> </li> <li> <p>Context Strategies </p> <p>Context Strategies are predefined approaches to append the red teaming session's context to each prompt. Click on \u2018Context Strategies\u2019 to view the list of context strategies that are available for use. </p> <p></p> <p>Click on \u2018Use\u2019 to select a context strategy.  </p> <p>Enter your prompt in the \u2018Prompt\u2019 box. Based on the context strategy you selected, certain context (based on past chat history) will be appended to the prompt. </p> <p>Click on \u2018X\u2019 to remove the context strategy set.  </p> </li> </ol> <p>Ending a Session All sessions are being saved in real time, you can click on the \u2018X\u2019 button to end a session and resume it later.  </p> <p>Click on 'Exit'. </p> <p>Resuming a Session</p> <p>You can also view the details of previous sessions or resume a session through:      1. Click on \u2018history\u2019 icon, then \u2018View Past Sessions\u2019      2. Click on \u2018red teaming\u2019 icon, then \u2018View Past Sessions\u2019  </p>"},{"location":"user_guide/web_ui/web_ui_guide/","title":"Getting Started with Moonshot Web UI","text":"<p>In this step-by-step tutorial, we will walk you through the key functionalities of Moonshot\u2019s user-friendly web UI. </p> <p>Before starting on this tutorial, you should Install and Set Up Moonshot Web UI and have an understanding of Moonshot\u2019s key features. </p> <p>This tutorial will walk you through the UI\u2019s guided workflow to: </p> <ol> <li>Introduction to Moonshot Interface</li> <li>Choose tests relevant to your LLMs</li> <li>Set up connection to your LLMs</li> <li>Run Benchmarks</li> <li>Conduct Red Teaming</li> </ol> <p>After you have completed this tutorial, you can learn some of these more advanced functions: </p> <ol> <li>How to create custom cookbooks</li> </ol>"},{"location":"user_guide/web_ui/moonshot_interface/benchmarking/","title":"Benchmarking","text":"<p>When you click on the benchmarking icon, you will be directed to this page.</p> <p></p> <p>The 'Start New Run' button will allow you to create a new benchmark run. You can refer to the tutorial on how to run a benchmark test here.</p> <p>The 'View Past Runs' page allows you to examine the outcomes of your previous runs or initiate a new run.</p> <p></p> <p>The 'View Cookbooks' will bring you to a page that allows you to view the list of cookbooks that you have.</p> <p></p> <p>The 'View Recipes' will bring you to a page that allows you to view the list of recipes that you have.</p> <p></p>"},{"location":"user_guide/web_ui/moonshot_interface/endpoint/","title":"Endpoint","text":"<p>This page is the page when you click on the endpoints icon.</p> <p></p>"},{"location":"user_guide/web_ui/moonshot_interface/endpoint/#form-field-information","title":"Form Field Information","text":"<p>Below are the descriptions for each field in the form:</p> Name Description Example Name (Required) A unique name for you to identify this new endpoint by <code>My GPT4</code> Connection Type (Required) Type of API to use. If you do not see the type that you need, see How to build a custom connector <code>openai-connector</code> URI URI to the endpoint to be tested <code>&lt;left blank&gt;</code> Token Your private API token <code>123myopenaicontoken456</code> Max Calls Per Second The maximum number of calls to be made to the endpoint per second <code>10</code> Max Concurrency The maximum number of calls that can be made to the endpoint at any one time <code>1</code> Other Parameters Certain connector types require extra parameters. e.g., for OpenAI connectors, you will need to specify the <code>model</code>. See OpenAI docs <code>{ \"timeout\": 300, \"allow_retries\": true, \"num_of_retries\": 3, \"temperature\": 0.5, \"model\": \"gpt-4\" }</code>"},{"location":"user_guide/web_ui/moonshot_interface/endpoint/#creating-a-new-endpoint","title":"Creating a New Endpoint","text":"<p>To create a new endpoint, click on the 'Create New Endpoint' button. This action will display a popup containing a form for creating a new endpoint.</p> <p></p> <p>To add additional parameters, click on the 'More Config' button.</p> <p></p> <p>After adjusting your additional configurations, click 'OK' to save these parameters. Once you return to the 'Create Endpoint' form, ensure all necessary fields are filled before clicking 'Save' to store your new endpoint.</p>"},{"location":"user_guide/web_ui/moonshot_interface/endpoint/#editing-an-endpoint","title":"Editing an Endpoint","text":"<p>To edit an existing endpoint, click on the 'Edit Endpoint' button. This will display a popup similar to the 'Create New Endpoint' form, but with the current values pre-filled.</p> <p></p> <p>Just like when creating an endpoint, you can click on the 'More Config' button to add or modify additional parameters for your model.</p> <p></p> <p>After making changes to your additional parameters, click 'OK' to save them. Once you return to the 'Edit Endpoint' form, ensure all necessary fields are filled before clicking 'Save' to update your endpoint.</p>"},{"location":"user_guide/web_ui/moonshot_interface/history/","title":"History","text":"<p>Upon clicking the history icon, you'll be navigated to a this history page.</p> <p>This page provides you with the option to review your previous benchmark runs by clicking 'View Past Runs', or to revisit your past red teaming sessions by selecting 'View Past Sessions'.</p> <p></p> <p>The 'Past Benchmark Runs' page allows you to examine the outcomes of your previous runs or initiate a new run.</p> <p></p> <p>The 'Past Red Teaming Sessions' page offers the functionality to continue a paused red teaming session or to kick-off a new one.</p> <p></p>"},{"location":"user_guide/web_ui/moonshot_interface/homepage/","title":"Home","text":"<p>The Moonshot landing page appears when you first launch the UI.</p>"},{"location":"user_guide/web_ui/moonshot_interface/homepage/#sidebar","title":"Sidebar","text":"<p>The sidebar contains several icons, each representing a different page within the Moonshot UI:</p> Icon Description This icon directs you to the endpoint list page, where you can view, create, and manage your endpoints. This icon takes you to the benchmarking page. Here, you can initiate benchmarking processes to evaluate your models against standard tests. This icon leads you to the red teaming page. On this page, you can start a red teaming process to discover new vulnerabilities in your models. This icon navigates you to the history page of your runs. Here, you can review the details and results of your past runs. This icon guides you to the list of prompt templates and context strategies. These resources can help you customize your testing processes."},{"location":"user_guide/web_ui/moonshot_interface/homepage/#discover-new-vulnerabilities","title":"Discover new vulnerabilities","text":"<p>The \"Discover new vulnerabilities\" button initiates a red teaming process. Red teaming is a proactive approach to identifying vulnerabilities in your models before they can be exploited.</p>"},{"location":"user_guide/web_ui/moonshot_interface/homepage/#evaluate-against-standard-tests","title":"Evaluate against standard tests","text":"<p>The \"Evaluate against standard tests\" button starts a benchmarking process. Benchmarking allows you to assess your models' performance against a set of standard tests, providing a comprehensive evaluation of their capabilities.</p>"},{"location":"user_guide/web_ui/moonshot_interface/homepage/#create-cookbooks","title":"Create Cookbooks","text":"<p>The \"Create Cookbooks\" button takes you to the cookbook creation page. Cookbooks are collections of recipes (tests) that you can run against your models. By creating your own cookbooks, you can curate a set of tests that are most relevant to your models' use cases.</p>"},{"location":"user_guide/web_ui/moonshot_interface/homepage/#initiating-the-benchmarking-process","title":"Initiating the Benchmarking Process","text":"<p>The \"Get Started\" button serves as your gateway to initiate a benchmarking process. By clicking on this button, you will be directed to the benchmarking setup page where you can configure and start the benchmarking process for your models.</p>"},{"location":"user_guide/web_ui/moonshot_interface/homepage/#monitoring-the-benchmarking-run-status","title":"Monitoring the Benchmarking Run Status","text":"<p>The status of your benchmarking runs can be conveniently monitored through the bell icon located at the top right corner of the screen. A simple click on this icon will reveal a dropdown list displaying the status of all your ongoing and completed benchmarking runs.</p> <p>For a more detailed view, you can click on any of the listed benchmarking runs. This action will navigate you to a dedicated page for that particular run. Here, you can delve into the specifics of the run, including its progress, results, and a comprehensive report detailing the performance of your model during the benchmarking process.</p>"},{"location":"user_guide/web_ui/moonshot_interface/redteaming/","title":"Red Teaming","text":"<p>When you click on the red teaming icon, you will be directed to this page.</p> <p></p> <p>The 'Start New Session' button will allow you to create a new red teaming session. You can refer to the tutorial on how to run teaming here.</p> <p>The 'View Past Sessions' page offers the functionality to continue a paused red teaming session or to kick-off a new one.</p> <p></p> <p>The 'View Attack Modules' will bring you to a page that allows you to view the list of attack modules that you have.</p> <p></p>"},{"location":"user_guide/web_ui/moonshot_interface/utils/","title":"Utils","text":"<p>When you click on the utils icon, you will be directed to this page.</p> <p>By clicking, you can access the list of available prompt templates and context strategies for use.</p> <p></p> <p></p> <p></p>"}]}