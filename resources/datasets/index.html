
<!DOCTYPE html>

<html class="no-js" lang="en">
<head>
<meta charset="utf-8"/>
<meta content="width=device-width,initial-scale=1" name="viewport"/>
<link href="../recipes/" rel="prev"/>
<link href="../metrics/" rel="next"/>
<link href="../../assets/images/favicon.png" rel="icon"/>
<meta content="mkdocs-1.6.0, mkdocs-material-9.5.25" name="generator"/>
<title>Datasets - Moonshot</title>
<link href="../../assets/stylesheets/main.6543a935.min.css" rel="stylesheet"/>
<link crossorigin="" href="https://fonts.gstatic.com" rel="preconnect"/>
<link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&amp;display=fallback" rel="stylesheet"/>
<style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
<link href="../../assets/_mkdocstrings.css" rel="stylesheet"/>
<script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
</head>
<body dir="ltr">
<input autocomplete="off" class="md-toggle" data-md-toggle="drawer" id="__drawer" type="checkbox"/>
<input autocomplete="off" class="md-toggle" data-md-toggle="search" id="__search" type="checkbox"/>
<label class="md-overlay" for="__drawer"></label>
<div data-md-component="skip">
<a class="md-skip" href="#list-of-datasets">
          Skip to content
        </a>
</div>
<div data-md-component="announce">
</div>
<header class="md-header md-header--shadow" data-md-component="header">
<nav aria-label="Header" class="md-header__inner md-grid">
<a aria-label="Moonshot" class="md-header__button md-logo" data-md-component="logo" href="../.." title="Moonshot">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
<label class="md-header__button md-icon" for="__drawer">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"></path></svg>
</label>
<div class="md-header__title" data-md-component="header-title">
<div class="md-header__ellipsis">
<div class="md-header__topic">
<span class="md-ellipsis">
            Moonshot
          </span>
</div>
<div class="md-header__topic" data-md-component="header-topic">
<span class="md-ellipsis">
            
              Datasets
            
          </span>
</div>
</div>
</div>
<script>var media,input,key,value,palette=__md_get("__palette");if(palette&&palette.color){"(prefers-color-scheme)"===palette.color.media&&(media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']"),palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent"));for([key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
<label class="md-header__button md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
</label>
<div class="md-search" data-md-component="search" role="dialog">
<label class="md-search__overlay" for="__search"></label>
<div class="md-search__inner" role="search">
<form class="md-search__form" name="search">
<input aria-label="Search" autocapitalize="off" autocomplete="off" autocorrect="off" class="md-search__input" data-md-component="search-query" name="query" placeholder="Search" required="" spellcheck="false" type="text"/>
<label class="md-search__icon md-icon" for="__search">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"></path></svg>
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</label>
<nav aria-label="Search" class="md-search__options">
<button aria-label="Clear" class="md-search__icon md-icon" tabindex="-1" title="Clear" type="reset">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"></path></svg>
</button>
</nav>
</form>
<div class="md-search__output">
<div class="md-search__scrollwrap" data-md-scrollfix="">
<div class="md-search-result" data-md-component="search-result">
<div class="md-search-result__meta">
            Initializing search
          </div>
<ol class="md-search-result__list" role="presentation"></ol>
</div>
</div>
</div>
</div>
</div>
<div class="md-header__source">
<a class="md-source" data-md-component="source" href="https://github.com/aiverify-foundation/moonshot" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
</nav>
</header>
<div class="md-container" data-md-component="container">
<main class="md-main" data-md-component="main">
<div class="md-main__inner md-grid">
<div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation">
<div class="md-sidebar__scrollwrap">
<div class="md-sidebar__inner">
<nav aria-label="Navigation" class="md-nav md-nav--primary md-nav--integrated" data-md-level="0">
<label class="md-nav__title" for="__drawer">
<a aria-label="Moonshot" class="md-nav__button md-logo" data-md-component="logo" href="../.." title="Moonshot">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"></path></svg>
</a>
    Moonshot
  </label>
<div class="md-nav__source">
<a class="md-source" data-md-component="source" href="https://github.com/aiverify-foundation/moonshot" title="Go to repository">
<div class="md-source__icon md-icon">
<svg viewbox="0 0 448 512" xmlns="http://www.w3.org/2000/svg"><!--! Font Awesome Free 6.5.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"></path></svg>
</div>
<div class="md-source__repository">
    GitHub
  </div>
</a>
</div>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../..">
<span class="md-ellipsis">
    Home
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
<span class="md-ellipsis">
    Getting Started
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_2_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_2">
<span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../getting_started/quick_start/">
<span class="md-ellipsis">
    Quick Start Guide
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../getting_started/overview/">
<span class="md-ellipsis">
    Overview
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../getting_started/quick_install/">
<span class="md-ellipsis">
    Quick Install
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../getting_started/first_test/">
<span class="md-ellipsis">
    Your First Test
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
<span class="md-ellipsis">
    Tutorials
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_3">
<span class="md-nav__icon md-icon"></span>
            Tutorials
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_1" id="__nav_3_1_label" tabindex="0">
<span class="md-ellipsis">
    Web UI
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_1">
<span class="md-nav__icon md-icon"></span>
            Web UI
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/web-ui/create_cookbook/">
<span class="md-ellipsis">
    How to Create Custom Cookbook
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/web-ui/create_endpoint/">
<span class="md-ellipsis">
    How to Create Connector Endpoint
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/web-ui/benchmark/">
<span class="md-ellipsis">
    How to Run Benchmark Tests
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/web-ui/redteam/">
<span class="md-ellipsis">
    How to Run Red Teaming
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_2" id="__nav_3_2_label" tabindex="0">
<span class="md-ellipsis">
    CLI
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_2">
<span class="md-nav__icon md-icon"></span>
            CLI
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/cli/create_benchmark_tests/">
<span class="md-ellipsis">
    How to Create Custom Benchmark Tests
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/cli/create_endpoint/">
<span class="md-ellipsis">
    How to Create Connector Endpoint
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/cli/run_benchmark_tests/">
<span class="md-ellipsis">
    How to Run Benchmark Tests
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/cli/run_red_teaming/">
<span class="md-ellipsis">
    How to Run Red Teaming
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_3_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
<span class="md-ellipsis">
    Contributor
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_3_3_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_3_3">
<span class="md-nav__icon md-icon"></span>
            Contributor
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/contributor/configure_web_api/">
<span class="md-ellipsis">
    Configuring Moonshot WebAPI
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../tutorial/contributor/create_connector/">
<span class="md-ellipsis">
    How to Create a Connector
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4" type="checkbox"/>
<label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
<span class="md-ellipsis">
    User Guide
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_4">
<span class="md-nav__icon md-icon"></span>
            User Guide
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1" id="__nav_4_1_label" tabindex="0">
<span class="md-ellipsis">
    Moonshot Web UI
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_1">
<span class="md-nav__icon md-icon"></span>
            Moonshot Web UI
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/web_ui_guide/">
<span class="md-ellipsis">
    Get Started with Moonshot Web UI
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4_1_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1_2" id="__nav_4_1_2_label" tabindex="0">
<span class="md-ellipsis">
    Moonshot Interface
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_1_2_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_1_2">
<span class="md-nav__icon md-icon"></span>
            Moonshot Interface
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/moonshot_interface/homepage/">
<span class="md-ellipsis">
    Home
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/moonshot_interface/endpoint/">
<span class="md-ellipsis">
    Endpoint
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/moonshot_interface/benchmarking/">
<span class="md-ellipsis">
    Benchmarking
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/moonshot_interface/redteaming/">
<span class="md-ellipsis">
    Red Teaming
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/moonshot_interface/history/">
<span class="md-ellipsis">
    History
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/moonshot_interface/utils/">
<span class="md-ellipsis">
    Utils
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4_1_3" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_1_3" id="__nav_4_1_3_label" tabindex="0">
<span class="md-ellipsis">
    Testing Workflow
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_1_3_label" class="md-nav" data-md-level="3">
<label class="md-nav__title" for="__nav_4_1_3">
<span class="md-nav__icon md-icon"></span>
            Testing Workflow
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/choosing_relevant_tests/">
<span class="md-ellipsis">
    Choosing Relevant Tests
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/connecting_to_llms/">
<span class="md-ellipsis">
    Connecting to LLMs
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/running_benchmarks/">
<span class="md-ellipsis">
    Running Benchmarks
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/running_red_teaming/">
<span class="md-ellipsis">
    Conducting Red Teaming
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/web_ui/creating_custom_cookbooks/">
<span class="md-ellipsis">
    Creating Custom Cookbooks
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_4_2" type="checkbox"/>
<label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
<span class="md-ellipsis">
    CLI
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_4_2_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_4_2">
<span class="md-nav__icon md-icon"></span>
            CLI
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/cli/connecting_endpoints/">
<span class="md-ellipsis">
    Connecting to LLMs
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/cli/benchmarking/">
<span class="md-ellipsis">
    Running Benchmark
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/cli/red_teaming/">
<span class="md-ellipsis">
    Running Red Teaming
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../user_guide/cli/add_your_own_tests/">
<span class="md-ellipsis">
    Adding Your Own Tests
  </span>
</a>
</li>
</ul>
</nav>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_5" type="checkbox"/>
<label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
<span class="md-ellipsis">
    API Reference
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_5_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_5">
<span class="md-nav__icon md-icon"></span>
            API Reference
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item md-nav__item--nested">
<input class="md-nav__toggle md-toggle" id="__nav_5_1" type="checkbox"/>
<label class="md-nav__link" for="__nav_5_1" id="__nav_5_1_label" tabindex="0">
<span class="md-ellipsis">
    Moonshot Library
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="false" aria-labelledby="__nav_5_1_label" class="md-nav" data-md-level="2">
<label class="md-nav__title" for="__nav_5_1">
<span class="md-nav__icon md-icon"></span>
            Moonshot Library
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_connector_endpoint/">
<span class="md-ellipsis">
    Connector Endpoint API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_connector/">
<span class="md-ellipsis">
    Connector API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_context_strategy/">
<span class="md-ellipsis">
    Context Strategy API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_cookbook/">
<span class="md-ellipsis">
    Cookbook API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_dataset/">
<span class="md-ellipsis">
    Dataset API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_environment_variables/">
<span class="md-ellipsis">
    Environment Variable API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_metrics/">
<span class="md-ellipsis">
    Metric API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_prompt_template/">
<span class="md-ellipsis">
    Prompt Template API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_recipe/">
<span class="md-ellipsis">
    Recipe API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_red_teaming/">
<span class="md-ellipsis">
    Red Teaming API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_result/">
<span class="md-ellipsis">
    Result API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_run/">
<span class="md-ellipsis">
    Run API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_runner/">
<span class="md-ellipsis">
    Runner API
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/api_session/">
<span class="md-ellipsis">
    Session API
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../api_reference/web_api_swagger/">
<span class="md-ellipsis">
    Web-API
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item md-nav__item--active md-nav__item--nested">
<input checked="" class="md-nav__toggle md-toggle" id="__nav_6" type="checkbox"/>
<label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
<span class="md-ellipsis">
    Resources
  </span>
<span class="md-nav__icon md-icon"></span>
</label>
<nav aria-expanded="true" aria-labelledby="__nav_6_label" class="md-nav" data-md-level="1">
<label class="md-nav__title" for="__nav_6">
<span class="md-nav__icon md-icon"></span>
            Resources
          </label>
<ul class="md-nav__list" data-md-scrollfix="">
<li class="md-nav__item">
<a class="md-nav__link" href="../jupyter_notebook/">
<span class="md-ellipsis">
    Jupyter Notebook
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../cookbooks/">
<span class="md-ellipsis">
    Cookbook
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../recipes/">
<span class="md-ellipsis">
    Recipes
  </span>
</a>
</li>
<li class="md-nav__item md-nav__item--active">
<input class="md-nav__toggle md-toggle" id="__toc" type="checkbox"/>
<a class="md-nav__link md-nav__link--active" href="./">
<span class="md-ellipsis">
    Datasets
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../metrics/">
<span class="md-ellipsis">
    Metrics
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../attack_modules/">
<span class="md-ellipsis">
    Attack Modules
  </span>
</a>
</li>
</ul>
</nav>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../contributing/">
<span class="md-ellipsis">
    Contributor Guide
  </span>
</a>
</li>
<li class="md-nav__item">
<a class="md-nav__link" href="../../common_issues/">
<span class="md-ellipsis">
    Common Issues
  </span>
</a>
</li>
</ul>
</nav>
</div>
</div>
</div>
<div class="md-content" data-md-component="content">
<article class="md-content__inner md-typeset">
<h1 id="list-of-datasets">List of Datasets</h1>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th>License</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr>
<td>squad-shifts-tnf</td>
<td>Zero-shot reading comprehension on paragraphs and questions from squadshifts</td>
<td>-</td>
<td>https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/squad_shifts</td>
</tr>
<tr>
<td>BBQ-lite on religion - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on religion, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>advglue</td>
<td>Adversarial GLUE Benchmark (AdvGLUE) is a comprehensive robustness evaluation benchmark that focuses on the adversarial robustness evaluation of language models.</td>
<td>-</td>
<td>https://github.com/AI-secure/adversarial-glue</td>
</tr>
<tr>
<td>Food in Singapore</td>
<td>Contain prompts that test model's udnerstanding in Food, in True/False format</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>MedMCQA</td>
<td>MedMCQ is a large-scale, multiple-choice question answering dataset designed to address realworld medical entrance exam questions. It contains more than 194k high-quality AIIMS &amp; NEET PG entrnace exam MCQs covering 2.4k healthcare topics and 21 medical subjects.</td>
<td>MIT License</td>
<td>https://github.com/MedMCQA/MedMCQA</td>
</tr>
<tr>
<td>tamil-thirukural</td>
<td>This dataset is used to test the comprehension abilities for the Thirukkural. Thirukkural is a classic Tamil literature composed by the ancient Tamil poet Thiruvalluvar. It consists of 1330 couplets (kurals) that are grouped into 133 chapters, each containing 10 couplets.</td>
<td>Creative Commons Attribution 4.0 International</td>
<td>https://github.com/vijayanandrp/Thirukkural-Tamil-Dataset</td>
</tr>
<tr>
<td>RealtimeQA</td>
<td>RealTime QA is a dynamic question answering (QA) platform that inquires about the present.</td>
<td>-</td>
<td>https://github.com/realtimeqa/realtimeqa_public</td>
</tr>
<tr>
<td>sg-university-tutorial-questions-legal</td>
<td>Contain tutorial questions ans answers from Singapore's Universities to test model's ability in understanding legal context in Singapore</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>BBQ-lite on gender - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on gender, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>ARC-Easy</td>
<td>A dataset of genuine grade-school level, multiple-choice science questions in advanced Q&amp;A. This is the challenge set.</td>
<td>CC BY-SA</td>
<td>https://allenai.org/data/arc</td>
</tr>
<tr>
<td>BBQ-lite on nationality - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on nationality, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>m3exam-vietnamese</td>
<td>This dataset contains local exam questions for testing Vietnamese capability.</td>
<td>CC BY-NC-SA</td>
<td>https://github.com/DAMO-NLP-SG/M3Exam</td>
</tr>
<tr>
<td>BBQ-lite on physical-appearance - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on physical-appearance, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>tanglish-tweets-SA</td>
<td>Code-mixed Tamil and English tweets curated for the sentiment analysis task.</td>
<td>CC0: Public Domain</td>
<td>-</td>
</tr>
<tr>
<td>Ethics-Commonsense-Hard</td>
<td>This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept.</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/ethics/</td>
</tr>
<tr>
<td>uciadult</td>
<td>The UCI Adult dataset has been used widely used to assess fairness.</td>
<td>Creative Commons Attribution 4.0 International</td>
<td>https://archive.ics.uci.edu/dataset/2/adult</td>
</tr>
<tr>
<td>BBQ-lite on age - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on age, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>MLC Baseline - Suicide &amp; Self-Harm</td>
<td>Responses that enable, encourage, or endorse acts of intentional self-harm.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>sg-legal-glossary</td>
<td>A list of singapore legal terms extracted from SICC and Judiciary websites.</td>
<td>-</td>
<td>https://www.sicc.gov.sg/glossary-of-legal-terms</td>
</tr>
<tr>
<td>MLC Baseline - Hate</td>
<td>Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>BBQ-lite on age - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on age, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>cause_and_effect</td>
<td>This recipe measures if the model is able to distinguish and understand cause and effect. The higher the grade, the better the system can perform this capability.</td>
<td>-</td>
<td>https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/cause_and_effect</td>
</tr>
<tr>
<td>BBQ-lite on race-x-gender - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on race-x-gender, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>TruthfulQA (MCQ Version)</td>
<td>TruthfulQA aims to measure the the truthfulness of a model. This dataset uses a multiple choice format.</td>
<td>Apache-2.0</td>
<td>https://github.com/sylinrl/TruthfulQA</td>
</tr>
<tr>
<td>Ethics-Commonsense-Hard</td>
<td>This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept.</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/ethics/</td>
</tr>
<tr>
<td>PubMedQA</td>
<td>PubMedQA is a large-scale, multiple-choice question answering dataset designed to address realworld medical entrance exam questions. It contains more than 194k high-quality AIIMS &amp; NEET PG entrnace exam MCQs covering 2.4k healthcare topics and 21 medical subjects.</td>
<td>MIT License</td>
<td>https://github.com/MedMCQA/MedMCQA</td>
</tr>
<tr>
<td>Facts about Singapore in True and False</td>
<td>Contain prompts that contains facts about Singapore, in True/False format</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>RealToxicityPrompts</td>
<td>RealToxicityPrompts aims to measure the model's ability in identify toxic sentences.</td>
<td>Apache-2.0</td>
<td>https://github.com/allenai/real-toxicity-prompts/</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>gre_reading_comprehension</td>
<td>To measure the model/'s ability to summarize text, infer and deduce knowledge from context, and match the context.</td>
<td>-</td>
<td>https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/gre_reading_comprehension</td>
</tr>
<tr>
<td>MMLU College Medicine</td>
<td>MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU College Medicine</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>BBQ-lite on race-x-ses - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on race-x-ses, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Singapore Polical History</td>
<td>Contain questions about Singapore's key historical events in political.</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>ChallengingToxicityPrompts</td>
<td>ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences.</td>
<td>CC BY-SA 4.0</td>
<td>https://github.com/AI-secure/DecodingTrust</td>
</tr>
<tr>
<td>MLC Baseline - Violent Crimes</td>
<td>Responses that enable, encourage, or endorse the commission of violent crimes.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>MMLU Clinical Knowledge</td>
<td>MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Clinical Knowledge</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>coqa_conversational_question_answering</td>
<td>To measure the ability of machines to understand a text passage and answer a series of interconnected questions</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Singapore Transport System</td>
<td>Contain questions about Singapore's public housing system</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>ChallengingToxicityPrompts</td>
<td>ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences.</td>
<td>CC BY-SA 4.0</td>
<td>https://github.com/AI-secure/DecodingTrust</td>
</tr>
<tr>
<td>BBQ-lite on race-x-ses - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on race-x-ses, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>MLC Baseline - Chemical, Biological, Radiological, Nuclear, and Explosives</td>
<td>Responses that enable, encourage, or endorse the creation of weapons of mass destruction.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>BBQ-lite on gender - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on gender, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>BBQ-lite on sexual-orientation - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on sexual-orientation, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>MLC Baseline - Chemical, Biological, Radiological, Nuclear, and Explosives</td>
<td>Responses that enable, encourage, or endorse the creation of weapons of mass destruction.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>MLC Baseline - Hate</td>
<td>Responses that demean or dehumanize people on the basis of their sensitive, personal characteristics.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Winogrande</td>
<td>This dataset is used for commonsense reasoning, expert-crafted pronoun resolution problems designed to be unsolvable for statistical models.</td>
<td>Apache-2.0</td>
<td>https://github.com/allenai/winogrande</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Contextual Parametric Knowledge Conflicts</td>
<td>To measure the model/’s ability in making informed predictions</td>
<td>-</td>
<td>https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/contextual_parametric_knowledge_conflicts</td>
</tr>
<tr>
<td>MMLU Anatomy</td>
<td>MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Anatomy</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>Singapore Transport System</td>
<td>Contain questions about Singapore's transport system</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>truthfulqa</td>
<td>TruthfulQA aims to measure the the truthfulness of a model.</td>
<td>Apache-2.0</td>
<td>https://github.com/sylinrl/TruthfulQA</td>
</tr>
<tr>
<td>ARC-Easy</td>
<td>A dataset of genuine grade-school level, multiple-choice science questions in advanced Q&amp;A. This is the easy set.</td>
<td>CC BY-SA</td>
<td>https://allenai.org/data/arc</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Iconic Places in Singapore</td>
<td>Contain questions about Singapore's iconic places.</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>MLC Baseline - Sex-Related Crimes</td>
<td>Responses that enable, encourage, or endorse the commission of sex-related crimes.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Analogical Similarity</td>
<td>To measure the model’s ability in discriminating between different degrees of analogical similarity in two given episodes</td>
<td>-</td>
<td>https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/analogical_similarity</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>BBQ-lite on race-ethnicity - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on race-ethnicity, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>GSM8K</td>
<td>This dataset consists of high quality grade school math problems created by human. These problems take between 2 and 8 steps to solve, and usually requires a sequence of elementary calculations.</td>
<td>MIT License</td>
<td>https://github.com/openai/grade-school-math</td>
</tr>
<tr>
<td>MLC Baseline - Child Abuse and Exploitation</td>
<td>Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>m3exam-indonesian</td>
<td>This dataset contains local exam questions for testing Indonesian capability.</td>
<td>CC BY-NC-SA</td>
<td>https://github.com/DAMO-NLP-SG/M3Exam</td>
</tr>
<tr>
<td>BBQ-lite on race-x-gender - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on race-x-gender, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>MLC Baseline - Sex-Related Crimes</td>
<td>Responses that enable, encourage, or endorse the commission of sex-related crimes.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>BBQ-lite on disability-status - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on disability-status, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>MMLU College Biology</td>
<td>MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU College Biology</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>ChallengingToxicityPrompts</td>
<td>ChallengingToxicityPrompts was created by the authors of DecodingTrust, with the aim to measure the model's ability in identify toxic sentences.</td>
<td>CC BY-SA 4.0</td>
<td>https://github.com/AI-secure/DecodingTrust</td>
</tr>
<tr>
<td>BBQ-lite on religion - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on religion, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>MLC Baseline - Child Abuse and Exploitation</td>
<td>Responses that contain, describe, enable, encourage, or endorse the sexual abuse of children.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>MLC Baseline - Non-Violent Crimes</td>
<td>Responses that enable, encourage, or endorse the commission of non-violent crimes.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>MLC Baseline - Non-Violent Crimes</td>
<td>Responses that enable, encourage, or endorse the commission of non-violent crimes.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>List of Occupations</td>
<td>This dataset contains a list of occupations collected from various websites (e.g., MoM of Singapore). The dataset can be used to test job-related applications.</td>
<td>MIT License</td>
<td>IMDA</td>
</tr>
<tr>
<td>In-the-wild Jailbreak Dataset</td>
<td>This dataset contains jailbreak prompts that were collected from various places (e.g., Discord).</td>
<td>MIT license</td>
<td>https://github.com/verazuo/jailbreak_llms</td>
</tr>
<tr>
<td>MLC Baseline - Suicide &amp; Self-Harm</td>
<td>Responses that enable, encourage, or endorse acts of intentional self-harm.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>MLC Baseline - Violent Crimes</td>
<td>Responses that enable, encourage, or endorse the commission of violent crimes.</td>
<td>-</td>
<td>-</td>
</tr>
<tr>
<td>Ethics-Commonsense-Hard</td>
<td>This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept.</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/ethics/</td>
</tr>
<tr>
<td>auto_categorization</td>
<td>To measure the model's ability in categorising elements into groups.</td>
<td>-</td>
<td>https://github.com/google/BIG-bench/tree/main/bigbench/benchmark_tasks/auto_categorization</td>
</tr>
<tr>
<td>BBQ-lite on sexual-orientation - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on sexual-orientation, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>tamil-news-classification</td>
<td>This dataset is used to classify a static set of Tamil News. The task is to classify news to its respective category. The dataset has 6 news categories - "tamilnadu", "india", "cinema", "sports", "politics", "world".</td>
<td>GNU General Public License v3.0</td>
<td>-</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>C-Values - Values of Chinese Large Language attack_modules</td>
<td>This dataset contains prompts that can measure the alignment ability of LLMs in both safety and responsibility in Chinese Language.</td>
<td>Apache-2.0 license</td>
<td>-</td>
</tr>
<tr>
<td>BBQ-lite on physical-appearance - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on physical-appearance, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>enronemail</td>
<td>The Enron email dataset is aimed at evaluating if there is leakage of private information. The dataset was used in DecodingTrust as part of its privacy evaluation.</td>
<td>Apache-2.0</td>
<td>https://github.com/ParakweetLabs/EmailIntentDataSet</td>
</tr>
<tr>
<td>m3exam-thai</td>
<td>This dataset contains local exam questions for testing Thai capability.</td>
<td>CC BY-NC-SA</td>
<td>https://github.com/DAMO-NLP-SG/M3Exam</td>
</tr>
<tr>
<td>MMLU Medical Genetics</td>
<td>MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Medical Genetics</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>BBQ-lite on ses - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on ses, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>truthfulqa</td>
<td>TruthfulQA aims to measure the the truthfulness of a model.</td>
<td>Apache-2.0</td>
<td>https://github.com/sylinrl/TruthfulQA</td>
</tr>
<tr>
<td>Ethics-Commonsense-Hard</td>
<td>This dataset contains prompts that embedded the body of moral standards and principles that most people intuitively accept.</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/ethics/</td>
</tr>
<tr>
<td>Places in Singapore</td>
<td>Contain prompts that test model's udnerstanding places in Singapore, in True/False format</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>BBQ-lite on nationality - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on nationality, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>MMLU Professional Medicine.json</td>
<td>MMLU measure knowledge acquired during pretraining by evaluating models exclusively in zero-shot and few-shot settings. This particular dataset contains questions on MMLU Professional Medicine.json</td>
<td>MIT License</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>BBQ-lite on race-ethnicity - Ambiguous Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on race-ethnicity, containing only the ambiguous questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>winobias-variation1</td>
<td>This dataset contains gender-bias based on the professions from the Labor Force Statistics (https://www.bls.gov/cps/cpsaat11.htm), which contain some gender-bias.</td>
<td>MIT License</td>
<td>https://github.com/uclanlp/corefBias/tree/master/WinoBias/wino</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>HellaSwag</td>
<td>This dataset is used to evaluate commonsense with questions that are trivial for humans but difficult for state-of-the-art models.</td>
<td>MIT License</td>
<td>https://github.com/rowanz/hellaswag</td>
</tr>
<tr>
<td>BBQ-lite on ses - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on ses, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
<tr>
<td>Safety Benchmark (Singapore Context)</td>
<td>Contain prompts that test safety in Singapore-context</td>
<td>Apache-2.0</td>
<td>IMDA</td>
</tr>
<tr>
<td>MedQA (US)</td>
<td>MedQA is a free-form multiple-choice OpenQA dataset for solving medical problems. These are collected from the professional medical board exams. We extracted the list of MCQ questions from the US in this dataset.</td>
<td>MIT License</td>
<td>https://github.com/jind11/MedQA</td>
</tr>
<tr>
<td>uciadult</td>
<td>The UCI adult dataset, created in 1996, is used to train models to predict whether a person's income will exceed $50K/yr based on census data. Also known as "Census Income" dataset.</td>
<td>Creative Commons Attribution 4.0 International</td>
<td>https://archive.ics.uci.edu/dataset/2/adult</td>
</tr>
<tr>
<td>MMLU</td>
<td>This dataset covers 57 tasks including elementary mathemathics, US history, computer science, law, and more.</td>
<td>MIT license</td>
<td>https://github.com/hendrycks/test</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>Chinese Version - Bias Benchmark for QA</td>
<td>This aims to measure social biases across 9 different categories in Chinese language.</td>
<td>-</td>
<td>https://github.com/YFHuangxxxx/CBBQ</td>
</tr>
<tr>
<td>BBQ-lite on disability-status - Disambiguated Questions</td>
<td>This dataset is an excerpt from Bias Benchmark from QA on disability-status, containing only the disambiguated questions.</td>
<td>CC-BY-4.0 license</td>
<td>https://arxiv.org/pdf/2110.08193v2</td>
</tr>
</tbody>
</table>
</article>
</div>
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
</div>
<button class="md-top md-icon" data-md-component="top" hidden="" type="button">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"></path></svg>
  Back to top
</button>
</main>
<footer class="md-footer">
<nav aria-label="Footer" class="md-footer__inner md-grid">
<a aria-label="Previous: Recipes" class="md-footer__link md-footer__link--prev" href="../recipes/">
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"></path></svg>
</div>
<div class="md-footer__title">
<span class="md-footer__direction">
                Previous
              </span>
<div class="md-ellipsis">
                Recipes
              </div>
</div>
</a>
<a aria-label="Next: Metrics" class="md-footer__link md-footer__link--next" href="../metrics/">
<div class="md-footer__title">
<span class="md-footer__direction">
                Next
              </span>
<div class="md-ellipsis">
                Metrics
              </div>
</div>
<div class="md-footer__button md-icon">
<svg viewbox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"></path></svg>
</div>
</a>
</nav>
<div class="md-footer-meta md-typeset">
<div class="md-footer-meta__inner md-grid">
<div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" rel="noopener" target="_blank">
      Material for MkDocs
    </a>
</div>
</div>
</div>
</footer>
</div>
<div class="md-dialog" data-md-component="dialog">
<div class="md-dialog__inner md-typeset"></div>
</div>
<script id="__config" type="application/json">{"base": "../..", "features": ["navigation.footer", "navigation.top", "toc.integrate", "toc.follow"], "search": "../../assets/javascripts/workers/search.b8dbb3d2.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
<script src="../../assets/javascripts/bundle.081f42fc.min.js"></script>
<script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body>
</html>