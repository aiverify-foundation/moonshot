{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1348f980-76e0-4635-afbc-e708aa19970b",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Advanced Workflow - Test Your Own Custom Connector\n",
    "\n",
    "**Scenario**: You are a tester and you want to evaluate your Math application that uses Langchain. In this case, the existing list of connectors in Moonshot is unable to communicate to this custom Math application. How do we create a custom connector to use Moonshot to test this custom application?\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Create your own `connector` in Moonshot\n",
    "- Create a new `connector endpoint` in Moonshot\n",
    "- Run a new `recipe` on this custom connector\n",
    "\n",
    "**Before starting this tutorial, please make sure you have already installed `moonshot` and `moonshot-data`.** Otherwise, please follow this tutorial to install and configure Moonshot first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca988355-1937-4d06-9df0-606b13f29ec6",
   "metadata": {},
   "source": [
    "## Import Moonshot Library API\n",
    "\n",
    "In this section, we prepare our Jupyter notebook environment by importing necessary libraries required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "315fb2da-9dce-4851-a82e-e852f133b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moonshot Framework API Imports\n",
    "# These imports from the Moonshot framework allow us to interact with the API, \n",
    "# creating and managing various components such as recipes, cookbooks, and endpoints.\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "# Ensure that the root of the Moonshot framework is in the system path for module importing.\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from moonshot.api import (\n",
    "    api_create_endpoint,\n",
    "    api_get_all_recipe,\n",
    "    api_create_recipe,\n",
    "    api_create_cookbook,\n",
    "    api_get_all_runner,\n",
    "    api_load_runner,\n",
    "    api_read_result,\n",
    "    api_set_environment_variables\n",
    ")\n",
    "\n",
    "# modify moonshot_path to point to your own copy of moonshot-data\n",
    "moonshot_path = \"./data/\"\n",
    "env = {\n",
    "    \"ATTACK_MODULES\": os.path.join(moonshot_path, \"attack-modules\"),\n",
    "    \"BOOKMARKS\": os.path.join(moonshot_path, \"generated-outputs/bookmarks\"),\n",
    "    \"CONNECTORS\": os.path.join(moonshot_path, \"connectors\"),\n",
    "    \"CONNECTORS_ENDPOINTS\": os.path.join(moonshot_path, \"connectors-endpoints\"),\n",
    "    \"CONTEXT_STRATEGY\": os.path.join(moonshot_path, \"context-strategy\"),\n",
    "    \"COOKBOOKS\": os.path.join(moonshot_path, \"cookbooks\"),\n",
    "    \"DATABASES\": os.path.join(moonshot_path, \"generated-outputs/databases\"),\n",
    "    \"DATABASES_MODULES\": os.path.join(moonshot_path, \"databases-modules\"),\n",
    "    \"DATASETS\": os.path.join(moonshot_path, \"datasets\"),\n",
    "    \"IO_MODULES\": os.path.join(moonshot_path, \"io-modules\"),\n",
    "    \"METRICS\": os.path.join(moonshot_path, \"metrics\"),\n",
    "    \"PROMPT_TEMPLATES\": os.path.join(moonshot_path, \"prompt-templates\"),\n",
    "    \"RECIPES\": os.path.join(moonshot_path, \"recipes\"),\n",
    "    \"RESULTS\": os.path.join(moonshot_path, \"generated-outputs/results\"),\n",
    "    \"RESULTS_MODULES\": os.path.join(moonshot_path, \"results-modules\"),\n",
    "    \"RUNNERS\": os.path.join(moonshot_path, \"generated-outputs/runners\"),\n",
    "    \"RUNNERS_MODULES\": os.path.join(moonshot_path, \"runners-modules\"),\n",
    "}\n",
    "\n",
    "# Apply the environment variables to configure the Moonshot framework.\n",
    "api_set_environment_variables(env)\n",
    "\n",
    "# Note: there will be no printout if the environment variables are set successfully"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbecb59b-f86c-4aa9-b572-e57c61cf8e10",
   "metadata": {},
   "source": [
    "## Create Custom `Connector` \n",
    "\n",
    "In this section, we will learn how to create a custom `connector` and a `connector endpoint` to communicate to a custom Math application. We will use Langchain Agent and OpenAI to create this application.\n",
    "\n",
    "A Langchain Agent can contain one or more `Tool`. In our application, we will create two tools:\n",
    "\n",
    "1) Math Tool using `LLMMathChain`\n",
    "2) Assistant using `LLMChain`\n",
    "\n",
    "Our assistant will use our Math Tool to answer math questions. This assistant will reply in the following format:\n",
    "\n",
    "`{\"input\": <prompt>, \"output\": <response>}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a056e-9f29-4a7b-be3c-a0d9302b705c",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4ba39-4d9a-437c-b4d3-60dd103ed5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install langchain library\n",
    "!pip install langchain langchain_openai numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74548164-b09b-41f1-bb66-e42b7081e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc8d5f-12b1-40a6-8833-aa08e29c67fb",
   "metadata": {},
   "source": [
    "### Connector Code\n",
    "\n",
    "Copy the following code in the cell to `./{moonshot_path}/connectors/custom-app.py`, where `{moonshot_path}` is the path of your own copy of moonshot-data you specified in the first cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39531e20-0ea0-440a-9ddd-f14207f66a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "\n",
    "from moonshot.src.connectors.connector_response import ConnectorResponse\n",
    "from moonshot.src.connectors.connector import Connector, perform_retry\n",
    "from moonshot.src.connectors_endpoints.connector_endpoint_arguments import (\n",
    "    ConnectorEndpointArguments,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MathApplicationConnector(Connector):\n",
    "    def __init__(self, ep_arguments: ConnectorEndpointArguments):\n",
    "        # Initialize super class\n",
    "        super().__init__(ep_arguments)\n",
    "\n",
    "        self.load_agent()\n",
    "\n",
    "        # Set the model to use and remove it from optional_params if it exists\n",
    "        self.model = self.optional_params.get(\"model\", \"\")\n",
    "\n",
    "    def load_agent(self):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = self.token\n",
    "        \n",
    "        my_llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "        problem_chain = LLMMathChain.from_llm(llm=my_llm)\n",
    "        \n",
    "        math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                                       func=problem_chain.run,\n",
    "                                       description=\"This agent answers Math problems.\")\n",
    "        \n",
    "        template = \"\"\"You are a math agent tasked to solve simple math problems. \n",
    "        The answer must be logically arrived.\n",
    "        Your answer must clearly detail the steps involved.\n",
    "        You must give the final answer in the problem.\n",
    "        \n",
    "        Here's the problem {question}\\n\"\"\"\n",
    "        \n",
    "        math_assistant_template = PromptTemplate(input_variables=[\"question\"],\n",
    "                                                 template=template)\n",
    "        math_assistant = LLMChain(llm=my_llm,\n",
    "                                  prompt=math_assistant_template)\n",
    "        math_assistant_tool = Tool.from_function(name=\"Math Assistant\",\n",
    "                                                 func=math_assistant.run,\n",
    "                                                 description=\"Answer logic questions.\")\n",
    "\n",
    "        # Load the agent through Langchain\n",
    "        self._client = initialize_agent(\n",
    "            tools=[math_tool, math_assistant_tool],\n",
    "            llm=my_llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=False,\n",
    "            handle_parsing_errors=True)\n",
    "\n",
    "    @Connector.rate_limited\n",
    "    @perform_retry\n",
    "    async def get_response(self, prompt: str) -> ConnectorResponse:\n",
    "        \"\"\"\n",
    "        Asynchronously sends a prompt to the math agent and returns the generated response.\n",
    "\n",
    "        This method constructs a request with the given prompt, optionally prepended and appended with\n",
    "        predefined strings, and sends it to the math agent. The method then awaits the response from the agent,\n",
    "        processes it, and returns the resulting message content wrapped in a ConnectorResponse object.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The input prompt to send to the math agent.\n",
    "\n",
    "        Returns:\n",
    "            ConnectorResponse: An object containing the text response generated by the math agent.\n",
    "        \"\"\"\n",
    "        connector_prompt = f\"{self.pre_prompt}{prompt}{self.post_prompt}\"\n",
    "        response = self._client.invoke({\"input\": connector_prompt})\n",
    "        return ConnectorResponse(response=await self._process_response(response))\n",
    "    async def _process_response(self, response: Any) -> str:\n",
    "        \"\"\"\n",
    "        Process the response and return the message content as a string.\n",
    "\n",
    "        This method processes the response received from API call. It extracts the message content from the first choice\n",
    "        provided in the response, which is expected to contain the relevant information or answer.\n",
    "\n",
    "        Args:\n",
    "            response (Any): The response object received from an API call. It is expected to\n",
    "            follow the structure of OpenAI's chat completion response.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the message content from the first choice in the response. This\n",
    "            content represents the AI-generated text based on the input prompt.\n",
    "        \"\"\"\n",
    "        return response[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da516bb-7897-4e82-aa57-db444e91d790",
   "metadata": {},
   "source": [
    "## Create `endpoint` using custom connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ce90d2c-f547-44ca-b1e7-5ed88ced62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The newly created endpoint id: my-custom-math\n"
     ]
    }
   ],
   "source": [
    "endpoint_id = api_create_endpoint(\n",
    "    \"my-custom-math\",        # name: Assign a unique name to identify this endpoint later.\n",
    "    \"custom-app\",            # connector_type: Specify the connector type for the model you want to evaluate.\n",
    "    \"\",                      # uri: Leave blank as the OpenAI library handles the connection.\n",
    "    \"ADD_NEW_TOKEN_HERE\",    # token: Insert your OpenAI API token here.\n",
    "    1,                       # max_calls_per_second: Set the maximum number of calls allowed per second.\n",
    "    1,                       # max_concurrency: Set the maximum number of concurrent calls.\n",
    "    \"gpt-4o\",                # model: Define the model version to use. \n",
    "    \n",
    "    # params: Include any additional parameters required for this model.\n",
    "    {\n",
    "        \"timeout\": 300,      # timeout: Define the timeout for API calls in seconds.\n",
    "        \"max_attempts\": 3,   # max_attempts: Define the max number of retry attempts. \n",
    "        \"temperature\": 0.5,  # temperature: Set the temperature for response variability.\n",
    "    }  \n",
    ")\n",
    "print(f\"The newly created endpoint id: {endpoint_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94cbfd-2bd2-4123-b663-a56dd9129aac",
   "metadata": {},
   "source": [
    "### Create dataset and recipe to test my custom endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "539a0eb4-d039-4b9d-9d5c-db4782b6b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'math-dataset' has been created.\n"
     ]
    }
   ],
   "source": [
    "math_dataset = {\n",
    "    \"name\": \"Math Dataset\",\n",
    "    \"description\":\"Measures whether the model knows how to do math\",\n",
    "    \"license\": \"MIT license\",\n",
    "    \"reference\": \"\",\n",
    "    \"examples\": [\n",
    "        {\n",
    "            \"input\": \"1 + 1 = ?\",\n",
    "            \"target\": \"2\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"10 * 5 = ?\",\n",
    "            \"target\": \"50\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Jane has 5 apples. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
    "            \"target\": \"12\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"John has 15 pears. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
    "            \"target\": \"10\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Xiaoming has 3 meat buns. He was given another 10 vegetable buns. How many meat buns does he have?\",\n",
    "            \"target\": \"3\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "in_file = f\"{moonshot_path}/datasets/math-dataset.json\"\n",
    "json.dump(math_dataset, open(in_file, \"w+\"), indent=2)\n",
    "if os.path.exists(in_file):\n",
    "     print(f\"Dataset 'math-dataset' has been created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbfdd440-12be-4623-9cc8-9644423be021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe 'math-questions' has been created.\n"
     ]
    }
   ],
   "source": [
    "test_recipe = api_create_recipe(\n",
    "    \"Math Questions\", # name (mandatory)\n",
    "    \"This recipe is created to test model's ability in answering math questions.\", # description (mandatory)\n",
    "    [\"chatbot\"], # tags (optional)\n",
    "    [\"capability\"], # category (optional)\n",
    "    [\"math-dataset\"], # filename of the dataset (mandatory)\n",
    "    [], # prompt templates (optional)\n",
    "    [\"exactstrmatch\"], # metrics (mandatory)\n",
    "    { # grading scale, optional\n",
    "        \"A\": [\n",
    "            80,\n",
    "            100\n",
    "        ],\n",
    "        \"B\": [\n",
    "            60,\n",
    "            79\n",
    "        ],\n",
    "        \"C\": [\n",
    "            40,\n",
    "            59\n",
    "        ],\n",
    "        \"D\": [\n",
    "            20,\n",
    "            39\n",
    "        ],\n",
    "        \"E\": [\n",
    "            0,\n",
    "            19\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Recipe '{test_recipe}' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff0cc-7904-48f0-95d5-c09bf6aedb20",
   "metadata": {},
   "source": [
    "### Testing Custom Endpoint with New Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4347f34-e954-4211-bff0-2675fe5fd2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-08 18:59:50,337 [INFO][runner.py::run_recipes(354)] [Runner] math-recipe - Running benchmark recipe run...\n",
      "/Users/kkok/codes/moonshot_test/moonshot/examples/jupyter-notebook/moonshot-data/connectors/custom-app.py:49: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  math_assistant = LLMChain(llm=my_llm,\n",
      "/Users/kkok/codes/moonshot_test/moonshot/examples/jupyter-notebook/moonshot-data/connectors/custom-app.py:56: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 1.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  self._client = initialize_agent(\n",
      "2024-11-08 18:59:50,457 [INFO][benchmarking.py::generate(156)] [Benchmarking] Running recipes (['math-questions'])...\n",
      "2024-11-08 18:59:50,458 [INFO][benchmarking.py::generate(160)] [Benchmarking] Running recipe math-questions... (1/1)\n",
      "2024-11-08 18:59:50,462 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 0.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-08 18:59:53,351 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 1.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-08 18:59:55,912 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 2.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-08 18:59:58,572 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 3.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-08 19:00:03,591 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 4.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "2024-11-08 19:00:06,145 [INFO][benchmarking.py::generate(190)] [Benchmarking] Run took 15.6877s\n",
      "2024-11-08 19:00:06,147 [INFO][benchmarking.py::generate(245)] [Benchmarking] Preparing results took 0.0000s\n",
      "2024-11-08 19:00:06,151 [INFO][benchmarking-result.py::generate(58)] [BenchmarkingResult] Generate results took 0.0034s\n",
      "2024-11-08 19:00:06,153 [INFO][runner.py::run_recipes(380)] [Runner] math-recipe - Benchmark recipe run completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"id\": \"math-recipe\",\n",
      "    \"start_time\": \"2024-11-08 18:59:50\",\n",
      "    \"end_time\": \"2024-11-08 19:00:06\",\n",
      "    \"duration\": 15,\n",
      "    \"status\": \"completed\",\n",
      "    \"recipes\": [\n",
      "      \"math-questions\"\n",
      "    ],\n",
      "    \"cookbooks\": null,\n",
      "    \"endpoints\": [\n",
      "      \"my-custom-math\"\n",
      "    ],\n",
      "    \"num_of_prompts\": 5,\n",
      "    \"random_seed\": 0,\n",
      "    \"system_prompt\": \"\"\n",
      "  },\n",
      "  \"results\": {\n",
      "    \"recipes\": [\n",
      "      {\n",
      "        \"id\": \"math-questions\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"model_id\": \"my-custom-math\",\n",
      "            \"dataset_id\": \"math-dataset\",\n",
      "            \"prompt_template_id\": \"no-template\",\n",
      "            \"data\": [\n",
      "              {\n",
      "                \"prompt\": \"1 + 1 = ?\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"2\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"2\",\n",
      "                \"duration\": 2.885328042029869\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"10 * 5 = ?\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"50\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"50\",\n",
      "                \"duration\": 2.5577816659933887\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"Jane has 5 apples. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"12\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"12\",\n",
      "                \"duration\": 2.6573317910078913\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"John has 15 pears. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"John has 22 apples.\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"10\",\n",
      "                \"duration\": 5.015393582987599\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"Xiaoming has 3 meat buns. He was given another 10 vegetable buns. How many meat buns does he have?\",\n",
      "                \"predicted_result\": {\n",
      "                  \"response\": \"13\",\n",
      "                  \"context\": []\n",
      "                },\n",
      "                \"target\": \"3\",\n",
      "                \"duration\": 2.5499268329585902\n",
      "              }\n",
      "            ],\n",
      "            \"metrics\": [\n",
      "              {\n",
      "                \"accuracy\": 60.0,\n",
      "                \"grading_criteria\": {\n",
      "                  \"accuracy\": 60.0\n",
      "                }\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"evaluation_summary\": [\n",
      "          {\n",
      "            \"model_id\": \"my-custom-math\",\n",
      "            \"num_of_prompts\": 5,\n",
      "            \"avg_grade_value\": 60.0,\n",
      "            \"grade\": \"B\"\n",
      "          }\n",
      "        ],\n",
      "        \"grading_scale\": {\n",
      "          \"A\": [\n",
      "            80,\n",
      "            100\n",
      "          ],\n",
      "          \"B\": [\n",
      "            60,\n",
      "            79\n",
      "          ],\n",
      "          \"C\": [\n",
      "            40,\n",
      "            59\n",
      "          ],\n",
      "          \"D\": [\n",
      "            20,\n",
      "            39\n",
      "          ],\n",
      "          \"E\": [\n",
      "            0,\n",
      "            19\n",
      "          ]\n",
      "        },\n",
      "        \"total_num_of_prompts\": 5\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from slugify import slugify\n",
    "from moonshot.api import api_get_all_run, api_create_runner, api_get_all_runner_name\n",
    "\n",
    "name = \"math recipe\" # Indicate the name\n",
    "recipes = [\"math-questions\"] # Test one recipe math-questions. You can add more recipes in the list to test as well\n",
    "endpoints = [\"my-custom-math\"]  # Test against 1 endpoint, my-custom-math\n",
    "num_of_prompts = 5 # The number of prompt(s) to run from EACH dataset in the cookbook; 0 means using all prompts in dataset\n",
    "\n",
    "# Optional fields\n",
    "random_seed = 0   # Default: 0; this allows for randomness in dataset selection when num_of_prompts are set\n",
    "system_prompt = \"\"  # Default: \"\"; this allows setting the system prompt for the endpoints\n",
    "\n",
    "# Advanced user - Modify runner processing module and result processing module\n",
    "# Default: benchmarking and benchmarking-result. Change it to your module name if you have your own runner and/or result module\n",
    "runner_proc_module = \"benchmarking\"  # Default: \"benchmarking\"\n",
    "result_proc_module = \"benchmarking-result\"  # Default: \"benchmarking-result\"\n",
    "\n",
    "# Run the recipe with the defined endpoint(s)\n",
    "# If the id exists, it will perform a load on the runner, instead of creating a new runner.\n",
    "# Using an existing runner allows the new run to possibly use cached results from previous runs, which greatly reduces the run time\n",
    "slugify_id = slugify(name, lowercase=True)\n",
    "if slugify_id in api_get_all_runner_name():\n",
    "    rec_runner = api_load_runner(slugify_id)\n",
    "else:\n",
    "    rec_runner = api_create_runner(name, endpoints)\n",
    "\n",
    "# run_recies is an async function. Currently there is no sync version.\n",
    "# We will get an existing event loop and execute the run recipes process.\n",
    "await rec_runner.run_recipes(\n",
    "    recipes,\n",
    "    num_of_prompts,\n",
    "    random_seed,\n",
    "    system_prompt,\n",
    "    runner_proc_module,\n",
    "    result_proc_module,\n",
    ")\n",
    "await rec_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
    "\n",
    "# Display results\n",
    "runner_runs = api_get_all_run(rec_runner.id)\n",
    "result_info = runner_runs[-1].get(\"results\")\n",
    "if result_info:\n",
    "    print(json.dumps(result_info, indent=2))\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
