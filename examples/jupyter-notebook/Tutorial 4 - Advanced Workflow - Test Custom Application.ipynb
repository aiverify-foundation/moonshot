{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1348f980-76e0-4635-afbc-e708aa19970b",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Advanced Workflow - Test Your Own Custom Connector\n",
    "\n",
    "**Scenario**: You are a tester and you want to evaluate your Math application that uses Langchain. In this case, the existing list of connectors in Moonshot is unable to communicate to this custom Math application. How to create a custom connector to use Moonshot with this appication?\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Create your own `connector` in Moonshot\n",
    "- Create a new `connector endpoint` in Moonshot\n",
    "- Run a new `recipe` on this custom connector\n",
    "\n",
    "**Before starting this tutorial, please make sure you have already installed `moonshot` and `moonshot-data`.** Otherwise, please follow this tutorial to install and configure Moonshot first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca988355-1937-4d06-9df0-606b13f29ec6",
   "metadata": {},
   "source": [
    "## Import Moonshot Library API\n",
    "\n",
    "In this section, we prepare our Jupyter notebook environment by importing necessary libraries required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "315fb2da-9dce-4851-a82e-e852f133b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Moonshot Framework API Imports\n",
    "# These imports from the Moonshot framework allow us to interact with the API, \n",
    "# creating and managing various components such as recipes, cookbooks, and endpoints.\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "# Ensure that the root of the Moonshot framework is in the system path for module importing.\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from moonshot.api import (\n",
    "    api_create_endpoint,\n",
    "    api_get_all_recipe,\n",
    "    api_create_recipe,\n",
    "    api_create_cookbook,\n",
    "    api_get_all_runner,\n",
    "    api_load_runner,\n",
    "    api_read_result,\n",
    "    api_set_environment_variables\n",
    ")\n",
    "\n",
    "moonshot_path = \"./data\"\n",
    "env = {\n",
    "    \"ATTACK_MODULES\": os.path.join(moonshot_path, \"attack-modules\"),\n",
    "    \"CONNECTORS\": os.path.join(moonshot_path, \"connectors\"),\n",
    "    \"CONNECTORS_ENDPOINTS\": os.path.join(moonshot_path, \"connectors-endpoints\"),\n",
    "    \"CONTEXT_STRATEGY\": os.path.join(moonshot_path, \"context-strategy\"),\n",
    "    \"COOKBOOKS\": os.path.join(moonshot_path, \"cookbooks\"),\n",
    "    \"DATABASES\": os.path.join(moonshot_path, \"generated-outputs/databases\"),\n",
    "    \"DATABASES_MODULES\": os.path.join(moonshot_path, \"databases-modules\"),\n",
    "    \"DATASETS\": os.path.join(moonshot_path, \"datasets\"),\n",
    "    \"IO_MODULES\": os.path.join(moonshot_path, \"io-modules\"),\n",
    "    \"METRICS\": os.path.join(moonshot_path, \"metrics\"),\n",
    "    \"PROMPT_TEMPLATES\": os.path.join(moonshot_path, \"prompt-templates\"),\n",
    "    \"RECIPES\": os.path.join(moonshot_path, \"recipes\"),\n",
    "    \"RESULTS\": os.path.join(moonshot_path, \"generated-outputs/results\"),\n",
    "    \"RESULTS_MODULES\": os.path.join(moonshot_path, \"results-modules\"),\n",
    "    \"RUNNERS\": os.path.join(moonshot_path, \"generated-outputs/runners\"),\n",
    "    \"RUNNERS_MODULES\": os.path.join(moonshot_path, \"runners-modules\"),\n",
    "}\n",
    "\n",
    "# Apply the environment variables to configure the Moonshot framework.\n",
    "api_set_environment_variables(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbecb59b-f86c-4aa9-b572-e57c61cf8e10",
   "metadata": {},
   "source": [
    "## Create Custom `Connector` \n",
    "\n",
    "In this section, we will learn how to create a custom `connector` and a `connector endpoint` to communicate to a custom Math application. We will use Langchain Agent and OpenAI to create this application.\n",
    "\n",
    "A Langchain Agent can contain one or more `Tool`. In our application, we will create two tools:\n",
    "\n",
    "1) Math Tool using `LLMMathChain`\n",
    "2) Assistant using `LLMChain`\n",
    "\n",
    "Our assistant will use our Math Tool to answer math questions. This assistant will reply in the following format:\n",
    "\n",
    "`{\"input\": <prompt>, \"output\": <response>}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a056e-9f29-4a7b-be3c-a0d9302b705c",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4ba39-4d9a-437c-b4d3-60dd103ed5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install langchain library\n",
    "!pip install langchain langchain_openai numexpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74548164-b09b-41f1-bb66-e42b7081e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain_openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc8d5f-12b1-40a6-8833-aa08e29c67fb",
   "metadata": {},
   "source": [
    "### Connector Code\n",
    "\n",
    "Copy the following code in the cell to `./data/connectors/custom-app.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "39531e20-0ea0-440a-9ddd-f14207f66a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from typing import Any\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMMathChain, LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "\n",
    "from moonshot.src.connectors.connector import Connector, perform_retry\n",
    "from moonshot.src.connectors_endpoints.connector_endpoint_arguments import (\n",
    "    ConnectorEndpointArguments,\n",
    ")\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class MathApplicationConnector(Connector):\n",
    "    def __init__(self, ep_arguments: ConnectorEndpointArguments):\n",
    "        # Initialize super class\n",
    "        super().__init__(ep_arguments)\n",
    "\n",
    "        self.load_agent()\n",
    "\n",
    "        # Set the model to use and remove it from optional_params if it exists\n",
    "        self.model = self.optional_params.get(\"model\", \"\")\n",
    "\n",
    "    def load_agent(self):\n",
    "        os.environ[\"OPENAI_API_KEY\"] = self.token\n",
    "        \n",
    "        my_llm = OpenAI(model='gpt-3.5-turbo-instruct', temperature=0)\n",
    "        problem_chain = LLMMathChain.from_llm(llm=my_llm)\n",
    "        \n",
    "        math_tool = Tool.from_function(name=\"Calculator\",\n",
    "                                       func=problem_chain.run,\n",
    "                                       description=\"This agent answers Math problems.\")\n",
    "        \n",
    "        template = \"\"\"You are a math agent tasked to solve simple math problems. \n",
    "        The answer must be logically arrived.\n",
    "        Your answer must clearly detail the steps involved.\n",
    "        You must give the final answer in the problem.\n",
    "        \n",
    "        Here's the problem {question}\\n\"\"\"\n",
    "        \n",
    "        math_assistant_template = PromptTemplate(input_variables=[\"question\"],\n",
    "                                                 template=template)\n",
    "        math_assistant = LLMChain(llm=my_llm,\n",
    "                                  prompt=math_assistant_template)\n",
    "        math_assistant_tool = Tool.from_function(name=\"Math Assistant\",\n",
    "                                                 func=math_assistant.run,\n",
    "                                                 description=\"Answer logic questions.\")\n",
    "\n",
    "        # Load the agent through Langchain\n",
    "        self._client = initialize_agent(\n",
    "            tools=[math_tool, math_assistant_tool],\n",
    "            llm=my_llm,\n",
    "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "            verbose=False,\n",
    "            handle_parsing_errors=True)\n",
    "\n",
    "    @Connector.rate_limited\n",
    "    @perform_retry\n",
    "    def get_response(self, prompt: str) -> str:\n",
    "        \"\"\"\n",
    "        Asynchronously sends a prompt to the OpenAI API and returns the generated response.\n",
    "\n",
    "        This method constructs a request with the given prompt, optionally prepended and appended with\n",
    "        predefined strings, and sends it to the OpenAI API. If a system prompt is set, it is included in the\n",
    "        request. The method then awaits the response from the API, processes it, and returns the resulting message\n",
    "        content as a string.\n",
    "\n",
    "        Args:\n",
    "            prompt (str): The input prompt to send to the OpenAI API.\n",
    "\n",
    "        Returns:\n",
    "            str: The text response generated by the OpenAI model.\n",
    "        \"\"\"\n",
    "        connector_prompt = f\"{self.pre_prompt}{prompt}{self.post_prompt}\"\n",
    "        response = self._client.invoke({\"input\": connector_prompt})\n",
    "        return self._process_response(response)\n",
    "\n",
    "    async def _process_response(self, response: Any) -> str:\n",
    "        \"\"\"\n",
    "        Process the response and return the message content as a string.\n",
    "\n",
    "        This method processes the response received from API call. It extracts the message content from the first choice\n",
    "        provided in the response, which is expected to contain the relevant information or answer.\n",
    "\n",
    "        Args:\n",
    "            response (Any): The response object received from an API call. It is expected to\n",
    "            follow the structure of OpenAI's chat completion response.\n",
    "\n",
    "        Returns:\n",
    "            str: A string containing the message content from the first choice in the response. This\n",
    "            content represents the AI-generated text based on the input prompt.\n",
    "        \"\"\"\n",
    "        return response[\"output\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da516bb-7897-4e82-aa57-db444e91d790",
   "metadata": {},
   "source": [
    "## Create `endpoint` using custom connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3ce90d2c-f547-44ca-b1e7-5ed88ced62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The newly created endpoint id: my-custom-math\n"
     ]
    }
   ],
   "source": [
    "endpoint_id = api_create_endpoint(\n",
    "    \"my-custom-math\",  # name: Assign a unique name to identify this endpoint later.\n",
    "    \"custom-app\",      # connector_type: Specify the connector type for the model you want to evaluate.\n",
    "    \"\",                # uri: Leave blank as the OpenAI library handles the connection.\n",
    "    \"ADD_TOKEN_HERE\",    # token: Insert your OpenAI API token here.\n",
    "    1,                       # max_calls_per_second: Set the maximum number of calls allowed per second.\n",
    "    1,                       # max_concurrency: Set the maximum number of concurrent calls.\n",
    "    {\n",
    "        \"timeout\": 300,      # Define the timeout for API calls in seconds.\n",
    "        \"allow_retries\": True,  # Specify whether to allow retries on failed calls.\n",
    "        \"num_of_retries\": 3,  # Set the number of retries if allowed.\n",
    "    }  # params: Include any additional parameters required for this model.\n",
    ")\n",
    "print(f\"The newly created endpoint id: {endpoint_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94cbfd-2bd2-4123-b663-a56dd9129aac",
   "metadata": {},
   "source": [
    "### Create dataset and recipe to test my custom endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "539a0eb4-d039-4b9d-9d5c-db4782b6b657",
   "metadata": {},
   "outputs": [],
   "source": [
    "math_dataset = {\n",
    "    \"name\": \"Math Dataset\",\n",
    "    \"description\":\"Measures whether the model knows how to do math\",\n",
    "    \"license\": \"MIT license\",\n",
    "    \"reference\": \"\",\n",
    "    \"examples\": [\n",
    "        {\n",
    "            \"input\": \"1 + 1 = ?\",\n",
    "            \"target\": \"2\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"10 * 5 = ?\",\n",
    "            \"target\": \"50\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Jane has 5 apples. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
    "            \"target\": \"12\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"John has 15 pears. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
    "            \"target\": \"10\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Xiaoming has 3 meat buns. He was given another 10 vegetable buns. How many meat buns does he have?\",\n",
    "            \"target\": \"3\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# to change later when notebook is shifted\n",
    "in_file = \"./data/datasets/math-dataset.json\"\n",
    "json.dump(math_dataset, open(in_file, \"w+\"), indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "fbfdd440-12be-4623-9cc8-9644423be021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe 'math-questions' has been created.\n"
     ]
    }
   ],
   "source": [
    "test_recipe = api_create_recipe(\n",
    "    \"Math Questions\", # name, mandatory\n",
    "    \"This recipe is created to test model's ability in answering math questions.\", # description, mandatory\n",
    "    [\"chatbot\"], # tags, optional\n",
    "    [\"capability\"], # category, optional\n",
    "    [\"math-dataset\"], # dataset filename, mandatory\n",
    "    [], # prompt template, optional\n",
    "    [\"exactstrmatch\"], # metrics, mandatory\n",
    "    [], # attack strategy, optional\n",
    "    { # grading scale, optional\n",
    "        \"A\": [\n",
    "            80,\n",
    "            100\n",
    "        ],\n",
    "        \"B\": [\n",
    "            60,\n",
    "            79\n",
    "        ],\n",
    "        \"C\": [\n",
    "            40,\n",
    "            59\n",
    "        ],\n",
    "        \"D\": [\n",
    "            20,\n",
    "            39\n",
    "        ],\n",
    "        \"E\": [\n",
    "            0,\n",
    "            19\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Recipe '{test_recipe}' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff0cc-7904-48f0-95d5-c09bf6aedb20",
   "metadata": {},
   "source": [
    "### Testing Custom Endpoint with New Recipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d4347f34-e954-4211-bff0-2675fe5fd2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Established connection to database (data/generated-outputs/databases/math-recipe-6.db)\n",
      "[Runner] math-recipe-6 - Running benchmark recipe run...\n",
      "[Run] Part 0: Initialising run...\n",
      "[Run] Initialise run took 0.0016s\n",
      "[Run] Part 1: Loading asyncio running loop...\n",
      "[Run] Part 2: Loading modules...\n",
      "[Run] Module loading took 0.0030s\n",
      "[Run] Part 3: Running runner processing module...\n",
      "[Benchmarking] Load recipe connectors took 0.0151s\n",
      "[Benchmarking] Set connectors system prompt took 0.0000s\n",
      "[Benchmarking] Part 1: Running recipes (['math-questions'])...\n",
      "[Benchmarking] Running recipe math-questions... (1/1)\n",
      "[Benchmarking] Load required instances...\n",
      "[Benchmarking] Load recipe instance took 0.0011s\n",
      "[Benchmarking] Load recipe metrics took 0.0006s\n",
      "[Benchmarking] Build and execute generator pipeline...\n",
      "[Benchmarking] Dataset math-dataset, using 5 of 5 prompts.\n",
      "Predicting prompt 1 [my-custom-math]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prompt 1] took 2.4349s\n",
      "Predicting prompt 2 [my-custom-math]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prompt 2] took 2.5052s\n",
      "Predicting prompt 3 [my-custom-math]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Prompt 3] took 4.6737s\n",
      "[Benchmarking] Predicting prompts for recipe [math-questions] took 9.6267s\n",
      "[Benchmarking] Sorting the recipe predictions into groups\n",
      "[Benchmarking] Sorted the recipe predictions into groups for recipe [math-questions] took 0.0001s\n",
      "[Benchmarking] Performing metrics calculation\n",
      "[Benchmarking] Running metrics for conn_id (my-custom-math), recipe_id (math-questions), dataset_id (math-dataset), prompt_template_id (no-template)\n",
      "[exactstrmatch] Running [get_results] took 0.0000s\n",
      "[Benchmarking] Performing metrics calculation for recipe [math-questions] took 0.0001s\n",
      "[Benchmarking] Run took 9.6321s\n",
      "[Benchmarking] Updating completion status...\n",
      "[Benchmarking] Preparing results...\n",
      "[Benchmarking] Preparing results took 0.0001s\n",
      "[Run] Running runner processing module took 9.6486s\n",
      "[Run] Part 4: Running result processing module...\n",
      "[BenchmarkingResult] Generate results took 0.0038s\n",
      "[Run] Running result processing module took 0.0051s\n",
      "[Run] Part 5: Wrap up run...\n",
      "[Runner] math-recipe-6 - Benchmark recipe run completed and reset.\n",
      "Closed connection to database (data/generated-outputs/databases/math-recipe-6.db)\n",
      "Established connection to database (data/generated-outputs/databases/math-recipe-6.db)\n",
      "{\n",
      "  \"metadata\": {\n",
      "    \"id\": \"math-recipe-6\",\n",
      "    \"start_time\": \"2024-05-24 10:51:28\",\n",
      "    \"end_time\": \"2024-05-24 10:51:38\",\n",
      "    \"duration\": 9,\n",
      "    \"status\": \"completed\",\n",
      "    \"recipes\": [\n",
      "      \"math-questions\"\n",
      "    ],\n",
      "    \"cookbooks\": null,\n",
      "    \"endpoints\": [\n",
      "      \"my-custom-math\"\n",
      "    ],\n",
      "    \"num_of_prompts\": 5,\n",
      "    \"random_seed\": 0,\n",
      "    \"system_prompt\": \"\"\n",
      "  },\n",
      "  \"results\": {\n",
      "    \"recipes\": [\n",
      "      {\n",
      "        \"id\": \"math-questions\",\n",
      "        \"details\": [\n",
      "          {\n",
      "            \"model_id\": \"my-custom-math\",\n",
      "            \"dataset_id\": \"math-dataset\",\n",
      "            \"prompt_template_id\": \"no-template\",\n",
      "            \"data\": [\n",
      "              {\n",
      "                \"prompt\": \"10 * 5 = ?\",\n",
      "                \"predicted_result\": \"50\",\n",
      "                \"target\": \"50\",\n",
      "                \"duration\": 2.434881834080443\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"Jane has 5 apples. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
      "                \"predicted_result\": \"12\",\n",
      "                \"target\": \"12\",\n",
      "                \"duration\": 2.5052224160172045\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"John has 15 pears. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
      "                \"predicted_result\": \"John has 22 apples.\",\n",
      "                \"target\": \"10\",\n",
      "                \"duration\": 4.673718750011176\n",
      "              },\n",
      "              {\n",
      "                \"prompt\": \"Xiaoming has 3 meat buns. He was given another 10 vegetable buns. How many meat buns does he have?\",\n",
      "                \"predicted_result\": \"Xiaoming has 12 meat buns.\",\n",
      "                \"target\": 3,\n",
      "                \"duration\": 8.34608683316037\n",
      "              }\n",
      "            ],\n",
      "            \"metrics\": [\n",
      "              {\n",
      "                \"accuracy\": 50.0,\n",
      "                \"grading_criteria\": {\n",
      "                  \"accuracy\": 50.0\n",
      "                }\n",
      "              }\n",
      "            ]\n",
      "          }\n",
      "        ],\n",
      "        \"evaluation_summary\": [\n",
      "          {\n",
      "            \"model_id\": \"my-custom-math\",\n",
      "            \"num_of_prompts\": 4,\n",
      "            \"avg_grade_value\": 50.0,\n",
      "            \"grade\": \"C\"\n",
      "          }\n",
      "        ],\n",
      "        \"grading_scale\": {\n",
      "          \"A\": [\n",
      "            80,\n",
      "            100\n",
      "          ],\n",
      "          \"B\": [\n",
      "            60,\n",
      "            79\n",
      "          ],\n",
      "          \"C\": [\n",
      "            40,\n",
      "            59\n",
      "          ],\n",
      "          \"D\": [\n",
      "            20,\n",
      "            39\n",
      "          ],\n",
      "          \"E\": [\n",
      "            0,\n",
      "            19\n",
      "          ]\n",
      "        },\n",
      "        \"total_num_of_prompts\": 4\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from slugify import slugify\n",
    "from moonshot.api import api_get_all_run, api_create_runner, api_get_all_runner_name\n",
    "\n",
    "name = \"math recipe 6\" # Indicate the name\n",
    "recipes = [\"math-questions\"] # Test against 2 recipes, item-category and bbq\n",
    "endpoints = [\"my-custom-math\"]  # Test against 1 endpoint, test-openai-endpoint\n",
    "num_of_prompts = 5 # use a smaller number to test out the function; 0 means using all prompts in dataset\n",
    "\n",
    "# Below are the optional fields\n",
    "random_seed = 0   # Default: 0; this allows for randomness in dataset selection when num_of_prompts are set\n",
    "system_prompt = \"\"  # Default: \"\"; this allows setting the system prompt for the endpoints\n",
    "\n",
    "# Advanced user - Modify runner processing module and result processing module\n",
    "# Default: benchmarking and benchmarking-result\n",
    "runner_proc_module = \"benchmarking\"  # Default: \"benchmarking\"\n",
    "result_proc_module = \"benchmarking-result\"  # Default: \"benchmarking-result\"\n",
    "\n",
    "# Run the recipes with the defined endpoints\n",
    "# If the id exists, it will perform a load on the runner, instead of creating a new runner.\n",
    "# The benefit of this, allows the new run to use possible cached results from previous runs which greatly enhances the run time.\n",
    "slugify_id = slugify(name, lowercase=True)\n",
    "if slugify_id in api_get_all_runner_name():\n",
    "    rec_runner = api_load_runner(slugify_id)\n",
    "else:\n",
    "    rec_runner = api_create_runner(name, endpoints)\n",
    "\n",
    "# run_cookbooks is an async function. Currently there is no sync version.\n",
    "# We will get an existing event loop and execute the run cookbooks process.\n",
    "await rec_runner.run_recipes(\n",
    "    recipes,\n",
    "    num_of_prompts,\n",
    "    random_seed,\n",
    "    system_prompt,\n",
    "    runner_proc_module,\n",
    "    result_proc_module,\n",
    ")\n",
    "rec_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
    "\n",
    "# Display results\n",
    "runner_runs = api_get_all_run(rec_runner.id)\n",
    "result_info = runner_runs[-1].get(\"results\")\n",
    "if result_info:\n",
    "    print(json.dumps(result_info, indent=2))\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "moonshot_jupyter",
   "language": "python",
   "name": "moonshot_jupyter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
