{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1348f980-76e0-4635-afbc-e708aa19970b",
   "metadata": {},
   "source": [
    "# Tutorial 4 - Advanced Workflow - Test Your Own Custom Connector\n",
    "\n",
    "**Scenario**: \n",
    "\n",
    "You are a tester and you want to evaluate your Math application that uses Langchain.<br>\n",
    "In this case, the existing list of connectors in Moonshot is unable to communicate to this custom Math application.\n",
    "\n",
    "How do we create a custom connector to use Moonshot to test this custom application?\n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Create your own `connector` in Moonshot\n",
    "- Create a new `connector endpoint` in Moonshot\n",
    "- Run a new `recipe` on this custom connector\n",
    "\n",
    "Prerequisite:\n",
    "\n",
    "1. You have added your OpenAI connector configuration named `my-openai-endpoint` in Moonshot. If you are unsure how to do it, please refer to \"<b>Tutorial 1</b>\" in the same folder.\n",
    "\n",
    "**Before starting this tutorial, please make sure you have already installed `moonshot` and `moonshot-data`.**<br>\n",
    "Otherwise, please refer to \"<b>Moonshot - Pre-Req - Setup.ipynb</b>\" to install and configure Moonshot first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24874e86",
   "metadata": {},
   "source": [
    "## Import and configure Moonshot\n",
    "\n",
    "In this section, we prepare our Jupyter notebook environment by importing necessary libraries required to execute red teaming session.\n",
    "\n",
    "> ⚠️ **Note:** Check that `moonshot_data_path` below matches the location where you installed `moonshot-data` and edit the code to match your location if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315fb2da-9dce-4851-a82e-e852f133b6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python built-ins:\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "\n",
    "# IF you're running this notebook from the moonshot/examples/jupyter-notebook folder, the below\n",
    "# line will enable you to import moonshot from the local source code. If you installed moonshot\n",
    "# from pip, you can remove this:\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "from moonshot.api import (\n",
    "    api_create_endpoint,\n",
    "    api_create_recipe,\n",
    "    api_load_runner,\n",
    "    api_set_environment_variables\n",
    ")\n",
    "\n",
    "# Environment Configuration\n",
    "# Here we set up the environment variables for the Moonshot framework.\n",
    "# These variables define the paths to various modules and components used by Moonshot,\n",
    "# organizing the framework's structure and access points.\n",
    "\n",
    "# modify moonshot_data_path to point to your own copy of moonshot-data\n",
    "moonshot_data_path = \"./moonshot-data\"\n",
    "env = {\n",
    "    \"ATTACK_MODULES\": os.path.join(moonshot_data_path, \"attack-modules\"),\n",
    "    \"BOOKMARKS\": os.path.join(moonshot_data_path, \"generated-outputs/bookmarks\"),\n",
    "    \"CONNECTORS\": os.path.join(moonshot_data_path, \"connectors\"),\n",
    "    \"CONNECTORS_ENDPOINTS\": os.path.join(moonshot_data_path, \"connectors-endpoints\"),\n",
    "    \"CONTEXT_STRATEGY\": os.path.join(moonshot_data_path, \"context-strategy\"),\n",
    "    \"COOKBOOKS\": os.path.join(moonshot_data_path, \"cookbooks\"),\n",
    "    \"DATABASES\": os.path.join(moonshot_data_path, \"generated-outputs/databases\"),\n",
    "    \"DATABASES_MODULES\": os.path.join(moonshot_data_path, \"databases-modules\"),\n",
    "    \"DATASETS\": os.path.join(moonshot_data_path, \"datasets\"),\n",
    "    \"IO_MODULES\": os.path.join(moonshot_data_path, \"io-modules\"),\n",
    "    \"METRICS\": os.path.join(moonshot_data_path, \"metrics\"),\n",
    "    \"PROMPT_TEMPLATES\": os.path.join(moonshot_data_path, \"prompt-templates\"),\n",
    "    \"RECIPES\": os.path.join(moonshot_data_path, \"recipes\"),\n",
    "    \"RESULTS\": os.path.join(moonshot_data_path, \"generated-outputs/results\"),\n",
    "    \"RESULTS_MODULES\": os.path.join(moonshot_data_path, \"results-modules\"),\n",
    "    \"RUNNERS\": os.path.join(moonshot_data_path, \"generated-outputs/runners\"),\n",
    "    \"RUNNERS_MODULES\": os.path.join(moonshot_data_path, \"runners-modules\"),\n",
    "}\n",
    "\n",
    "# Check user has set moonshot_data_path correctly:\n",
    "if not os.path.isdir(env[\"ATTACK_MODULES\"]):\n",
    "    raise ValueError(\n",
    "        \"Configured path %s does not exist. Is moonshot-data installed at %s?\"\n",
    "        % (env[\"ATTACK_MODULES\"], moonshot_data_path)\n",
    "    )\n",
    "\n",
    "# Apply the environment variables to configure the Moonshot framework.\n",
    "api_set_environment_variables(env)\n",
    "\n",
    "# Note: there might be some warning on IProgress not found. we can ignore it for now."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbecb59b-f86c-4aa9-b572-e57c61cf8e10",
   "metadata": {},
   "source": [
    "## Create Custom Connector \n",
    "\n",
    "In this section, we will learn how to create a custom `connector` and a `connector endpoint` to communicate to a custom Math application. We will use Langchain Agent and OpenAI to create this application.\n",
    "\n",
    "A Langchain Agent can contain one or more `Tool`. In our application, we will create two tools:\n",
    "\n",
    "1) Math Tool using `LLMMathChain`\n",
    "2) Assistant using `LLMChain`\n",
    "\n",
    "Our assistant will use our Math Tool to answer math questions. This assistant will reply in the following format:\n",
    "\n",
    "`{\"input\": <prompt>, \"output\": <response>}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44a056e-9f29-4a7b-be3c-a0d9302b705c",
   "metadata": {},
   "source": [
    "### Install Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19f4ba39-4d9a-437c-b4d3-60dd103ed5bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in ./env/lib/python3.11/site-packages (0.2.17)\n",
      "Requirement already satisfied: langchain_openai in ./env/lib/python3.11/site-packages (0.1.25)\n",
      "Requirement already satisfied: numexpr in ./env/lib/python3.11/site-packages (2.10.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.11/site-packages (from langchain) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.11/site-packages (from langchain) (3.10.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.43 in ./env/lib/python3.11/site-packages (from langchain) (0.2.43)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in ./env/lib/python3.11/site-packages (from langchain) (0.2.4)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./env/lib/python3.11/site-packages (from langchain) (0.1.147)\n",
      "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3,>=1 in ./env/lib/python3.11/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.40.0 in ./env/lib/python3.11/site-packages (from langchain_openai) (1.51.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in ./env/lib/python3.11/site-packages (from langchain_openai) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.13.1)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.3.0,>=0.2.43->langchain) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.12)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (0.5.0)\n",
      "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain_openai) (4.66.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in ./env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in ./env/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: regex>=2022.1.18 in ./env/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain_openai) (2024.9.11)\n",
      "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.43->langchain) (3.0.0)\n"
     ]
    }
   ],
   "source": [
    "# Install langchain library\n",
    "!pip install langchain langchain_openai numexpr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febc8d5f-12b1-40a6-8833-aa08e29c67fb",
   "metadata": {},
   "source": [
    "### Custom Connector Code\n",
    "\n",
    "1. Copy the connector to `./{moonshot_data_path}/connectors/custom-app.py`, <br>\n",
    "where `{moonshot_data_path}` is the path of your own copy of moonshot-data you specified in the first cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39531e20-0ea0-440a-9ddd-f14207f66a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copied ./moonshot-data/../assets/jupyter-assets-custom-app.py to ./moonshot-data/connectors/custom-app.py\n"
     ]
    }
   ],
   "source": [
    "# Copy the custom-app.py from assets to moonshot-data\n",
    "import shutil\n",
    "\n",
    "source_path = f\"{moonshot_data_path}/../assets/jupyter-assets-custom-app.py\"\n",
    "destination_path = f\"{moonshot_data_path}/connectors/custom-app.py\"\n",
    "\n",
    "shutil.copyfile(source_path, destination_path)\n",
    "print(f\"Copied {source_path} to {destination_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bd7d7b9",
   "metadata": {},
   "source": [
    "2. Display the contents of this custom connector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dad44fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import os\n",
      "from typing import Any\n",
      "\n",
      "from langchain.agents import Tool, initialize_agent\n",
      "from langchain.agents.agent_types import AgentType\n",
      "from langchain.chains import LLMChain, LLMMathChain\n",
      "from langchain.prompts import PromptTemplate\n",
      "from langchain_openai import OpenAI\n",
      "\n",
      "from moonshot.src.connectors.connector import Connector, perform_retry\n",
      "from moonshot.src.connectors.connector_response import ConnectorResponse\n",
      "from moonshot.src.connectors_endpoints.connector_endpoint_arguments import (\n",
      "    ConnectorEndpointArguments,\n",
      ")\n",
      "\n",
      "\n",
      "class MathApplicationConnector(Connector):\n",
      "    def __init__(self, ep_arguments: ConnectorEndpointArguments):\n",
      "        \"\"\"\n",
      "        Initialize the MathApplicationConnector with endpoint arguments.\n",
      "\n",
      "        Args:\n",
      "            ep_arguments (ConnectorEndpointArguments): The endpoint arguments for the connector.\n",
      "        \"\"\"\n",
      "        # Initialize super class\n",
      "        super().__init__(ep_arguments)\n",
      "\n",
      "        self.load_agent()\n",
      "\n",
      "    def load_agent(self):\n",
      "        \"\"\"\n",
      "        Load the agent with the necessary tools and configurations.\n",
      "\n",
      "        This method sets the OpenAI API key, initializes the language model, and sets up the tools\n",
      "        for solving math problems and answering logic questions. It then initializes the agent\n",
      "        using these tools and configurations.\n",
      "        \"\"\"\n",
      "        os.environ[\"OPENAI_API_KEY\"] = self.token\n",
      "\n",
      "        my_llm = OpenAI(model=\"gpt-3.5-turbo-instruct\", temperature=0)\n",
      "        problem_chain = LLMMathChain.from_llm(llm=my_llm)\n",
      "\n",
      "        math_tool = Tool.from_function(\n",
      "            name=\"Calculator\",\n",
      "            func=problem_chain.run,\n",
      "            description=\"This agent answers Math problems.\",\n",
      "        )\n",
      "\n",
      "        template = \"\"\"You are a math agent tasked to solve simple math problems.\n",
      "        The answer must be logically arrived.\n",
      "        Your answer must clearly detail the steps involved.\n",
      "        You must give the final answer in the problem.\\n\n",
      "        Here's the problem {question}\\n\"\"\"\n",
      "\n",
      "        math_assistant_template = PromptTemplate(\n",
      "            input_variables=[\"question\"], template=template\n",
      "        )\n",
      "        math_assistant = LLMChain(llm=my_llm, prompt=math_assistant_template)\n",
      "        math_assistant_tool = Tool.from_function(\n",
      "            name=\"Math Assistant\",\n",
      "            func=math_assistant.run,\n",
      "            description=\"Answer logic questions.\",\n",
      "        )\n",
      "\n",
      "        # Load the agent through Langchain\n",
      "        self._client = initialize_agent(\n",
      "            tools=[math_tool, math_assistant_tool],\n",
      "            llm=my_llm,\n",
      "            agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
      "            verbose=False,\n",
      "            handle_parsing_errors=True,\n",
      "        )\n",
      "\n",
      "    @Connector.rate_limited\n",
      "    @perform_retry\n",
      "    async def get_response(self, prompt: str) -> ConnectorResponse:\n",
      "        \"\"\"\n",
      "        Asynchronously sends a prompt to the math agent and returns the generated response.\n",
      "\n",
      "        This method constructs a request with the given prompt, optionally prepended and appended with\n",
      "        predefined strings, and sends it to the math agent. The method then awaits the response from the agent,\n",
      "        processes it, and returns the resulting message content wrapped in a ConnectorResponse object.\n",
      "\n",
      "        Args:\n",
      "            prompt (str): The input prompt to send to the math agent.\n",
      "\n",
      "        Returns:\n",
      "            ConnectorResponse: An object containing the text response generated by the math agent.\n",
      "        \"\"\"\n",
      "        connector_prompt = f\"{self.pre_prompt}{prompt}{self.post_prompt}\"\n",
      "        response = self._client.invoke({\"input\": connector_prompt})\n",
      "        return ConnectorResponse(response=await self._process_response(response))\n",
      "\n",
      "    async def _process_response(self, response: Any) -> str:\n",
      "        \"\"\"\n",
      "        Process the response and return the message content as a string.\n",
      "\n",
      "        This method processes the response received from API call. It extracts the message content from the first choice\n",
      "        provided in the response, which is expected to contain the relevant information or answer.\n",
      "\n",
      "        Args:\n",
      "            response (Any): The response object received from an API call. It is expected to\n",
      "            follow the structure of OpenAI's chat completion response.\n",
      "\n",
      "        Returns:\n",
      "            str: A string containing the message content from the first choice in the response. This\n",
      "            content represents the AI-generated text based on the input prompt.\n",
      "        \"\"\"\n",
      "        return response[\"output\"]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display the contents of this custom connector\n",
    "with open(destination_path, 'r') as file:\n",
    "    custom_app_contents = file.read()\n",
    "    print(custom_app_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4cfbf0",
   "metadata": {},
   "source": [
    "To explain more on how to create the custom connector:<br>\n",
    "1. We create a new Class called `MathApplicationConnector`, then inherit the <b>[Connector](https://github.com/aiverify-foundation/moonshot/blob/main/moonshot/src/connectors/connector.py)</b> superclass.\n",
    "\n",
    "2. We create a new `load_agent` method, where it loads the necessary tools and configuration. This method includes reading the OpenAI API Key, initializes the language model, sets up the tools for solving math problems and answering logic questions. This is the part where we load the agent through Langchain with all the prompt templates and so on.\n",
    "\n",
    "3. We will initialise the `load_agent` method in the constructor.<br>`self.load_agent()`\n",
    "\n",
    "4. Every connector will require this method `async def get_response(self, prompt: str) -> ConnectorResponse`.<br>\n",
    "The purpose of this method is to be responsible of invoking the `self._client` to predict the response of a provided prompt input. <br>\n",
    "Some common modifications in this function may include adding system prompt or setting specific model parameters.<br>\n",
    "<br>\n",
    "Input: prompt (str) - The prompt that requires the prediction. Prompt is from the dataset.<br>\n",
    "Return: [ConnectorResponse](https://github.com/aiverify-foundation/moonshot/blob/main/moonshot/src/connectors/connector_response.py) - An instance of ConnectorResponse which contains response and context (if required)\n",
    "<br><br>\n",
    "<b>ConnectorResponse</b> provides 2 parameters: response and context.<br>\n",
    "response - this should contain the response from the llm.<br>\n",
    "context - this should contain the context from the llm, if required.<br>\n",
    "\n",
    "5. We create a private method `async def _process_response(self, response: Any)` which takes in a response argument.<br>\n",
    "The purpose of this method is to be responsible of retrieving the output from the llm response.<br>\n",
    "In this scenario, the llm response will be in this format: `{\"input\": <prompt>, \"output\": <response>}`.<br>\n",
    "We will need to extract the response which is in the `\"output\"` key, hence `return response[\"output\"]`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da516bb-7897-4e82-aa57-db444e91d790",
   "metadata": {},
   "source": [
    "## Create endpoint using custom connector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9828a86b",
   "metadata": {},
   "source": [
    "Now that we have created the custom connector above, we will need a create the endpoint.\n",
    "\n",
    "To understand more on how endpoint works, you may refer to the `Tutorial 1 - Basic Workflow - Execute a Benchmark`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ce90d2c-f547-44ca-b1e7-5ed88ced62bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The newly created endpoint id: my-custom-math\n"
     ]
    }
   ],
   "source": [
    "endpoint_id = api_create_endpoint(\n",
    "    \"my-custom-math\",        # name: Assign a unique name to identify this endpoint later.\n",
    "    \"custom-app\",            # connector_type: Specify the connector type for the model you want to evaluate.\n",
    "    \"\",                      # uri: Leave blank as the OpenAI library handles the connection.\n",
    "    \"ADD_YOUR_TOKEN_HERE\",   # token: Insert your OpenAI API token here.\n",
    "    1,                       # max_calls_per_second: Set the maximum number of calls allowed per second.\n",
    "    1,                       # max_concurrency: Set the maximum number of concurrent calls.\n",
    "    \"gpt-4o\",                # model: Define the model version to use.\n",
    "    # params: Include any additional parameters required for this model.\n",
    "    {\n",
    "        \"timeout\": 300,      # timeout: Define the timeout for API calls in seconds.\n",
    "        \"max_attempts\": 3,   # max_attempts: Define the max number of retry attempts. \n",
    "        \"temperature\": 0.5,  # temperature: Set the temperature for response variability.\n",
    "    }  \n",
    ")\n",
    "print(f\"The newly created endpoint id: {endpoint_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c94cbfd-2bd2-4123-b663-a56dd9129aac",
   "metadata": {},
   "source": [
    "### Create dataset and recipe to test my custom endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255f6eae",
   "metadata": {},
   "source": [
    "Let's create a new dataset that has the math questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "539a0eb4-d039-4b9d-9d5c-db4782b6b657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 'math-dataset' has been created.\n"
     ]
    }
   ],
   "source": [
    "math_dataset = {\n",
    "    \"name\": \"Math Dataset\",\n",
    "    \"description\":\"Measures whether the model knows how to do math\",\n",
    "    \"license\": \"MIT license\",\n",
    "    \"reference\": \"\",\n",
    "    \"examples\": [\n",
    "        {\n",
    "            \"input\": \"1 + 1 = ?\",\n",
    "            \"target\": \"2\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"10 * 5 = ?\",\n",
    "            \"target\": \"50\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Jane has 5 apples. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
    "            \"target\": \"12\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"John has 15 pears. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
    "            \"target\": \"10\"\n",
    "        },\n",
    "        {\n",
    "            \"input\": \"Xiaoming has 3 meat buns. He was given another 10 vegetable buns. How many meat buns does he have?\",\n",
    "            \"target\": \"3\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "in_file = f\"{moonshot_data_path}/datasets/math-dataset.json\"\n",
    "json.dump(math_dataset, open(in_file, \"w+\"), indent=4)\n",
    "if os.path.exists(in_file):\n",
    "     print(f\"Dataset 'math-dataset' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375221b9",
   "metadata": {},
   "source": [
    "Let's create a new recipe that allows us to use the math-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fbfdd440-12be-4623-9cc8-9644423be021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe 'math-questions' has been created.\n"
     ]
    }
   ],
   "source": [
    "test_recipe = api_create_recipe(\n",
    "    \"Math Questions\", # name (mandatory)\n",
    "    \"This recipe is created to test model's ability in answering math questions.\", # description (mandatory)\n",
    "    [\"chatbot\"], # tags (optional)\n",
    "    [\"capability\"], # category (optional)\n",
    "    [\"math-dataset\"], # filename of the dataset (mandatory)\n",
    "    [], # prompt templates (optional)\n",
    "    [\"exactstrmatch\"], # metrics (mandatory)\n",
    "    { # grading scale, optional\n",
    "        \"A\": [\n",
    "            80,\n",
    "            100\n",
    "        ],\n",
    "        \"B\": [\n",
    "            60,\n",
    "            79\n",
    "        ],\n",
    "        \"C\": [\n",
    "            40,\n",
    "            59\n",
    "        ],\n",
    "        \"D\": [\n",
    "            20,\n",
    "            39\n",
    "        ],\n",
    "        \"E\": [\n",
    "            0,\n",
    "            19\n",
    "        ]\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"Recipe '{test_recipe}' has been created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523ff0cc-7904-48f0-95d5-c09bf6aedb20",
   "metadata": {},
   "source": [
    "### Testing Custom Endpoint with New Recipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a0fcb88",
   "metadata": {},
   "source": [
    "We have created the custom connector, custom connector-endpoint, math-dataset, math-recipe.\n",
    "\n",
    "Let's run the recipe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4347f34-e954-4211-bff0-2675fe5fd2f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-20 00:03:25,211 [INFO][runner.py::run_recipes(349)] [Runner] math-recipe - Running benchmark recipe run...\n",
      "2024-12-20 00:03:25,254 [INFO][benchmarking.py::generate(169)] [Benchmarking] Running recipes (['math-questions'])...\n",
      "2024-12-20 00:03:25,254 [INFO][benchmarking.py::generate(173)] [Benchmarking] Running recipe math-questions... (1/1)\n",
      "2024-12-20 00:03:25,262 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 3.\n",
      "2024-12-20 00:03:30,626 [INFO][connector.py::get_prediction(348)] [Connector ID: my-custom-math] Predicting Prompt Index 4.\n",
      "2024-12-20 00:03:33,267 [INFO][benchmarking.py::generate(203)] [Benchmarking] Run took 8.0126s\n",
      "2024-12-20 00:03:33,272 [INFO][benchmarking.py::generate(258)] [Benchmarking] Preparing results took 0.0001s\n",
      "2024-12-20 00:03:33,294 [INFO][benchmarking-result.py::generate(58)] [BenchmarkingResult] Generate results took 0.0205s\n",
      "2024-12-20 00:03:33,296 [INFO][runner.py::run_recipes(375)] [Runner] math-recipe - Benchmark recipe run completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"metadata\": {\n",
      "        \"id\": \"math-recipe\",\n",
      "        \"start_time\": \"2024-12-20 00:03:25\",\n",
      "        \"end_time\": \"2024-12-20 00:03:33\",\n",
      "        \"duration\": 8,\n",
      "        \"status\": \"completed\",\n",
      "        \"recipes\": [\n",
      "            \"math-questions\"\n",
      "        ],\n",
      "        \"cookbooks\": null,\n",
      "        \"endpoints\": [\n",
      "            \"my-custom-math\"\n",
      "        ],\n",
      "        \"prompt_selection_percentage\": 50,\n",
      "        \"random_seed\": 0,\n",
      "        \"system_prompt\": \"\"\n",
      "    },\n",
      "    \"results\": {\n",
      "        \"recipes\": [\n",
      "            {\n",
      "                \"id\": \"math-questions\",\n",
      "                \"details\": [\n",
      "                    {\n",
      "                        \"model_id\": \"my-custom-math\",\n",
      "                        \"dataset_id\": \"math-dataset\",\n",
      "                        \"prompt_template_id\": \"no-template\",\n",
      "                        \"data\": [\n",
      "                            {\n",
      "                                \"prompt\": \"John has 15 pears. She gave 3 away. John gave her another 10 apples. How many apples does she have?\",\n",
      "                                \"predicted_result\": {\n",
      "                                    \"response\": \"John has 22 apples.\",\n",
      "                                    \"context\": []\n",
      "                                },\n",
      "                                \"target\": \"10\",\n",
      "                                \"duration\": 5.360548042001028\n",
      "                            },\n",
      "                            {\n",
      "                                \"prompt\": \"Xiaoming has 3 meat buns. He was given another 10 vegetable buns. How many meat buns does he have?\",\n",
      "                                \"predicted_result\": {\n",
      "                                    \"response\": \"13\",\n",
      "                                    \"context\": []\n",
      "                                },\n",
      "                                \"target\": \"3\",\n",
      "                                \"duration\": 2.6309450840017234\n",
      "                            }\n",
      "                        ],\n",
      "                        \"metrics\": [\n",
      "                            {\n",
      "                                \"accuracy\": 0.0,\n",
      "                                \"grading_criteria\": {\n",
      "                                    \"accuracy\": 0.0\n",
      "                                }\n",
      "                            }\n",
      "                        ]\n",
      "                    }\n",
      "                ],\n",
      "                \"evaluation_summary\": [\n",
      "                    {\n",
      "                        \"model_id\": \"my-custom-math\",\n",
      "                        \"num_of_prompts\": 2,\n",
      "                        \"avg_grade_value\": 0.0,\n",
      "                        \"grade\": \"E\"\n",
      "                    }\n",
      "                ],\n",
      "                \"grading_scale\": {\n",
      "                    \"A\": [\n",
      "                        80,\n",
      "                        100\n",
      "                    ],\n",
      "                    \"B\": [\n",
      "                        60,\n",
      "                        79\n",
      "                    ],\n",
      "                    \"C\": [\n",
      "                        40,\n",
      "                        59\n",
      "                    ],\n",
      "                    \"D\": [\n",
      "                        20,\n",
      "                        39\n",
      "                    ],\n",
      "                    \"E\": [\n",
      "                        0,\n",
      "                        19\n",
      "                    ]\n",
      "                },\n",
      "                \"total_num_of_prompts\": 2\n",
      "            }\n",
      "        ]\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "from slugify import slugify\n",
    "from moonshot.api import api_get_all_run, api_create_runner, api_get_all_runner_name\n",
    "\n",
    "name = \"math recipe\" # Indicate the name\n",
    "recipes = [\"math-questions\"] # Test one recipe math-questions. You can add more recipes in the list to test as well\n",
    "endpoints = [\"my-custom-math\"]  # Test against 1 endpoint, my-custom-math\n",
    "prompt_selection_percentage = 50 # The percentage number of prompt(s) to run from EACH dataset in the recipe; this refers to 50% of each dataset prompts.\n",
    "\n",
    "# Optional fields\n",
    "random_seed = 0   # Default: 0; this allows for randomness in dataset selection when prompt selection percentage are set\n",
    "system_prompt = \"\"  # Default: \"\"; this allows setting the system prompt for the endpoints\n",
    "\n",
    "# Advanced user - Modify runner processing module and result processing module\n",
    "# Default: benchmarking and benchmarking-result. Change it to your module name if you have your own runner and/or result module\n",
    "runner_proc_module = \"benchmarking\"  # Default: \"benchmarking\"\n",
    "result_proc_module = \"benchmarking-result\"  # Default: \"benchmarking-result\"\n",
    "\n",
    "# Run the recipe with the defined endpoint(s)\n",
    "# If the id exists, it will perform a load on the runner, instead of creating a new runner.\n",
    "# Using an existing runner allows the new run to possibly use cached results from previous runs, which greatly reduces the run time\n",
    "slugify_id = slugify(name, lowercase=True)\n",
    "if slugify_id in api_get_all_runner_name():\n",
    "    rec_runner = api_load_runner(slugify_id)\n",
    "else:\n",
    "    rec_runner = api_create_runner(name, endpoints)\n",
    "\n",
    "# run_recies is an async function. Currently there is no sync version.\n",
    "# We will get an existing event loop and execute the run recipes process.\n",
    "await rec_runner.run_recipes(\n",
    "    recipes,\n",
    "    prompt_selection_percentage,\n",
    "    random_seed,\n",
    "    system_prompt,\n",
    "    runner_proc_module,\n",
    "    result_proc_module,\n",
    ")\n",
    "await rec_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
    "\n",
    "# Display results\n",
    "runner_runs = api_get_all_run(rec_runner.id)\n",
    "result_info = runner_runs[-1].get(\"results\")\n",
    "if result_info:\n",
    "    print(json.dumps(result_info, indent=4))\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
