{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1adab3f9-616e-4efb-9217-ea01014d4e03",
   "metadata": {},
   "source": [
    "# Tutorial 1 - Basic Workflow - Execute Existing Tests \n",
    "\n",
    "**Scenario**: You are a model developer and you are told to deploy a system that uses a Large Language Model. However, you are uncertain which model performs best for your use case and you want to assess potential models' capabilities using the pre-built benchmarks in Moonshot. How can you do this? \n",
    "\n",
    "In this tutorial, you will learn how to:\n",
    "\n",
    "- Add your own `connector_endpoints` into Moonshot\n",
    "- List and run an existing `cookbook` in Moonshot\n",
    "\n",
    "**Before starting this tutorial, please make sure you have already installed `moonshot` and `moonshot-data`.** Otherwise, please follow [this tutorial](https://aiverify-foundation.github.io/moonshot/getting_started/quick_install) to install and configure Moonshot first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9890dfc2-cd4a-405f-b90f-b9284e50dca6",
   "metadata": {},
   "source": [
    "## Import and configure Moonshot\n",
    "\n",
    "In this section, we prepare our Jupyter notebook environment by importing necessary libraries required to execute an existing benchmark.\n",
    "\n",
    "> ⚠️ **Check:** that `moonshot_data_path` below matches the location where you installed `moonshot-data` - and edit the code to match your location if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0dfafc2-097d-4a17-b8ef-dd964ede8b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 18:13:40,135 [WARNING][env_variables.py::load_env(157)] Unable to retrieve the following environment variables: ['BOOKMARKS']. The stock set will be used.\n"
     ]
    }
   ],
   "source": [
    "# Python built-ins:\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "import sys\n",
    "\n",
    "# IF you're running this notebook from the moonshot/examples/jupyter-notebook folder, the below\n",
    "# line will enable you to import moonshot from the local source code. If you installed moonshot\n",
    "# from pip, you can remove this:\n",
    "sys.path.insert(0, '../../')\n",
    "\n",
    "# Import moonshot utilities:\n",
    "from moonshot.api import (\n",
    "    api_create_endpoint,\n",
    "    api_get_all_endpoint,\n",
    "    api_get_all_cookbook,\n",
    "    api_load_runner,\n",
    "    api_read_result,\n",
    "    api_set_environment_variables,\n",
    ")\n",
    "\n",
    "# Configure moonshot data location:\n",
    "moonshot_data_path = \"./data\"\n",
    "env = {\n",
    "    \"ATTACK_MODULES\": os.path.join(moonshot_data_path, \"attack-modules\"),\n",
    "    \"CONNECTORS\": os.path.join(moonshot_data_path, \"connectors\"),\n",
    "    \"CONNECTORS_ENDPOINTS\": os.path.join(moonshot_data_path, \"connectors-endpoints\"),\n",
    "    \"CONTEXT_STRATEGY\": os.path.join(moonshot_data_path, \"context-strategy\"),\n",
    "    \"COOKBOOKS\": os.path.join(moonshot_data_path, \"cookbooks\"),\n",
    "    \"DATABASES\": os.path.join(moonshot_data_path, \"generated-outputs/databases\"),\n",
    "    \"DATABASES_MODULES\": os.path.join(moonshot_data_path, \"databases-modules\"),\n",
    "    \"DATASETS\": os.path.join(moonshot_data_path, \"datasets\"),\n",
    "    \"IO_MODULES\": os.path.join(moonshot_data_path, \"io-modules\"),\n",
    "    \"METRICS\": os.path.join(moonshot_data_path, \"metrics\"),\n",
    "    \"PROMPT_TEMPLATES\": os.path.join(moonshot_data_path, \"prompt-templates\"),\n",
    "    \"RECIPES\": os.path.join(moonshot_data_path, \"recipes\"),\n",
    "    \"RESULTS\": os.path.join(moonshot_data_path, \"generated-outputs/results\"),\n",
    "    \"RESULTS_MODULES\": os.path.join(moonshot_data_path, \"results-modules\"),\n",
    "    \"RUNNERS\": os.path.join(moonshot_data_path, \"generated-outputs/runners\"),\n",
    "    \"RUNNERS_MODULES\": os.path.join(moonshot_data_path, \"runners-modules\"),\n",
    "}\n",
    "\n",
    "# Check user has set moonshot_data_path correctly:\n",
    "if not os.path.isdir(env[\"ATTACK_MODULES\"]):\n",
    "    raise ValueError(\n",
    "        \"Configured path %s does not exist. Is moonshot-data installed at %s?\"\n",
    "        % (env[\"ATTACK_MODULES\"], moonshot_data_path)\n",
    "    )\n",
    "\n",
    "# Apply the environment variables to configure the Moonshot framework.\n",
    "api_set_environment_variables(env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0792527a-ab68-4826-b4c2-3d2f2a0b2a59",
   "metadata": {},
   "source": [
    "## Define the target model endpoint / API\n",
    "\n",
    "Moonshot provides [connectors](https://aiverify-foundation.github.io/moonshot/api_reference/api_connector/) to a range of different LLM hosting providers - such as OpenAI (direct or Azure), Hugging Face, Amazon Bedrock, and Google Gemini.\n",
    "\n",
    "There are some [example endpoint configurations](https://github.com/aiverify-foundation/moonshot-data/tree/main/connectors-endpoints) provided in `moonshot-data`, but they don't include API keys or other credentials: So you'll usually need to edit these configurations, or add your own, to connect to your target LLM.\n",
    "\n",
    "You can register new Moonshot endpoints directly from Python, as shown below.\n",
    "\n",
    "▶️ **TODO: Edit the cell below to configure your own LLM.**\n",
    "\n",
    "> If you're using OpenAI, you'll just need to replace `ADD_YOUR_TOKEN_HERE` below with your own OpenAI token.\n",
    ">\n",
    "> If you're using a different provider, check out the [list of connector IDs](https://github.com/aiverify-foundation/moonshot-data/tree/main/connectors) provided by `moonshot-data`. Different connectors have different required parameters. For example, the `amazon-bedrock-connector` can automatically pick up credentials configured in the AWS CLI - so you'll usually leave `token` blank for this connector type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4b4f87c6-8ad8-4b3f-b233-5d9143bf43dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The newly created endpoint id: my-openai-endpoint\n"
     ]
    }
   ],
   "source": [
    "endpoint_id = api_create_endpoint(\n",
    "    \"my-openai-endpoint\",  # name: Assign a unique name to identify this endpoint later.\n",
    "    \"openai-connector\",      # connector_type: Specify the connector type for the model you want to evaluate.\n",
    "    \"\",                      # uri: Leave blank as the OpenAI library handles the connection.\n",
    "    \"ADD_NEW_TOKEN_HERE\",    # token: Insert your OpenAI API token here.\n",
    "    1,    1,                   # max_calls_per_second: Set the maximum number of calls allowed per second.\n",
    "    \"gpt-3.5-turbo\" ,\n",
    "    {\n",
    "        \"timeout\": 300,      # Define the timeout for API calls in seconds.\n",
    "        \"max_attempts\": 3,  # Set the number of retries if allowed.\n",
    "        \"temperature\": 0.5,   # Set the temperature for response variability.\n",
    "    }  # params: Include any additional parameters required for this model.\n",
    ")\n",
    "print(f\"The newly created endpoint id: {endpoint_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d04074",
   "metadata": {},
   "source": [
    "You'll see running the above creates a new configuration file under your Moonshot data `CONNECTORS_ENDPOINTS` folder.\n",
    "\n",
    "These stored endpoint IDs are what we'll reference when running tests in Moonshot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbdb703b-94ca-4515-85e6-9dde0bfb9c69",
   "metadata": {},
   "source": [
    "## Run a test using our predefined `cookbook`\n",
    "\n",
    "Moonshot comes with a list of `cookbooks` and `recipes`. A `recipe` contains one or more benchmark datasets and evaluation metrics. A `cookbook` contains one or more `recipes`. To execute an existing test, we can select either a `recipe` or `cookbook`.\n",
    "\n",
    "In this tutorial, we will run a `cookbook` called `leaderboard-cookbook`. This cookbook contains a set of popular benchmarks (e.g., `mmlu`) that can be used to assess the capability of the model. \n",
    "\n",
    "*For the purpose of this tutorial, we will configure our `runner` to run 1 prompt from every recipe in this cookbook - on the endpoint we created*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07b6cab8-bbcb-47a2-b61f-62ebc4581345",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-01 18:15:46,115 [INFO][runner.py::run_cookbooks(422)] [Runner] sample-cookbook-runner - Running benchmark cookbook run...\n",
      "2024-11-01 18:15:47,634 [INFO][benchmarking.py::generate(126)] [Benchmarking] Running cookbooks (['leaderboard-cookbook'])...\n",
      "2024-11-01 18:15:47,634 [INFO][benchmarking.py::generate(132)] [Benchmarking] Running cookbook leaderboard-cookbook... (1/1)\n",
      "2024-11-01 18:15:47,759 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 12623.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:48,194 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:49,249 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:50,479 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:50,480 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 12623 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:50,482 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: mmlu, ds_id: mmlu-all, pt_id: mmlu, prompt_index: 12623] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:50,486 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to sort recipe predictions into groups in executing recipe due to error: 'NoneType' object has no attribute 'conn_id'\n",
      "2024-11-01 18:15:50,543 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 432.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:50,829 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:51,524 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:53,624 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:53,625 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 432 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:53,626 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: truthfulqa-mcq, ds_id: truthfulqa-mcq, pt_id: mcq-template, prompt_index: 432] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:53,630 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to sort recipe predictions into groups in executing recipe due to error: 'NoneType' object has no attribute 'conn_id'\n",
      "2024-11-01 18:15:53,758 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 25247.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:54,036 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:55,098 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:56,244 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:56,245 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 25247 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:56,246 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: winogrande, ds_id: winogrande, pt_id: mcq-template, prompt_index: 25247] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:56,250 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to sort recipe predictions into groups in executing recipe due to error: 'NoneType' object has no attribute 'conn_id'\n",
      "2024-11-01 18:15:56,539 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 25247.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:56,847 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:57,923 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:59,080 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:59,080 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 25247 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:59,081 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: hellaswag, ds_id: hellaswag, pt_id: mcq-template, prompt_index: 25247] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:15:59,083 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to sort recipe predictions into groups in executing recipe due to error: 'NoneType' object has no attribute 'conn_id'\n",
      "2024-11-01 18:15:59,143 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 1577.\n",
      "2024-11-01 18:15:59,145 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 3155.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:15:59,494 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:00,576 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:01,709 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:01,710 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 1577 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:01,710 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: arc, ds_id: arc-challenge, pt_id: mcq-template, prompt_index: 1577] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:02,020 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:02,867 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:03,971 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:03,971 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 3155 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:03,972 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: arc, ds_id: arc-easy, pt_id: mcq-template, prompt_index: 3155] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:03,980 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to sort recipe predictions into groups in executing recipe due to error: 'NoneType' object has no attribute 'conn_id'\n",
      "2024-11-01 18:16:04,038 [INFO][connector.py::get_prediction(348)] [Connector ID: my-openai-endpoint] Predicting Prompt Index 6311.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:04,327 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 1 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:05,399 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 2 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 401 Unauthorized\"\n",
      "2024-11-01 18:16:06,629 [ERROR][connector.py::perform_retry_callback(57)] [Connector ID: my-openai-endpoint] Attempt 3 failed due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:06,630 [ERROR][connector.py::get_prediction(376)] [Connector ID: my-openai-endpoint] Prompt Index 6311 failed to get prediction: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:06,633 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to generate prediction for prompt_info [conn_id: my-openai-endpoint, rec_id: gsm8k, ds_id: gsm8k, pt_id: mcq-template, prompt_index: 6311] due to error: Error code: 401 - {'error': {'message': 'Incorrect API key provided: ADD_NEW_******HERE. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n",
      "2024-11-01 18:16:06,637 [ERROR][run_progress.py::notify_error(47)] [Benchmarking] Failed to sort recipe predictions into groups in executing recipe due to error: 'NoneType' object has no attribute 'conn_id'\n",
      "2024-11-01 18:16:06,641 [INFO][benchmarking.py::generate(190)] [Benchmarking] Run took 19.0071s\n",
      "2024-11-01 18:16:06,643 [INFO][benchmarking.py::generate(245)] [Benchmarking] Preparing results took 0.0004s\n",
      "2024-11-01 18:16:06,679 [INFO][benchmarking-result.py::generate(58)] [BenchmarkingResult] Generate results took 0.0361s\n",
      "2024-11-01 18:16:06,680 [INFO][runner.py::run_cookbooks(448)] [Runner] sample-cookbook-runner - Benchmark cookbook run completed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metadata\": {\n",
      "    \"id\": \"sample-cookbook-runner\",\n",
      "    \"start_time\": \"2024-11-01 18:15:46\",\n",
      "    \"end_time\": \"2024-11-01 18:16:06\",\n",
      "    \"duration\": 20,\n",
      "    \"status\": \"completed_with_errors\",\n",
      "    \"recipes\": null,\n",
      "    \"cookbooks\": [\n",
      "      \"leaderboard-cookbook\"\n",
      "    ],\n",
      "    \"endpoints\": [\n",
      "      \"my-openai-endpoint\"\n",
      "    ],\n",
      "    \"num_of_prompts\": 1,\n",
      "    \"random_seed\": 0,\n",
      "    \"system_prompt\": \"\"\n",
      "  },\n",
      "  \"results\": {\n",
      "    \"cookbooks\": [\n",
      "      {\n",
      "        \"id\": \"leaderboard-cookbook\",\n",
      "        \"recipes\": [\n",
      "          {\n",
      "            \"id\": \"mmlu\",\n",
      "            \"details\": [],\n",
      "            \"evaluation_summary\": [],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 0\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"truthfulqa-mcq\",\n",
      "            \"details\": [],\n",
      "            \"evaluation_summary\": [],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 0\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"winogrande\",\n",
      "            \"details\": [],\n",
      "            \"evaluation_summary\": [],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 0\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"hellaswag\",\n",
      "            \"details\": [],\n",
      "            \"evaluation_summary\": [],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 0\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"arc\",\n",
      "            \"details\": [],\n",
      "            \"evaluation_summary\": [],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 0\n",
      "          },\n",
      "          {\n",
      "            \"id\": \"gsm8k\",\n",
      "            \"details\": [],\n",
      "            \"evaluation_summary\": [],\n",
      "            \"grading_scale\": {\n",
      "              \"A\": [\n",
      "                80,\n",
      "                100\n",
      "              ],\n",
      "              \"B\": [\n",
      "                60,\n",
      "                79\n",
      "              ],\n",
      "              \"C\": [\n",
      "                40,\n",
      "                59\n",
      "              ],\n",
      "              \"D\": [\n",
      "                20,\n",
      "                39\n",
      "              ],\n",
      "              \"E\": [\n",
      "                0,\n",
      "                19\n",
      "              ]\n",
      "            },\n",
      "            \"total_num_of_prompts\": 0\n",
      "          }\n",
      "        ],\n",
      "        \"overall_evaluation_summary\": [],\n",
      "        \"total_num_of_prompts\": 0\n",
      "      }\n",
      "    ]\n",
      "  }\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y2/k82j4vbd4cd9lym64kzxdx7m0000gn/T/ipykernel_95666/10801341.py:37: RuntimeWarning: coroutine 'Runner.close' was never awaited\n",
      "  cb_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n"
     ]
    }
   ],
   "source": [
    "from slugify import slugify\n",
    "from moonshot.api import api_get_all_run, api_create_runner, api_get_all_runner_name\n",
    "\n",
    "name = \"sample-cookbook-runner\" # Indicate the name\n",
    "cookbooks = [\"leaderboard-cookbook\"] # Test against 2 cookbooks, test-category-cookbook and common-risk-easy\n",
    "endpoints = [\"my-openai-endpoint\"] # Test against 1 endpoint, test-openai-endpoint\n",
    "num_of_prompts = 1 # use a smaller number to test out the function; 0 means using all prompts in dataset\n",
    "\n",
    "# Below are the optional fields\n",
    "random_seed = 0   # Default: 0; this allows for randomness in dataset selection when num_of_prompts are set\n",
    "system_prompt = \"\"  # Default: \"\"; this allows setting the system prompt for the endpoints\n",
    "\n",
    "# Advanced user - Modify runner processing module and result processing module\n",
    "# Default: benchmarking and benchmarking-result\n",
    "runner_proc_module = \"benchmarking\"  # Default: \"benchmarking\"\n",
    "result_proc_module = \"benchmarking-result\"  # Default: \"benchmarking-result\"\n",
    "\n",
    "# Run the cookbooks with the defined endpoints\n",
    "# If the id exists, it will perform a load on the runner, instead of creating a new runner.\n",
    "# The benefit of this, allows the new run to use possible cached results from previous runs which greatly enhances the run time.\n",
    "slugify_id = slugify(name, lowercase=True)\n",
    "if slugify_id in api_get_all_runner_name():\n",
    "    cb_runner = api_load_runner(slugify_id)\n",
    "else:\n",
    "    cb_runner = api_create_runner(name, endpoints)\n",
    "\n",
    "# run_cookbooks is an async function. Currently there is no sync version.\n",
    "# We will get an existing event loop and execute the run cookbooks process.\n",
    "await cb_runner.run_cookbooks(\n",
    "        cookbooks,\n",
    "        num_of_prompts,\n",
    "        random_seed,\n",
    "        system_prompt,\n",
    "        runner_proc_module,\n",
    "        result_proc_module,\n",
    "    )\n",
    "cb_runner.close()  # Perform a close on the runner to allow proper cleanup.\n",
    "\n",
    "# Display results in JSON\n",
    "runner_runs = api_get_all_run(cb_runner.id)\n",
    "result_info = runner_runs[-1].get(\"results\")\n",
    "if result_info:\n",
    "    print(json.dumps(result_info, indent=2))\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd2a0d5-d5f7-48f5-bd6f-73ca2d6a0430",
   "metadata": {},
   "source": [
    "## Beautifying the results\n",
    "\n",
    "The result above is shown in our raw JSON file. To beautify the results, you can use the `rich` library to put them into a nice table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c7f1b98-497d-4f92-acc5-838e11bd0434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-style: italic\">                                                  Cookbook Result                                                  </span>\n",
       "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> No. </span>┃<span style=\"font-weight: bold\"> Cookbook (with its recipes)                                                         </span>┃<span style=\"font-weight: bold\"> my-openai-endpoint  </span>┃\n",
       "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 1   │ Cookbook: <span style=\"color: #000080; text-decoration-color: #000080\">leaderboard-cookbook</span>                                                      │          E          │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">mmlu</span>                                                                 │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">truthfulqa-mcq</span>                                                       │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">winogrande</span>                                                           │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">hellaswag</span>                                                            │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">arc</span>                                                                  │      A [100.0]      │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: <span style=\"color: #000080; text-decoration-color: #000080\">gsm8k</span>                                                                │       E [0.0]       │\n",
       "└─────┴─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[3m                                                  Cookbook Result                                                  \u001b[0m\n",
       "┏━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mNo.\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mCookbook (with its recipes)                                                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mmy-openai-endpoint \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ 1   │ Cookbook: \u001b[34mleaderboard-cookbook\u001b[0m                                                      │          E          │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34mmmlu\u001b[0m                                                                 │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34mtruthfulqa-mcq\u001b[0m                                                       │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34mwinogrande\u001b[0m                                                           │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34mhellaswag\u001b[0m                                                            │       E [0.0]       │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34marc\u001b[0m                                                                  │      A [100.0]      │\n",
       "├─────┼─────────────────────────────────────────────────────────────────────────────────────┼─────────────────────┤\n",
       "│     │   └──  Recipe: \u001b[34mgsm8k\u001b[0m                                                                │       E [0.0]       │\n",
       "└─────┴─────────────────────────────────────────────────────────────────────────────────────┴─────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">==================================================\n",
       "<span style=\"color: #000080; text-decoration-color: #000080\">Time taken to run: 6s</span>\n",
       "*Overall rating will be the lowest grade that the recipes have in each cookbook\n",
       "==================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "==================================================\n",
       "\u001b[34mTime taken to run: 6s\u001b[0m\n",
       "*Overall rating will be the lowest grade that the recipes have in each cookbook\n",
       "==================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from rich.columns import Columns\n",
    "from rich.console import Console\n",
    "from rich.panel import Panel\n",
    "from rich.table import Table\n",
    "console = Console()\n",
    "\n",
    "def show_cookbook_results(cookbooks, endpoints, cookbook_results, duration):\n",
    "    \"\"\"\n",
    "    Show the results of the cookbook benchmarking.\n",
    "\n",
    "    This function takes the cookbooks, endpoints, cookbook results, results file, and duration as arguments.\n",
    "    If there are results, it generates a table with the cookbook results and prints a message indicating\n",
    "    where the results are saved. If there are no results, it prints a message indicating that no results were found.\n",
    "    Finally, it prints the duration of the run.\n",
    "\n",
    "    Args:\n",
    "        cookbooks (list): A list of cookbooks.\n",
    "        endpoints (list): A list of endpoints.\n",
    "        cookbook_results (dict): A dictionary with the results of the cookbook benchmarking.\n",
    "        duration (float): The duration of the run.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    if cookbook_results:\n",
    "        # Display recipe results\n",
    "        generate_cookbook_table(cookbooks, endpoints, cookbook_results)\n",
    "    else:\n",
    "        console.print(\"[red]There are no results.[/red]\")\n",
    "\n",
    "    # Print run stats\n",
    "    console.print(f\"{'='*50}\\n[blue]Time taken to run: {duration}s[/blue]\\n*Overall rating will be the lowest grade that the recipes have in each cookbook\\n{'='*50}\")\n",
    "\n",
    "def generate_cookbook_table(cookbooks: list, endpoints: list, results: dict) -> None:\n",
    "    \"\"\"\n",
    "    Generate and display a table with the cookbook benchmarking results.\n",
    "\n",
    "    This function creates a table that includes the index, cookbook name, recipe name, and the results\n",
    "    for each endpoint.\n",
    "\n",
    "    The cookbook names are prefixed with \"Cookbook:\" and are displayed with their overall grades. Each recipe under a\n",
    "    cookbook is indented and prefixed with \"Recipe:\" followed by its individual grades for each endpoint. If there are\n",
    "    no results for a cookbook, a row with dashes across all endpoint columns is added to indicate this.\n",
    "\n",
    "    Args:\n",
    "        cookbooks (list): A list of cookbook names to display in the table.\n",
    "        endpoints (list): A list of endpoints for which results are to be displayed.\n",
    "        results (dict): A dictionary containing the benchmarking results for cookbooks and recipes.\n",
    "\n",
    "    Returns:\n",
    "        None: The function prints the table to the console but does not return any value.\n",
    "    \"\"\"\n",
    "    table = Table(\n",
    "        title=\"Cookbook Result\", show_lines=True, expand=True, header_style=\"bold\"\n",
    "    )\n",
    "    table.add_column(\"No.\", width=2)\n",
    "    table.add_column(\"Cookbook (with its recipes)\", justify=\"left\", width=78)\n",
    "    for endpoint in endpoints:\n",
    "        table.add_column(endpoint, justify=\"center\")\n",
    "\n",
    "    index = 1\n",
    "    for cookbook in cookbooks:\n",
    "        # Get cookbook result\n",
    "        cookbook_result = next(\n",
    "            (\n",
    "                result\n",
    "                for result in results[\"results\"][\"cookbooks\"]\n",
    "                if result[\"id\"] == cookbook\n",
    "            ),\n",
    "            None,\n",
    "        )\n",
    "\n",
    "        if cookbook_result:\n",
    "            # Add the cookbook name with the \"Cookbook: \" prefix as the first row for this section\n",
    "            endpoint_results = []\n",
    "            for endpoint in endpoints:\n",
    "                # Find the evaluation summary for the endpoint\n",
    "                evaluation_summary = next(\n",
    "                    (\n",
    "                        temp_eval\n",
    "                        for temp_eval in cookbook_result[\"overall_evaluation_summary\"]\n",
    "                        if temp_eval[\"model_id\"] == endpoint\n",
    "                    ),\n",
    "                    None,\n",
    "                )\n",
    "\n",
    "                # Get the grade from the evaluation_summary, or use \"-\" if not found\n",
    "                grade = \"-\"\n",
    "                if evaluation_summary and evaluation_summary[\"overall_grade\"]:\n",
    "                    grade = evaluation_summary[\"overall_grade\"]\n",
    "                endpoint_results.append(grade)\n",
    "            table.add_row(\n",
    "                str(index),\n",
    "                f\"Cookbook: [blue]{cookbook}[/blue]\",\n",
    "                *endpoint_results,\n",
    "                end_section=True,\n",
    "            )\n",
    "\n",
    "            for recipe in cookbook_result[\"recipes\"]:\n",
    "                endpoint_results = []\n",
    "                for endpoint in endpoints:\n",
    "                    # Find the evaluation summary for the endpoint\n",
    "                    evaluation_summary = next(\n",
    "                        (\n",
    "                            temp_eval\n",
    "                            for temp_eval in recipe[\"evaluation_summary\"]\n",
    "                            if temp_eval[\"model_id\"] == endpoint\n",
    "                        ),\n",
    "                        None,\n",
    "                    )\n",
    "\n",
    "                    # Get the grade from the evaluation_summary, or use \"-\" if not found\n",
    "                    grade = \"-\"\n",
    "                    if (\n",
    "                        evaluation_summary\n",
    "                        and \"grade\" in evaluation_summary\n",
    "                        and \"avg_grade_value\" in evaluation_summary\n",
    "                        and evaluation_summary[\"grade\"]\n",
    "                    ):\n",
    "                        grade = f\"{evaluation_summary['grade']} [{evaluation_summary['avg_grade_value']}]\"\n",
    "                    endpoint_results.append(grade)\n",
    "\n",
    "                # Add the recipe name indented under the cookbook name\n",
    "                table.add_row(\n",
    "                    \"\",\n",
    "                    f\"  └──  Recipe: [blue]{recipe['id']}[/blue]\",\n",
    "                    *endpoint_results,\n",
    "                    end_section=True,\n",
    "                )\n",
    "\n",
    "            # Increment index only after all recipes of the cookbook have been added\n",
    "            index += 1\n",
    "        else:\n",
    "            # If no results for the cookbook, add a row indicating this with the \"Cookbook: \" prefix\n",
    "            # and a dash for each endpoint column\n",
    "            table.add_row(\n",
    "                str(index),\n",
    "                f\"Cookbook: {cookbook}\",\n",
    "                *([\"-\"] * len(endpoints)),\n",
    "                end_section=True,\n",
    "            )\n",
    "            index += 1\n",
    "\n",
    "    # Display table\n",
    "    console.print(table)\n",
    "\n",
    "if result_info:\n",
    "    show_cookbook_results(\n",
    "        cookbooks, endpoints, result_info, result_info[\"metadata\"][\"duration\"]\n",
    "    )\n",
    "else:\n",
    "    raise RuntimeError(\"no run result generated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcb23bf7-6705-4e19-9ffd-ea350731cfe7",
   "metadata": {},
   "source": [
    "## List all the Cookbook\n",
    "\n",
    "If you are curious what are the other cookbooks available, you can use `api_get_all_cookbook()`.\n",
    "\n",
    "Here's how it will look like in the output. To run these cookbooks, just replace `leaderboard-cookbook` with one of the cookbook IDs or you can append more cookbook IDs to the list in the previous cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d1ab399-82ee-430f-8477-24f6e40ab9a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cookbooks: 9\n",
      "Showing the first three cookbooks below...\n",
      "[\n",
      "  {\n",
      "    \"id\": \"common-risk-easy\",\n",
      "    \"name\": \"Easy test sets for Common Risks\",\n",
      "    \"description\": \"This is a cookbook that consists (easy) test sets for common risks. These test sets are adapted from various research and will be expanded in the future.\",\n",
      "    \"recipes\": [\n",
      "      \"uciadult\",\n",
      "      \"bbq\",\n",
      "      \"winobias\",\n",
      "      \"challenging-toxicity-prompts-completion\",\n",
      "      \"realtime-qa\",\n",
      "      \"commonsense-morality-easy\",\n",
      "      \"jailbreak-dan\",\n",
      "      \"advglue\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"common-risk-hard\",\n",
      "    \"name\": \"Hard test sets for Common Risks\",\n",
      "    \"description\": \"This is a cookbook that consists (hard) test sets for common risks. These test sets are adapted from various research and will be expanded in the future.\",\n",
      "    \"recipes\": [\n",
      "      \"uciadult\",\n",
      "      \"bbq\",\n",
      "      \"winobias\",\n",
      "      \"challenging-toxicity-prompts-completion\",\n",
      "      \"realtime-qa\",\n",
      "      \"commonsense-morality-hard\",\n",
      "      \"jailbreak-dan\",\n",
      "      \"advglue\"\n",
      "    ]\n",
      "  },\n",
      "  {\n",
      "    \"id\": \"medical-llm-leaderboard\",\n",
      "    \"name\": \"Medical LLM Leaderboard\",\n",
      "    \"description\": \"This cookbook contains the benchmarks used in Medical LLM Leaderboard hosted on HuggingFace. Achieving a high score may mean that the targeted system is performing well in answering healthcare questions.\",\n",
      "    \"recipes\": [\n",
      "      \"medical-mcq\",\n",
      "      \"mmlu-medical\"\n",
      "    ]\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "cookbook_ids = api_get_all_cookbook()\n",
    "print(\"Total number of cookbooks: {0}\".format(len(cookbook_ids)))\n",
    "print(\"Showing the first three cookbooks below...\")\n",
    "print(json.dumps(cookbook_ids[0:3], indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-virtualenv-name",
   "language": "python",
   "name": "my-virtualenv-name"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
